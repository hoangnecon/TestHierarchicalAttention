{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "authorship_tag": "ABX9TyN1iHOX4Wv6A0maA8KJ/++q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hoangnecon/TestHierarchicalAttention/blob/main/LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5YXp6Yw9AYI",
        "outputId": "dfead738-06e0-4efe-83ba-d5d2c15c656e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.5/42.5 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.8/121.8 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.7/161.7 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -U vnstock -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from vnstock import Vnstock #Phải tạo đối tượng\n",
        "from datetime import datetime\n",
        "import os\n",
        "\n",
        "def fetch_and_combine_data(symbols, start_date, end_date):\n",
        "    all_data = {}\n",
        "    print(f\"Bắt đầu tải dữ liệu cho các chỉ số: {symbols} từ {start_date} đến {end_date}...\")\n",
        "\n",
        "    # Khởi tạo đối tượng Vnstock\n",
        "    stock_client = Vnstock()\n",
        "\n",
        "    for symbol in symbols:\n",
        "        try:\n",
        "            df = stock_client.stock(symbol=symbol).quote.history(\n",
        "                start=start_date,\n",
        "                end=end_date\n",
        "            )\n",
        "\n",
        "            if df.empty:\n",
        "                print(f\"Cảnh báo: Không có dữ liệu trả về cho chỉ số {symbol}.\")\n",
        "                continue\n",
        "\n",
        "            df.rename(columns={'time': 'Date', 'open': f'{symbol}_Open', 'high': f'{symbol}_High',\n",
        "                               'low': f'{symbol}_Low', 'close': f'{symbol}_Close', 'volume': f'{symbol}_Volume'},\n",
        "                      inplace=True)\n",
        "\n",
        "            df['Date'] = pd.to_datetime(df['Date'])\n",
        "            df.set_index('Date', inplace=True)\n",
        "\n",
        "            all_data[symbol] = df\n",
        "            print(f\"Tải thành công dữ liệu cho {symbol}.\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Lỗi khi tải dữ liệu cho {symbol}: {e}\")\n",
        "            return None\n",
        "\n",
        "    if not all_data:\n",
        "        print(\"Lỗi: Không thể tải dữ liệu cho bất kỳ chỉ số nào.\")\n",
        "        return None\n",
        "\n",
        "    combined_df = pd.concat(all_data.values(), axis=1, join='outer')\n",
        "    combined_df.sort_index(inplace=True)\n",
        "    combined_df.fillna(method='ffill', inplace=True)\n",
        "    combined_df.dropna(inplace=True)\n",
        "\n",
        "    print(\"\\n✅ Hoàn tất việc tải và hợp nhất dữ liệu.\")\n",
        "    return combined_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291
        },
        "id": "M02CzyJM9MIp",
        "outputId": "3a235152-23fc-4e3e-aa32-c36ed51db8c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<!DOCTYPE html>\n",
              "<html>\n",
              "\n",
              "<head>\n",
              "    <meta charset=\"UTF-8\">\n",
              "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
              "    <link href=\"https://fonts.googleapis.com/css2?family=Lexend:wght@400;500;600;700&display=swap\" rel=\"stylesheet\">\n",
              "    <style>\n",
              "        .vnstock-ad-banner {\n",
              "            all: initial;\n",
              "            font-family: 'Lexend', sans-serif;\n",
              "            display: flex;\n",
              "            flex-wrap: wrap;\n",
              "            max-width: 100%;\n",
              "            margin: 12px 0;\n",
              "            border-radius: 10px;\n",
              "            overflow: hidden;\n",
              "            background: #ffffff;\n",
              "            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.08);\n",
              "            color: #333;\n",
              "        }\n",
              "\n",
              "        .vnstock-ad-content {\n",
              "            flex: 1;\n",
              "            padding: 12px 16px;\n",
              "            display: flex;\n",
              "            flex-direction: column;\n",
              "            justify-content: center;\n",
              "        }\n",
              "\n",
              "        .vnstock-ad-title {\n",
              "            margin: 0 0 10px 0;\n",
              "            line-height: 1.3;\n",
              "            font-size: 18px;\n",
              "            font-weight: 700;\n",
              "            color: #4CAF50;\n",
              "        }\n",
              "\n",
              "        .title-highlight {\n",
              "            color: #8C52FF;\n",
              "        }\n",
              "\n",
              "        .vnstock-ad-features {\n",
              "            list-style: none;\n",
              "            padding-left: 0;\n",
              "            margin: 10px 0 12px 0;\n",
              "            font-size: 13px;\n",
              "            line-height: 1.4;\n",
              "        }\n",
              "\n",
              "        .vnstock-ad-features li {\n",
              "            margin-bottom: 6px;\n",
              "        }\n",
              "\n",
              "        .feature-highlight {\n",
              "            color: #8C52FF;\n",
              "            font-weight: 600;\n",
              "        }\n",
              "\n",
              "        .button-container {\n",
              "            text-align: center;\n",
              "        }\n",
              "\n",
              "        .vnstock-ad-button {\n",
              "            display: inline-block;\n",
              "            background-color: #4CAF50;\n",
              "            color: #fff;\n",
              "            padding: 6px 16px;\n",
              "            text-decoration: none;\n",
              "            font-size: 13px;\n",
              "            border-radius: 20px;\n",
              "            font-weight: 600;\n",
              "            transition: all 0.2s;\n",
              "            box-shadow: 0 2px 6px rgba(76, 175, 80, 0.2);\n",
              "        }\n",
              "\n",
              "        .vnstock-ad-button:hover {\n",
              "            background-color: #8C52FF;\n",
              "            color: white;\n",
              "            transform: translateY(-1px);\n",
              "            box-shadow: 0 4px 8px rgba(140, 82, 255, 0.3);\n",
              "        }\n",
              "\n",
              "        .vnstock-ad-image {\n",
              "            flex: 1;\n",
              "            min-width: 180px;\n",
              "            max-width: 45%;\n",
              "        }\n",
              "\n",
              "        .vnstock-ad-image img {\n",
              "            width: 100%;\n",
              "            height: 100%;\n",
              "            max-height: 250px;\n",
              "            object-fit: cover;\n",
              "            display: block;\n",
              "        }\n",
              "\n",
              "        @media (max-width: 768px) {\n",
              "            .vnstock-ad-banner {\n",
              "                flex-direction: column;\n",
              "            }\n",
              "\n",
              "            .vnstock-ad-image {\n",
              "                min-width: auto;\n",
              "                max-width: 100%;\n",
              "            }\n",
              "        }\n",
              "    </style>\n",
              "</head>\n",
              "\n",
              "<body>\n",
              "    <div class=\"vnstock-ad-banner\">\n",
              "        <div class=\"vnstock-ad-content\">\n",
              "            <h2 class=\"vnstock-ad-title\">\n",
              "                <span class=\"title-highlight\">🤖 Python Coding với AI:</span> Học chủ động qua video ghi hình\n",
              "            </h2>\n",
              "            <ul class=\"vnstock-ad-features\">\n",
              "                <li><span class=\"feature-highlight\">🎥 Khóa học live đã khởi động:</span> Xem lại video bài giảng tại\n",
              "                    website, theo dõi tiến độ rõ ràng</li>\n",
              "                <li><span class=\"feature-highlight\">⚡ Điều khiển AI viết code Python:</span> Không cần học thuộc lòng,\n",
              "                    học ứng biến với AI agent</li>\n",
              "                <li><span class=\"feature-highlight\">🤖 Tập trung vào AI thực chiến:</span> Viết bot, phân tích dữ liệu\n",
              "                    bằng Python nhờ sức mạnh AI</li>\n",
              "                <li><span class=\"feature-highlight\">💡 Cộng đồng chất lượng cao:</span> 100+ nhà đầu tư, chuyên gia &\n",
              "                    lập trình viên cùng học hỏi</li>\n",
              "            </ul>\n",
              "            <div class=\"button-container\">\n",
              "                <a href=\"https://vnstocks.com/lp-khoa-hoc-python-chung-khoan\" class=\"vnstock-ad-button\">\n",
              "                    Đăng ký học ngay ›\n",
              "                </a>\n",
              "            </div>\n",
              "        </div>\n",
              "        <a href=\"https://vnstocks.com/lp-khoa-hoc-python-chung-khoan\" class=\"vnstock-ad-image\">\n",
              "            <img src=\"https://vnstocks.com/img/cta-python-chung-khoan-k11-start-now.jpg\"\n",
              "                alt=\"Khóa học Python Coding với AI\"\n",
              "                style=\"width: 100%; height: 100%; max-height: 250px; object-fit: cover; display: block;\">\n",
              "        </a>\n",
              "    </div>\n",
              "</body>\n",
              "\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "SYMBOLS_TO_FETCH = ['VNINDEX', 'VN30', 'VN100']\n",
        "START_DATE = '2019-01-01'\n",
        "END_DATE = '2023-12-31'\n",
        "OUTPUT_CSV_PATH = 'vn_indices_2019_2023.csv'\n",
        "\n",
        "\n",
        "print(\"Bắt đầu quá trình...\")\n",
        "final_dataframe = fetch_and_combine_data(\n",
        "    symbols=SYMBOLS_TO_FETCH,\n",
        "    start_date=START_DATE,\n",
        "    end_date=END_DATE\n",
        ")\n",
        "\n",
        "if final_dataframe is not None:\n",
        "\n",
        "    final_dataframe.to_csv(OUTPUT_CSV_PATH)\n",
        "    print(f\"\\n✅ Đã lưu thành công dữ liệu vào file: {OUTPUT_CSV_PATH}\")\n",
        "\n",
        "    print(\"\\n5 dòng dữ liệu đầu tiên:\")\n",
        "    print(final_dataframe.head())\n",
        "\n",
        "    print(\"\\nCác file trong thư mục hiện tại của Colab:\")\n",
        "    !ls -lh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dDQ_FSoF_XiE",
        "outputId": "13c68fd0-e225-4fdf-f85b-f4e61ec366b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-07-10 09:37:02 - vnstock.common.data.data_explorer - INFO - Không phải là mã chứng khoán, thông tin công ty và tài chính không khả dụng.\n",
            "INFO:vnstock.common.data.data_explorer:Không phải là mã chứng khoán, thông tin công ty và tài chính không khả dụng.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bắt đầu quá trình...\n",
            "Bắt đầu tải dữ liệu cho các chỉ số: ['VNINDEX', 'VN30', 'VN100'] từ 2019-01-01 đến 2023-12-31...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-07-10 09:37:04 - vnstock.common.data.data_explorer - INFO - Không phải là mã chứng khoán, thông tin công ty và tài chính không khả dụng.\n",
            "INFO:vnstock.common.data.data_explorer:Không phải là mã chứng khoán, thông tin công ty và tài chính không khả dụng.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tải thành công dữ liệu cho VNINDEX.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-07-10 09:37:05 - vnstock.common.data.data_explorer - INFO - Không phải là mã chứng khoán, thông tin công ty và tài chính không khả dụng.\n",
            "INFO:vnstock.common.data.data_explorer:Không phải là mã chứng khoán, thông tin công ty và tài chính không khả dụng.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tải thành công dữ liệu cho VN30.\n",
            "Tải thành công dữ liệu cho VN100.\n",
            "\n",
            "✅ Hoàn tất việc tải và hợp nhất dữ liệu.\n",
            "\n",
            "✅ Đã lưu thành công dữ liệu vào file: vn_indices_2019_2023.csv\n",
            "\n",
            "5 dòng dữ liệu đầu tiên:\n",
            "            VNINDEX_Open  VNINDEX_High  VNINDEX_Low  VNINDEX_Close  \\\n",
            "Date                                                                 \n",
            "2022-06-20       1218.37       1221.60      1180.40        1180.40   \n",
            "2022-06-21       1172.98       1189.97      1162.94        1172.47   \n",
            "2022-06-22       1180.11       1185.86      1162.98        1169.27   \n",
            "2022-06-23       1162.06       1188.88      1162.06        1188.88   \n",
            "2022-06-24       1190.82       1196.85      1185.48        1185.48   \n",
            "\n",
            "            VNINDEX_Volume  VN30_Open  VN30_High  VN30_Low  VN30_Close  \\\n",
            "Date                                                                     \n",
            "2022-06-20       620002900    1258.30    1262.83   1223.03     1225.56   \n",
            "2022-06-21       607711900    1220.76    1240.80   1212.69     1224.54   \n",
            "2022-06-22       529135300    1233.28    1242.06   1222.86     1227.18   \n",
            "2022-06-23       380442900    1219.40    1240.58   1219.08     1240.58   \n",
            "2022-06-24       410876800    1239.54    1246.22   1234.72     1235.47   \n",
            "\n",
            "            VN30_Volume  VN100_Open  VN100_High  VN100_Low  VN100_Close  \\\n",
            "Date                                                                      \n",
            "2022-06-20    168768300     1200.28     1205.64    1162.12      1164.33   \n",
            "2022-06-21    172801800     1164.33     1172.84    1146.33      1155.46   \n",
            "2022-06-22    142695000     1155.46     1171.76    1153.99      1161.32   \n",
            "2022-06-23    105240000     1161.32     1181.06    1155.29      1181.06   \n",
            "2022-06-24     90437000     1181.06     1188.88    1178.27      1178.27   \n",
            "\n",
            "            VN100_Volume  \n",
            "Date                      \n",
            "2022-06-20   440780139.0  \n",
            "2022-06-21    46278396.0  \n",
            "2022-06-22   379972360.0  \n",
            "2022-06-23   287745109.0  \n",
            "2022-06-24    15931986.0  \n",
            "\n",
            "Các file trong thư mục hiện tại của Colab:\n",
            "total 56K\n",
            "drwxr-xr-x 1 root root 4.0K Jul  8 17:47 sample_data\n",
            "-rw-r--r-- 1 root root  52K Jul 10 09:37 vn_indices_2019_2023.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# config.py\n",
        "%%writefile config.py\n",
        "RAW_DATA_PATH = 'vn_indices_2019_2023.csv'\n",
        "PROCESSED_DATA_PATH = 'vn_indices_processed.csv'\n",
        "INDICATORS = {\n",
        "    'rsi': {'window': 14},\n",
        "    'macd': {'fast': 12, 'slow': 26, 'signal': 9},\n",
        "    'bollinger': {'window': 20, 'std': 2}\n",
        "}\n",
        "TARGET_SYMBOLS = ['VNINDEX', 'VN30', 'VN100']\n",
        "PRICE_COLUMN_SUFFIX = '_Close'\n",
        "VOLUME_COLUMN_SUFFIX = '_Volume'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "StCT7HFJBK2w",
        "outputId": "4703fe07-b6ab-4608-f0b4-3eaf917998aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing config.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile feature_engineering.py\n",
        "# feature_engineering.py\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "# Import các cấu hình từ file config.py (ĐÃ SỬA: Bỏ PANDAS_FILL_METHOD)\n",
        "from config import RAW_DATA_PATH, PROCESSED_DATA_PATH, INDICATORS, TARGET_SYMBOLS, PRICE_COLUMN_SUFFIX\n",
        "\n",
        "def calculate_rsi(series, window):\n",
        "    \"\"\"Tính toán Chỉ số Sức mạnh Tương đối (RSI)\"\"\"\n",
        "    delta = series.diff()\n",
        "    gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()\n",
        "    loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()\n",
        "    rs = gain / loss\n",
        "    return 100 - (100 / (1 + rs))\n",
        "\n",
        "def calculate_macd(series, fast, slow, signal):\n",
        "    \"\"\"Tính toán Trung bình Động Hội tụ Phân kỳ (MACD)\"\"\"\n",
        "    exp1 = series.ewm(span=fast, adjust=False).mean()\n",
        "    exp2 = series.ewm(span=slow, adjust=False).mean()\n",
        "    macd = exp1 - exp2\n",
        "    signal_line = macd.ewm(span=signal, adjust=False).mean()\n",
        "    return macd, signal_line\n",
        "\n",
        "def calculate_bollinger_bands(series, window, std):\n",
        "    \"\"\"Tính toán Dải Bollinger\"\"\"\n",
        "    rolling_mean = series.rolling(window=window).mean()\n",
        "    rolling_std = series.rolling(window=window).std()\n",
        "    upper_band = rolling_mean + (rolling_std * std)\n",
        "    lower_band = rolling_mean - (rolling_std * std)\n",
        "    return upper_band, lower_band\n",
        "\n",
        "def add_features(df):\n",
        "    \"\"\"\n",
        "    Đọc dữ liệu thô, tính toán các chỉ báo kỹ thuật cho mỗi mã,\n",
        "    và trả về một dataframe mới với các đặc trưng này.\n",
        "    \"\"\"\n",
        "    print(\"Bắt đầu quá trình Feature Engineering...\")\n",
        "\n",
        "    for symbol in TARGET_SYMBOLS:\n",
        "        print(f\"-> Đang tính toán chỉ báo cho {symbol}...\")\n",
        "        price_col = f\"{symbol}{PRICE_COLUMN_SUFFIX}\"\n",
        "\n",
        "        # --- RSI ---\n",
        "        rsi_params = INDICATORS['rsi']\n",
        "        df[f'{symbol}_RSI'] = calculate_rsi(df[price_col], window=rsi_params['window'])\n",
        "\n",
        "        # --- MACD ---\n",
        "        macd_params = INDICATORS['macd']\n",
        "        macd, signal_line = calculate_macd(df[price_col], fast=macd_params['fast'], slow=macd_params['slow'], signal=macd_params['signal'])\n",
        "        df[f'{symbol}_MACD'] = macd\n",
        "        df[f'{symbol}_MACD_Signal'] = signal_line\n",
        "\n",
        "        # --- Bollinger Bands ---\n",
        "        bb_params = INDICATORS['bollinger']\n",
        "        upper_band, lower_band = calculate_bollinger_bands(df[price_col], window=bb_params['window'], std=bb_params['std'])\n",
        "        df[f'{symbol}_BB_Upper'] = upper_band\n",
        "        df[f'{symbol}_BB_Lower'] = lower_band\n",
        "\n",
        "    original_rows = len(df)\n",
        "    df.dropna(inplace=True)\n",
        "    new_rows = len(df)\n",
        "    print(f\"\\nĐã bỏ {original_rows - new_rows} hàng có giá trị NaN sau khi tính toán đặc trưng.\")\n",
        "\n",
        "    print(\"\\nHoàn tất Feature Engineering.\")\n",
        "    print(\"Dữ liệu mẫu sau khi xử lý:\")\n",
        "    print(df.head())\n",
        "\n",
        "    return df\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    try:\n",
        "        raw_df = pd.read_csv(RAW_DATA_PATH, index_col='Date', parse_dates=True)\n",
        "        processed_df = add_features(raw_df)\n",
        "        processed_df.to_csv(PROCESSED_DATA_PATH)\n",
        "        print(f\"\\n✅ Đã lưu thành công dữ liệu đã xử lý vào file {PROCESSED_DATA_PATH}\")\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Lỗi: Không tìm thấy file dữ liệu thô tại '{RAW_DATA_PATH}'.\")\n",
        "        print(\"Vui lòng chạy các ô tạo dữ liệu trước.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Đã xảy ra lỗi: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3EyHYi7dCwf0",
        "outputId": "308efa1f-5fd2-4546-e570-26ad31f0231f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing feature_engineering.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python feature_engineering.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2UZmbNwYC-JE",
        "outputId": "aef83db7-5f1d-48e1-b2f4-e26ba680e5d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bắt đầu quá trình Feature Engineering...\n",
            "-> Đang tính toán chỉ báo cho VNINDEX...\n",
            "-> Đang tính toán chỉ báo cho VN30...\n",
            "-> Đang tính toán chỉ báo cho VN100...\n",
            "\n",
            "Đã bỏ 19 hàng có giá trị NaN sau khi tính toán đặc trưng.\n",
            "\n",
            "Hoàn tất Feature Engineering.\n",
            "Dữ liệu mẫu sau khi xử lý:\n",
            "            VNINDEX_Open  VNINDEX_High  ...  VN100_BB_Upper  VN100_BB_Lower\n",
            "Date                                    ...                                \n",
            "2022-07-15       1183.15       1189.66  ...     1214.049565     1142.499435\n",
            "2022-07-18       1184.74       1184.93  ...     1213.959151     1143.285849\n",
            "2022-07-19       1176.10       1180.46  ...     1213.245691     1145.498309\n",
            "2022-07-20       1188.12       1198.63  ...     1213.481968     1147.715032\n",
            "2022-07-21       1195.03       1201.91  ...     1214.512315     1147.852685\n",
            "\n",
            "[5 rows x 30 columns]\n",
            "\n",
            "✅ Đã lưu thành công dữ liệu đã xử lý vào file vn_indices_processed.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile config.py\n",
        "# config.py\n",
        "PROCESSED_DATA_PATH = 'vn_indices_processed.csv'\n",
        "INDICATORS = {\n",
        "    'rsi': {'window': 14},\n",
        "    'macd': {'fast': 12, 'slow': 26, 'signal': 9},\n",
        "    'bollinger': {'window': 20, 'std': 2}\n",
        "}\n",
        "TARGET_SYMBOLS = ['VNINDEX', 'VN30', 'VN100']\n",
        "PRICE_COLUMN_SUFFIX = '_Close'\n",
        "VOLUME_COLUMN_SUFFIX = '_Volume'\n",
        "\n",
        "LOOKBACK_WINDOW = 30\n",
        "\n",
        "TARGET_COLUMN = 'VNINDEX_Close'\n",
        "\n",
        "WAVELET_FAMILY = 'db4'\n",
        "WAVELET_LEVEL = 4\n",
        "\n",
        "TEST_SET_SIZE = 0.2\n",
        "BATCH_SIZE = 32"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mIU843s7FAx5",
        "outputId": "7dcf70d9-dc75-4c3d-eedc-3e4616e497ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting config.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile dataset.py\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pywt\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "from config import (\n",
        "    PROCESSED_DATA_PATH, LOOKBACK_WINDOW, TARGET_COLUMN,\n",
        "    WAVELET_FAMILY, WAVELET_LEVEL, TEST_SET_SIZE, BATCH_SIZE\n",
        ")\n",
        "\n",
        "def create_multiscale_features(data, wavelet_family, level):\n",
        "    \"\"\"\n",
        "    Phân rã mỗi cột trong dataframe thành các thành phần đa quy mô bằng Wavelet.\n",
        "    \"\"\"\n",
        "    coeffs_df_list = []\n",
        "    for column in data.columns:\n",
        "        series = data[column].values\n",
        "        coeffs = pywt.wavedec(series, wavelet_family, level=level)\n",
        "\n",
        "        for i, c in enumerate(coeffs):\n",
        "            c_padded = np.pad(c, (0, len(data) - len(c)), 'constant')\n",
        "            coeff_name = f\"{column}_wavelet_L{i}\"\n",
        "            coeffs_df_list.append(pd.DataFrame({coeff_name: c_padded}, index=data.index))\n",
        "\n",
        "    multiscale_df = pd.concat(coeffs_df_list, axis=1)\n",
        "    return multiscale_df\n",
        "\n",
        "def create_sequences(data, target, lookback_window):\n",
        "    \"\"\"Tạo các chuỗi tuần tự- slide windows cho bài toán học có giám sát.\"\"\"\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - lookback_window):\n",
        "        X.append(data[i:(i + lookback_window)])\n",
        "        y.append(target[i + lookback_window])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "class StockDataset(Dataset):\n",
        "    \"\"\"Lớp Dataset tùy chỉnh của PyTorch.\"\"\"\n",
        "    def __init__(self, features, labels):\n",
        "        self.features = torch.tensor(features, dtype=torch.float32)\n",
        "        self.labels = torch.tensor(labels, dtype=torch.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.features)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.features[idx], self.labels[idx]\n",
        "\n",
        "def get_data_loaders():\n",
        "    print(\"Bắt đầu quá trình tạo DataLoader...\")\n",
        "    try:\n",
        "        df = pd.read_csv(PROCESSED_DATA_PATH, index_col='Date', parse_dates=True)\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Lỗi: Không tìm thấy file {PROCESSED_DATA_PATH}. Vui lòng chạy các bước trước.\")\n",
        "        return None, None, None, None\n",
        "\n",
        "    # 2. Tạo đặc trưng đa quy mô bằng Wavelet\n",
        "    print(f\"-> Đang tạo đặc trưng đa quy mô với Wavelet (family: {WAVELET_FAMILY}, level: {WAVELET_LEVEL})...\")\n",
        "    multiscale_df = create_multiscale_features(df, WAVELET_FAMILY, WAVELET_LEVEL)\n",
        "\n",
        "    print(\"-> Đang chuẩn hóa dữ liệu (scaling)...\")\n",
        "    feature_scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "    scaled_features = feature_scaler.fit_transform(multiscale_df)\n",
        "\n",
        "    target_scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "    scaled_target = target_scaler.fit_transform(df[[TARGET_COLUMN]])\n",
        "\n",
        "    print(f\"-> Đang tạo các chuỗi tuần tự với lookback window = {LOOKBACK_WINDOW}...\")\n",
        "    X, y = create_sequences(scaled_features, scaled_target.flatten(), LOOKBACK_WINDOW)\n",
        "\n",
        "    split_index = int(len(X) * (1 - TEST_SET_SIZE))\n",
        "    X_train, X_test = X[:split_index], X[split_index:]\n",
        "    y_train, y_test = y[:split_index], y[split_index:]\n",
        "    print(f\"-> Kích thước tập Train: {len(X_train)} mẫu\")\n",
        "    print(f\"-> Kích thước tập Test: {len(X_test)} mẫu\")\n",
        "\n",
        "    # 6. Tạo các đối tượng Dataset và DataLoader của PyTorch\n",
        "    train_dataset = StockDataset(X_train, y_train)\n",
        "    test_dataset = StockDataset(X_test, y_test)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "    print(\"\\n✅ Hoàn tất việc tạo DataLoader.\")\n",
        "    return train_loader, test_loader, feature_scaler, target_scaler\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Cài đặt thư viện wavelet nếu chưa có\n",
        "    try:\n",
        "        import pywt\n",
        "    except ImportError:\n",
        "        print(\"Đang cài đặt thư viện PyWavelets...\")\n",
        "        import subprocess\n",
        "        import sys\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"PyWavelets\"])\n",
        "\n",
        "    # Chạy hàm chính để kiểm tra\n",
        "    train_loader, test_loader, _, target_scaler = get_data_loaders()\n",
        "\n",
        "    if train_loader:\n",
        "        # Kiểm tra một batch dữ liệu\n",
        "        features, labels = next(iter(train_loader))\n",
        "        print(\"\\n--- Kiểm tra một batch từ DataLoader ---\")\n",
        "        print(f\"Kích thước batch features (đầu vào): {features.shape}\")\n",
        "        print(\"==> [Số mẫu trong batch, Độ dài chuỗi (lookback), Số lượng đặc trưng]\")\n",
        "        print(f\"Kích thước batch labels (đầu ra): {labels.shape}\")\n",
        "\n",
        "        # In ra ví dụ về giá trị đã được chuẩn hóa\n",
        "        print(f\"\\nVí dụ giá trị label (đã chuẩn hóa): {labels[:5].flatten()}\")\n",
        "        # Sử dụng target_scaler để biến đổi ngược lại về giá trị gốc\n",
        "        original_labels = target_scaler.inverse_transform(labels.numpy().reshape(-1, 1))\n",
        "        print(f\"Ví dụ giá trị label (đã giải chuẩn hóa): \\n{original_labels[:5].flatten()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16wvTFBDFrma",
        "outputId": "5c19aa34-db3b-4e2d-f3d7-6ff1768e72f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing dataset.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python dataset.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PIpKTrPzHKtb",
        "outputId": "5bed9dd8-6256-418d-9c2e-fd6b0e176a45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bắt đầu quá trình tạo DataLoader...\n",
            "-> Đang tạo đặc trưng đa quy mô với Wavelet (family: db4, level: 4)...\n",
            "-> Đang chuẩn hóa dữ liệu (scaling)...\n",
            "-> Đang tạo các chuỗi tuần tự với lookback window = 30...\n",
            "-> Kích thước tập Train: 270 mẫu\n",
            "-> Kích thước tập Test: 68 mẫu\n",
            "\n",
            "✅ Hoàn tất việc tạo DataLoader.\n",
            "\n",
            "--- Kiểm tra một batch từ DataLoader ---\n",
            "Kích thước batch features (đầu vào): torch.Size([32, 30, 150])\n",
            "==> [Số mẫu trong batch, Độ dài chuỗi (lookback), Số lượng đặc trưng]\n",
            "Kích thước batch labels (đầu ra): torch.Size([32])\n",
            "\n",
            "Ví dụ giá trị label (đã chuẩn hóa): tensor([0.3987, 0.6804, 0.3341, 0.7571, 0.4149])\n",
            "Ví dụ giá trị label (đã giải chuẩn hóa): \n",
            "[1062.19 1168.4  1037.84 1197.33 1068.31]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile config.py\n",
        "# config.py\n",
        "\n",
        "# --- Đường dẫn file ---\n",
        "PROCESSED_DATA_PATH = 'vn_indices_processed.csv'\n",
        "TRAINED_MODEL_PATH = 'mslstm_model.pth' #lưu model\n",
        "\n",
        "# --- Tham số tạo Dataset ---\n",
        "LOOKBACK_WINDOW = 30\n",
        "TARGET_COLUMN = 'VNINDEX_Close'\n",
        "TEST_SET_SIZE = 0.2\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# --- Tham số Biến đổi Wavelet ---\n",
        "WAVELET_FAMILY = 'db4'\n",
        "WAVELET_LEVEL = 4\n",
        "\n",
        "# --- Tham số Kiến trúc Model ---\n",
        "# Số đặc trưng gốc\n",
        "# (OHLCV + 5 chỉ báo) * 3 chỉ số = 10 * 3 = 30\n",
        "NUM_BASE_FEATURES = 30\n",
        "# Số quy mô wavelet = level + 1 (số nhánh lstm)\n",
        "NUM_SCALES = WAVELET_LEVEL + 1\n",
        "\n",
        "# Các tham số cho lớp LSTM\n",
        "LSTM_HIDDEN_UNITS = 64 # Số unit trong mỗi cell LSTM\n",
        "LSTM_NUM_LAYERS = 2    # Số lớp LSTM chồng lên nhau trong mỗi nhánh\n",
        "\n",
        "LEARNING_RATE = 0.001\n",
        "NUM_EPOCHS = 50"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ACQ4DNXIsiW",
        "outputId": "e2ed30eb-f4ca-48c6-e593-5d94d142304f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting config.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bây giờ sẽ buld MS_LSTM baseline cơ bản"
      ],
      "metadata": {
        "id": "djnH3-w2Kz8i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile model.py\n",
        "# model.py\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from config import (\n",
        "    NUM_BASE_FEATURES, NUM_SCALES, LSTM_HIDDEN_UNITS, LSTM_NUM_LAYERS,\n",
        "    BATCH_SIZE, LOOKBACK_WINDOW\n",
        ")\n",
        "\n",
        "class MSLSTM(nn.Module):\n",
        "    def __init__(self, input_feature_size, num_scales, lstm_hidden_units, lstm_num_layers):\n",
        "        \"\"\"  Args:\n",
        "            input_feature_size (int): Số đặc trưng cho mỗi quy mô (nhánh).\n",
        "            num_scales (int): Số lượng quy mô song song (số nhánh LSTM).\n",
        "            lstm_hidden_units (int): Số unit ẩn trong mỗi LSTM.\n",
        "            lstm_num_layers (int): Số lớp trong mỗi LSTM.\n",
        "        \"\"\"\n",
        "        super(MSLSTM, self).__init__()\n",
        "\n",
        "        self.num_scales = num_scales\n",
        "        self.input_feature_size = input_feature_size\n",
        "\n",
        "        # Tạo ra một danh sách các nhánh LSTM song song\n",
        "        # Mỗi nhánh là một mạng LSTM độc lập\n",
        "        self.lstm_branches = nn.ModuleList([\n",
        "            nn.LSTM(\n",
        "                input_size=input_feature_size,\n",
        "                hidden_size=lstm_hidden_units,\n",
        "                num_layers=lstm_num_layers,\n",
        "                batch_first=True, # Định dạng input: (batch, seq_len, features)\n",
        "                dropout=0.2 if lstm_num_layers > 1 else 0 # Thêm dropout nếu có nhiều lớp\n",
        "            ) for _ in range(num_scales)\n",
        "        ])\n",
        "\n",
        "        # Lớp Fully Connected cuối cùng để hợp nhất kết quả từ các nhánh\n",
        "        # và đưa ra dự báo cuối cùng.\n",
        "        # Đầu vào của nó là tổng số unit ẩn từ tất cả các nhánh\n",
        "        self.fc = nn.Linear(in_features=lstm_hidden_units * num_scales, out_features=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Định nghĩa luồng dữ liệu đi qua model.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Tensor đầu vào với shape [batch_size, lookback_window, total_features]\n",
        "                               Trong đó total_features = input_feature_size * num_scales\n",
        "        \"\"\"\n",
        "        # Danh sách để lưu trữ đầu ra từ mỗi nhánh LSTM\n",
        "        lstm_outputs = []\n",
        "\n",
        "        # Tách dữ liệu đầu vào và đưa vào từng nhánh LSTM tương ứng\n",
        "        for i in range(self.num_scales):\n",
        "            # Tách ra phần dữ liệu cho nhánh thứ i\n",
        "            start_idx = i * self.input_feature_size\n",
        "            end_idx = (i + 1) * self.input_feature_size\n",
        "\n",
        "            branch_input = x[:, :, start_idx:end_idx]\n",
        "\n",
        "            # Đưa dữ liệu qua nhánh LSTM thứ i\n",
        "            # Chúng ta chỉ cần đầu ra cuối cùng của chuỗi (hidden_state)\n",
        "            _, (hn, _) = self.lstm_branches[i](branch_input)\n",
        "\n",
        "            # Lấy hidden state của lớp cuối cùng\n",
        "            # Shape của hn là [num_layers, batch_size, hidden_units]\n",
        "            # Lấy output của layer cuối cùng: hn[-1]\n",
        "            lstm_outputs.append(hn[-1])\n",
        "\n",
        "        # Concatenate các đầu ra từ tất cả các nhánh lại với nhau\n",
        "        # Shape sẽ là [batch_size, lstm_hidden_units * num_scales]\n",
        "        concatenated_output = torch.cat(lstm_outputs, dim=1)\n",
        "\n",
        "        # Đưa qua lớp fully connected để có dự báo cuối cùng\n",
        "        final_prediction = self.fc(concatenated_output)\n",
        "\n",
        "        return final_prediction.squeeze() # Trả về tensor 1 chiều\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    print(\"--- Kiểm tra kiến trúc MS-LSTM ---\")\n",
        "\n",
        "    # Dữ liệu giả lập\n",
        "    batch_size = BATCH_SIZE\n",
        "    lookback = LOOKBACK_WINDOW\n",
        "    total_features = NUM_BASE_FEATURES * NUM_SCALES\n",
        "    dummy_input = torch.randn(batch_size, lookback, total_features)\n",
        "\n",
        "    # Khởi tạo model\n",
        "    model = MSLSTM(\n",
        "        input_feature_size=NUM_BASE_FEATURES,\n",
        "        num_scales=NUM_SCALES,\n",
        "        lstm_hidden_units=LSTM_HIDDEN_UNITS,\n",
        "        lstm_num_layers=LSTM_NUM_LAYERS\n",
        "    )\n",
        "\n",
        "    # In ra kiến trúc model\n",
        "    print(model)\n",
        "\n",
        "    # Đưa dữ liệu giả qua model\n",
        "    output = model(dummy_input)\n",
        "\n",
        "    # Kiểm tra shape của đầu ra\n",
        "    print(f\"\\nShape của input giả: {dummy_input.shape}\")\n",
        "    print(f\"Shape của output: {output.shape}\")\n",
        "    print(f\"==> Shape mong muốn là [{batch_size}], kết quả: {output.shape[0] == batch_size}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mI_4Xmc4K_Ym",
        "outputId": "ad4fffb0-57f5-4952-bb0d-8704fa151d2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting model.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python model.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBZ3u6UXLyhj",
        "outputId": "ac02eba5-81a7-4e4f-83a2-f25eb2117621"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Kiểm tra kiến trúc MS-LSTM ---\n",
            "MSLSTM(\n",
            "  (lstm_branches): ModuleList(\n",
            "    (0-4): 5 x LSTM(30, 64, num_layers=2, batch_first=True, dropout=0.2)\n",
            "  )\n",
            "  (fc): Linear(in_features=320, out_features=1, bias=True)\n",
            ")\n",
            "\n",
            "Shape của input giả: torch.Size([32, 30, 150])\n",
            "Shape của output: torch.Size([32])\n",
            "==> Shape mong muốn là [32], kết quả: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train"
      ],
      "metadata": {
        "id": "9KCGLAMnON9g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile train.py\n",
        "# train.py\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "from config import (\n",
        "    NUM_BASE_FEATURES, NUM_SCALES, LSTM_HIDDEN_UNITS, LSTM_NUM_LAYERS,\n",
        "    LEARNING_RATE, NUM_EPOCHS, TRAINED_MODEL_PATH\n",
        ")\n",
        "from dataset import get_data_loaders\n",
        "from model import MSLSTM\n",
        "\n",
        "def run_training():\n",
        "    \"\"\"Hàm chính để thực hiện toàn bộ quá trình huấn luyện.\"\"\"\n",
        "\n",
        "    # 0. Thiết lập môi trường\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    print(f\"Sử dụng thiết bị: {device.upper()}\")\n",
        "\n",
        "    # 1. Tải dữ liệu (Lấy cả train và test loader)\n",
        "    train_loader, test_loader, _, _ = get_data_loaders()\n",
        "    if not train_loader:\n",
        "        print(\"Dừng chương trình vì không tải được dữ liệu.\")\n",
        "        return\n",
        "\n",
        "    # 2. Khởi tạo Model, Loss, Optimizer\n",
        "    model = MSLSTM(\n",
        "        input_feature_size=NUM_BASE_FEATURES,\n",
        "        num_scales=NUM_SCALES,\n",
        "        lstm_hidden_units=LSTM_HIDDEN_UNITS,\n",
        "        lstm_num_layers=LSTM_NUM_LAYERS\n",
        "    ).to(device)\n",
        "\n",
        "    loss_function = nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "    # 3. Vòng lặp huấn luyện\n",
        "    print(\"\\n--- Bắt đầu Huấn luyện ---\")\n",
        "    best_val_loss = float('inf') # Biến để lưu val_loss tốt nhất\n",
        "\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        # --- PHA HUẤN LUYỆN (TRAINING PHASE) ---\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        # Sử dụng tqdm cho đẹp\n",
        "        for features, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS} [Train]\"):\n",
        "            features, labels = features.to(device), labels.to(device)\n",
        "            outputs = model(features)\n",
        "            loss = loss_function(outputs, labels)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        # --- PHA KIỂM ĐỊNH (VALIDATION PHASE) ---\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for features, labels in tqdm(test_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS} [Valid]\"):\n",
        "                features, labels = features.to(device), labels.to(device)\n",
        "                outputs = model(features)\n",
        "                loss = loss_function(outputs, labels)\n",
        "                val_loss += loss.item()\n",
        "\n",
        "        # --- IN KẾT QUẢ VÀ LƯU MODEL TỐT NHẤT ---\n",
        "        avg_train_loss = train_loss / len(train_loader)\n",
        "        avg_val_loss = val_loss / len(test_loader)\n",
        "\n",
        "        print(f\"Epoch [{epoch+1:02d}/{NUM_EPOCHS}] | Train Loss: {avg_train_loss:.6f} | Validation Loss: {avg_val_loss:.6f}\")\n",
        "\n",
        "        # Chỉ lưu model nếu validation loss của epoch này tốt hơn các epoch trước\n",
        "        if avg_val_loss < best_val_loss:\n",
        "            best_val_loss = avg_val_loss\n",
        "            torch.save(model.state_dict(), TRAINED_MODEL_PATH)\n",
        "            print(f\"   -> Validation loss cải thiện. Đã lưu model tốt nhất vào '{TRAINED_MODEL_PATH}'\")\n",
        "\n",
        "\n",
        "    print(f\"\\n--- Huấn luyện Hoàn tất ---\")\n",
        "    print(f\"✅ Model tốt nhất đã được lưu tại epoch có Validation Loss = {best_val_loss:.6f}\")\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    run_training()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JPUsi8rIOSit",
        "outputId": "d271c886-3a8e-4df5-ca66-fe1ad8b84133"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing train.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60TNNbfZPptX",
        "outputId": "8bccf9fc-3ef5-476d-89eb-fc8c54868fa3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/content/train.py\", line 12, in <module>\n",
            "    from dataset import get_data_loaders\n",
            "ModuleNotFoundError: No module named 'dataset'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bây giờ sẽ chạy evaluate"
      ],
      "metadata": {
        "id": "Ru9APmOkRa5U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile evaluate.py\n",
        "# evaluate.py\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from config import (\n",
        "    NUM_BASE_FEATURES, NUM_SCALES, LSTM_HIDDEN_UNITS, LSTM_NUM_LAYERS,\n",
        "    TRAINED_MODEL_PATH\n",
        ")\n",
        "from dataset import get_data_loaders\n",
        "from model import MSLSTM\n",
        "\n",
        "def run_evaluation():\n",
        "    \"\"\"Hàm chính để đánh giá mô hình trên tập test.\"\"\"\n",
        "\n",
        "    # 0. Thiết lập môi trường\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    print(f\"Sử dụng thiết bị: {device.upper()}\")\n",
        "\n",
        "    # 1. Tải dữ liệu (chỉ cần test_loader và scaler)\n",
        "    _, test_loader, _, target_scaler = get_data_loaders()\n",
        "    if not test_loader:\n",
        "        print(\"Dừng chương trình vì không tải được dữ liệu.\")\n",
        "        return\n",
        "\n",
        "    # 2. Tải lại mô hình đã huấn luyện\n",
        "    print(f\"Đang tải mô hình từ: {TRAINED_MODEL_PATH}\")\n",
        "    model = MSLSTM(\n",
        "        input_feature_size=NUM_BASE_FEATURES,\n",
        "        num_scales=NUM_SCALES,\n",
        "        lstm_hidden_units=LSTM_HIDDEN_UNITS,\n",
        "        lstm_num_layers=LSTM_NUM_LAYERS\n",
        "    )\n",
        "    try:\n",
        "        model.load_state_dict(torch.load(TRAINED_MODEL_PATH, map_location=device))\n",
        "        model.to(device)\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Lỗi: Không tìm thấy file model tại '{TRAINED_MODEL_PATH}'.\")\n",
        "        print(\"Vui lòng chạy train.py trước.\")\n",
        "        return\n",
        "\n",
        "    # 3. Đánh giá trên tập Test\n",
        "    model.eval()\n",
        "    predictions, actuals = [], []\n",
        "    with torch.no_grad():\n",
        "        for features, labels in test_loader:\n",
        "            features, labels = features.to(device), labels.to(device)\n",
        "            outputs = model(features)\n",
        "\n",
        "            predictions.extend(outputs.cpu().numpy())\n",
        "            actuals.extend(labels.cpu().numpy())\n",
        "\n",
        "    # 4. Giải chuẩn hóa để so sánh\n",
        "    predictions = np.array(predictions).reshape(-1, 1)\n",
        "    actuals = np.array(actuals).reshape(-1, 1)\n",
        "\n",
        "    original_predictions = target_scaler.inverse_transform(predictions)\n",
        "    original_actuals = target_scaler.inverse_transform(actuals)\n",
        "\n",
        "    # 5. Tính toán sai số và in kết quả\n",
        "    mae = np.mean(np.abs(original_predictions - original_actuals))\n",
        "    print(f\"\\n--- Kết quả Đánh giá trên Tập Test ---\")\n",
        "    print(f\"Sai số Trung bình Tuyệt đối (MAE): {mae:.4f} (điểm VN-Index)\")\n",
        "\n",
        "    # 6. Vẽ biểu đồ so sánh\n",
        "    plt.figure(figsize=(15, 6))\n",
        "    plt.plot(original_actuals, label='Giá trị Thực tế (Actuals)', color='blue', marker='.', linestyle='-')\n",
        "    plt.plot(original_predictions, label='Giá trị Dự đoán (Predictions)', color='red', linestyle='--')\n",
        "    plt.title('So sánh Giá trị Thực tế và Dự đoán trên Tập Test')\n",
        "    plt.xlabel('Ngày (trong tập Test)')\n",
        "    plt.ylabel('Giá đóng cửa VN-Index')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    output_image_path = 'prediction_vs_actual.png'\n",
        "    plt.savefig(output_image_path)\n",
        "    print(f\"✅ Đã lưu biểu đồ so sánh vào file '{output_image_path}'\")\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    run_evaluation()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZxU9jyVRi1W",
        "outputId": "16cd51dd-cfec-43c9-aebc-9188ef43fd51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing evaluate.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python evaluate.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HkjYoJ6lRkUy",
        "outputId": "4653fdde-5356-4f14-d75a-9e6aa03bed06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sử dụng thiết bị: CUDA\n",
            "Bắt đầu quá trình tạo DataLoader...\n",
            "-> Đang tạo đặc trưng đa quy mô với Wavelet (family: db4, level: 4)...\n",
            "-> Đang chuẩn hóa dữ liệu (scaling)...\n",
            "-> Đang tạo các chuỗi tuần tự với lookback window = 30...\n",
            "-> Kích thước tập Train: 270 mẫu\n",
            "-> Kích thước tập Test: 68 mẫu\n",
            "\n",
            "✅ Hoàn tất việc tạo DataLoader.\n",
            "Đang tải mô hình từ: mslstm_model.pth\n",
            "\n",
            "--- Kết quả Đánh giá trên Tập Test ---\n",
            "Sai số Trung bình Tuyệt đối (MAE): 20.1838 (điểm VN-Index)\n",
            "✅ Đã lưu biểu đồ so sánh vào file 'prediction_vs_actual.png'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bây giờ test tích hợp cơ chế Chú ý Đa đầu (Multi-Head Attention)."
      ],
      "metadata": {
        "id": "ahNvmKT9T1f6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile config.py\n",
        "# config.py\n",
        "\n",
        "# --- Đường dẫn file ---\n",
        "PROCESSED_DATA_PATH = 'vn_indices_processed.csv'\n",
        "TRAINED_MODEL_PATH = 'mslstm_attention_model.pth' # Đổi tên file model mới\n",
        "\n",
        "# --- Tham số tạo Dataset ---\n",
        "LOOKBACK_WINDOW = 30\n",
        "TARGET_COLUMN = 'VNINDEX_Close'\n",
        "TEST_SET_SIZE = 0.2\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# --- Tham số Biến đổi Wavelet ---\n",
        "WAVELET_FAMILY = 'db4'\n",
        "WAVELET_LEVEL = 4\n",
        "\n",
        "# --- Tham số Kiến trúc Model ---\n",
        "NUM_BASE_FEATURES = 30\n",
        "NUM_SCALES = WAVELET_LEVEL + 1\n",
        "LSTM_HIDDEN_UNITS = 64\n",
        "LSTM_NUM_LAYERS = 2\n",
        "# --- THAM SỐ MỚI CHO ATTENTION ---\n",
        "ATTENTION_NUM_HEADS = 4 # Số \"đầu\" chú ý\n",
        "\n",
        "# --- Tham số Huấn luyện ---\n",
        "LEARNING_RATE = 0.001\n",
        "NUM_EPOCHS = 50"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSAynKxwUGER",
        "outputId": "253fce6f-2eea-4d87-d2df-dad66be23899"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting config.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " ***MS-LSTM + Attention***"
      ],
      "metadata": {
        "id": "WuezT0kMUNQn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile model.py\n",
        "# model.py\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from config import (\n",
        "    NUM_BASE_FEATURES, NUM_SCALES, LSTM_HIDDEN_UNITS, LSTM_NUM_LAYERS,\n",
        "    BATCH_SIZE, LOOKBACK_WINDOW, ATTENTION_NUM_HEADS\n",
        ")\n",
        "\n",
        "class MSLSTMAttention(nn.Module):\n",
        "    def __init__(self, input_feature_size, num_scales, lstm_hidden_units, lstm_num_layers, num_heads):\n",
        "        super(MSLSTMAttention, self).__init__()\n",
        "\n",
        "        self.num_scales = num_scales\n",
        "        self.input_feature_size = input_feature_size\n",
        "        self.lstm_hidden_units = lstm_hidden_units\n",
        "\n",
        "        # 1. Các nhánh LSTM song song (Không đổi)\n",
        "        self.lstm_branches = nn.ModuleList([\n",
        "            nn.LSTM(\n",
        "                input_size=input_feature_size,\n",
        "                hidden_size=lstm_hidden_units,\n",
        "                num_layers=lstm_num_layers,\n",
        "                batch_first=True,\n",
        "                dropout=0.2 if lstm_num_layers > 1 else 0\n",
        "            ) for _ in range(num_scales)\n",
        "        ])\n",
        "\n",
        "        # 2. Lớp Chú ý Đa đầu (Multi-Head Attention)\n",
        "        # Nó sẽ nhận đầu vào từ các nhánh LSTM đã được ghép lại\n",
        "        self.attention = nn.MultiheadAttention(\n",
        "            embed_dim=lstm_hidden_units * num_scales, # Tổng kích thước đầu vào\n",
        "            num_heads=num_heads,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "        # 3. Lớp Fully Connected cuối cùng\n",
        "        # Đầu vào của nó vẫn là output từ lớp Attention\n",
        "        self.fc = nn.Linear(in_features=lstm_hidden_units * num_scales, out_features=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Danh sách để lưu trữ đầu ra từ mỗi nhánh LSTM\n",
        "        # Lần này chúng ta cần toàn bộ chuỗi đầu ra (output), không chỉ hidden state cuối\n",
        "        branch_outputs = []\n",
        "\n",
        "        for i in range(self.num_scales):\n",
        "            branch_input = x[:, :, i*self.input_feature_size : (i+1)*self.input_feature_size]\n",
        "\n",
        "            # output shape: [batch_size, seq_len, hidden_units]\n",
        "            output, _ = self.lstm_branches[i](branch_input)\n",
        "            branch_outputs.append(output)\n",
        "\n",
        "        # Ghép (concatenate) các chuỗi đầu ra từ tất cả các nhánh\n",
        "        # Shape: [batch_size, seq_len, lstm_hidden_units * num_scales]\n",
        "        concatenated_output = torch.cat(branch_outputs, dim=2)\n",
        "\n",
        "        # Đưa qua lớp Multi-Head Attention\n",
        "        # Query, Key, Value đều là concatenated_output (self-attention)\n",
        "        attention_output, _ = self.attention(concatenated_output, concatenated_output, concatenated_output)\n",
        "\n",
        "        # Ta chỉ lấy vector cuối cùng của chuỗi sau khi qua attention để dự báo\n",
        "        # Shape: [batch_size, lstm_hidden_units * num_scales]\n",
        "        last_time_step_output = attention_output[:, -1, :]\n",
        "\n",
        "        # Đưa qua lớp fully connected để có dự báo cuối cùng\n",
        "        final_prediction = self.fc(last_time_step_output)\n",
        "\n",
        "        return final_prediction.squeeze()\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Đoạn code kiểm tra kiến trúc model mới\n",
        "    print(\"--- Kiểm tra kiến trúc MS-LSTM + Attention ---\")\n",
        "    model = MSLSTMAttention(\n",
        "        input_feature_size=NUM_BASE_FEATURES,\n",
        "        num_scales=NUM_SCALES,\n",
        "        lstm_hidden_units=LSTM_HIDDEN_UNITS,\n",
        "        lstm_num_layers=LSTM_NUM_LAYERS,\n",
        "        num_heads=ATTENTION_NUM_HEADS\n",
        "    )\n",
        "    print(model)\n",
        "    dummy_input = torch.randn(BATCH_SIZE, LOOKBACK_WINDOW, NUM_BASE_FEATURES * NUM_SCALES)\n",
        "    output = model(dummy_input)\n",
        "    print(f\"\\nShape của input giả: {dummy_input.shape}\")\n",
        "    print(f\"Shape của output: {output.shape}\")\n",
        "    print(f\"==> Shape mong muốn là [{BATCH_SIZE}], kết quả: {output.shape[0] == BATCH_SIZE}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DgnF98gUUEV",
        "outputId": "7ef5d01d-2e21-4ffc-b78e-dc177c773454"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting model.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python model.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMESaAZeUiYg",
        "outputId": "65b23cf0-aacf-4118-c684-15a2f59e28af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Kiểm tra kiến trúc MS-LSTM + Attention ---\n",
            "MSLSTMAttention(\n",
            "  (lstm_branches): ModuleList(\n",
            "    (0-4): 5 x LSTM(30, 64, num_layers=2, batch_first=True, dropout=0.2)\n",
            "  )\n",
            "  (attention): MultiheadAttention(\n",
            "    (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
            "  )\n",
            "  (fc): Linear(in_features=320, out_features=1, bias=True)\n",
            ")\n",
            "\n",
            "Shape của input giả: torch.Size([32, 30, 150])\n",
            "Shape của output: torch.Size([32])\n",
            "==> Shape mong muốn là [32], kết quả: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile train.py\n",
        "# train.py\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "from config import (\n",
        "    NUM_BASE_FEATURES, NUM_SCALES, LSTM_HIDDEN_UNITS, LSTM_NUM_LAYERS,\n",
        "    ATTENTION_NUM_HEADS, # Thêm tham số attention\n",
        "    LEARNING_RATE, NUM_EPOCHS, TRAINED_MODEL_PATH\n",
        ")\n",
        "# Sửa đổi: import model mới\n",
        "from model import MSLSTMAttention\n",
        "from dataset import get_data_loaders\n",
        "\n",
        "\n",
        "def run_training():\n",
        "    \"\"\"Hàm chính để thực hiện toàn bộ quá trình huấn luyện.\"\"\"\n",
        "\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    print(f\"Sử dụng thiết bị: {device.upper()}\")\n",
        "\n",
        "    train_loader, test_loader, _, _ = get_data_loaders()\n",
        "    if not train_loader:\n",
        "        print(\"Dừng chương trình vì không tải được dữ liệu.\")\n",
        "        return\n",
        "\n",
        "    #Khởi tạo model MSLSTMAttention mới\n",
        "    model = MSLSTMAttention(\n",
        "        input_feature_size=NUM_BASE_FEATURES,\n",
        "        num_scales=NUM_SCALES,\n",
        "        lstm_hidden_units=LSTM_HIDDEN_UNITS,\n",
        "        lstm_num_layers=LSTM_NUM_LAYERS,\n",
        "        num_heads=ATTENTION_NUM_HEADS\n",
        "    ).to(device)\n",
        "\n",
        "    loss_function = nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "    print(\"\\n--- Bắt đầu Huấn luyện Model MS-LSTM + Attention ---\")\n",
        "    best_val_loss = float('inf')\n",
        "\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        for features, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS} [Train]\"):\n",
        "            features, labels = features.to(device), labels.to(device)\n",
        "            outputs = model(features)\n",
        "            loss = loss_function(outputs, labels)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for features, labels in tqdm(test_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS} [Valid]\"):\n",
        "                features, labels = features.to(device), labels.to(device)\n",
        "                outputs = model(features)\n",
        "                loss = loss_function(outputs, labels)\n",
        "                val_loss += loss.item()\n",
        "\n",
        "        avg_train_loss = train_loss / len(train_loader)\n",
        "        avg_val_loss = val_loss / len(test_loader)\n",
        "\n",
        "        print(f\"Epoch [{epoch+1:02d}/{NUM_EPOCHS}] | Train Loss: {avg_train_loss:.6f} | Validation Loss: {avg_val_loss:.6f}\")\n",
        "\n",
        "        if avg_val_loss < best_val_loss:\n",
        "            best_val_loss = avg_val_loss\n",
        "            torch.save(model.state_dict(), TRAINED_MODEL_PATH)\n",
        "            print(f\"   -> Validation loss cải thiện. Đã lưu model tốt nhất vào '{TRAINED_MODEL_PATH}'\")\n",
        "\n",
        "    print(f\"\\n--- Huấn luyện Hoàn tất ---\")\n",
        "    print(f\"✅ Model (Attention) tốt nhất đã được lưu tại epoch có Validation Loss = {best_val_loss:.6f}\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    run_training()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_Z6cu1eVHqa",
        "outputId": "0784e369-0a1a-43d9-d222-5f8d487e7595"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting train.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PvOUn90uVNT7",
        "outputId": "1f965882-f201-438c-cb4a-1f157bd4c57b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sử dụng thiết bị: CUDA\n",
            "Bắt đầu quá trình tạo DataLoader...\n",
            "-> Đang tạo đặc trưng đa quy mô với Wavelet (family: db4, level: 4)...\n",
            "-> Đang chuẩn hóa dữ liệu (scaling)...\n",
            "-> Đang tạo các chuỗi tuần tự với lookback window = 30...\n",
            "-> Kích thước tập Train: 270 mẫu\n",
            "-> Kích thước tập Test: 68 mẫu\n",
            "\n",
            "✅ Hoàn tất việc tạo DataLoader.\n",
            "\n",
            "--- Bắt đầu Huấn luyện Model MS-LSTM + Attention ---\n",
            "Epoch 1/50 [Train]: 100% 9/9 [00:00<00:00, 19.58it/s]\n",
            "Epoch 1/50 [Valid]: 100% 3/3 [00:00<00:00, 56.81it/s]\n",
            "Epoch [01/50] | Train Loss: 0.121739 | Validation Loss: 0.069954\n",
            "   -> Validation loss cải thiện. Đã lưu model tốt nhất vào 'mslstm_attention_model.pth'\n",
            "Epoch 2/50 [Train]: 100% 9/9 [00:00<00:00, 71.69it/s]\n",
            "Epoch 2/50 [Valid]: 100% 3/3 [00:00<00:00, 308.01it/s]\n",
            "Epoch [02/50] | Train Loss: 0.060295 | Validation Loss: 0.007198\n",
            "   -> Validation loss cải thiện. Đã lưu model tốt nhất vào 'mslstm_attention_model.pth'\n",
            "Epoch 3/50 [Train]: 100% 9/9 [00:00<00:00, 72.17it/s]\n",
            "Epoch 3/50 [Valid]: 100% 3/3 [00:00<00:00, 314.75it/s]\n",
            "Epoch [03/50] | Train Loss: 0.044625 | Validation Loss: 0.005162\n",
            "   -> Validation loss cải thiện. Đã lưu model tốt nhất vào 'mslstm_attention_model.pth'\n",
            "Epoch 4/50 [Train]: 100% 9/9 [00:00<00:00, 59.06it/s]\n",
            "Epoch 4/50 [Valid]: 100% 3/3 [00:00<00:00, 327.27it/s]\n",
            "Epoch [04/50] | Train Loss: 0.038087 | Validation Loss: 0.009235\n",
            "Epoch 5/50 [Train]: 100% 9/9 [00:00<00:00, 76.79it/s]\n",
            "Epoch 5/50 [Valid]: 100% 3/3 [00:00<00:00, 330.72it/s]\n",
            "Epoch [05/50] | Train Loss: 0.037213 | Validation Loss: 0.009940\n",
            "Epoch 6/50 [Train]: 100% 9/9 [00:00<00:00, 72.89it/s]\n",
            "Epoch 6/50 [Valid]: 100% 3/3 [00:00<00:00, 296.20it/s]\n",
            "Epoch [06/50] | Train Loss: 0.036943 | Validation Loss: 0.005199\n",
            "Epoch 7/50 [Train]: 100% 9/9 [00:00<00:00, 72.72it/s]\n",
            "Epoch 7/50 [Valid]: 100% 3/3 [00:00<00:00, 285.12it/s]\n",
            "Epoch [07/50] | Train Loss: 0.038063 | Validation Loss: 0.010852\n",
            "Epoch 8/50 [Train]: 100% 9/9 [00:00<00:00, 63.16it/s]\n",
            "Epoch 8/50 [Valid]: 100% 3/3 [00:00<00:00, 238.72it/s]\n",
            "Epoch [08/50] | Train Loss: 0.035196 | Validation Loss: 0.015178\n",
            "Epoch 9/50 [Train]: 100% 9/9 [00:00<00:00, 64.52it/s]\n",
            "Epoch 9/50 [Valid]: 100% 3/3 [00:00<00:00, 304.32it/s]\n",
            "Epoch [09/50] | Train Loss: 0.039936 | Validation Loss: 0.005516\n",
            "Epoch 10/50 [Train]: 100% 9/9 [00:00<00:00, 65.89it/s]\n",
            "Epoch 10/50 [Valid]: 100% 3/3 [00:00<00:00, 258.15it/s]\n",
            "Epoch [10/50] | Train Loss: 0.038311 | Validation Loss: 0.012636\n",
            "Epoch 11/50 [Train]: 100% 9/9 [00:00<00:00, 55.23it/s]\n",
            "Epoch 11/50 [Valid]: 100% 3/3 [00:00<00:00, 266.96it/s]\n",
            "Epoch [11/50] | Train Loss: 0.038709 | Validation Loss: 0.004639\n",
            "   -> Validation loss cải thiện. Đã lưu model tốt nhất vào 'mslstm_attention_model.pth'\n",
            "Epoch 12/50 [Train]: 100% 9/9 [00:00<00:00, 62.44it/s]\n",
            "Epoch 12/50 [Valid]: 100% 3/3 [00:00<00:00, 254.37it/s]\n",
            "Epoch [12/50] | Train Loss: 0.040524 | Validation Loss: 0.004308\n",
            "   -> Validation loss cải thiện. Đã lưu model tốt nhất vào 'mslstm_attention_model.pth'\n",
            "Epoch 13/50 [Train]: 100% 9/9 [00:00<00:00, 93.57it/s]\n",
            "Epoch 13/50 [Valid]: 100% 3/3 [00:00<00:00, 370.64it/s]\n",
            "Epoch [13/50] | Train Loss: 0.043210 | Validation Loss: 0.022547\n",
            "Epoch 14/50 [Train]: 100% 9/9 [00:00<00:00, 90.52it/s]\n",
            "Epoch 14/50 [Valid]: 100% 3/3 [00:00<00:00, 405.03it/s]\n",
            "Epoch [14/50] | Train Loss: 0.041569 | Validation Loss: 0.018454\n",
            "Epoch 15/50 [Train]: 100% 9/9 [00:00<00:00, 110.44it/s]\n",
            "Epoch 15/50 [Valid]: 100% 3/3 [00:00<00:00, 310.03it/s]\n",
            "Epoch [15/50] | Train Loss: 0.043210 | Validation Loss: 0.004447\n",
            "Epoch 16/50 [Train]: 100% 9/9 [00:00<00:00, 97.56it/s]\n",
            "Epoch 16/50 [Valid]: 100% 3/3 [00:00<00:00, 412.14it/s]\n",
            "Epoch [16/50] | Train Loss: 0.041268 | Validation Loss: 0.004071\n",
            "   -> Validation loss cải thiện. Đã lưu model tốt nhất vào 'mslstm_attention_model.pth'\n",
            "Epoch 17/50 [Train]: 100% 9/9 [00:00<00:00, 108.87it/s]\n",
            "Epoch 17/50 [Valid]: 100% 3/3 [00:00<00:00, 266.23it/s]\n",
            "Epoch [17/50] | Train Loss: 0.037797 | Validation Loss: 0.019599\n",
            "Epoch 18/50 [Train]: 100% 9/9 [00:00<00:00, 107.26it/s]\n",
            "Epoch 18/50 [Valid]: 100% 3/3 [00:00<00:00, 412.46it/s]\n",
            "Epoch [18/50] | Train Loss: 0.038907 | Validation Loss: 0.012615\n",
            "Epoch 19/50 [Train]: 100% 9/9 [00:00<00:00, 107.39it/s]\n",
            "Epoch 19/50 [Valid]: 100% 3/3 [00:00<00:00, 425.27it/s]\n",
            "Epoch [19/50] | Train Loss: 0.035819 | Validation Loss: 0.006886\n",
            "Epoch 20/50 [Train]: 100% 9/9 [00:00<00:00, 107.11it/s]\n",
            "Epoch 20/50 [Valid]: 100% 3/3 [00:00<00:00, 395.12it/s]\n",
            "Epoch [20/50] | Train Loss: 0.038219 | Validation Loss: 0.017881\n",
            "Epoch 21/50 [Train]: 100% 9/9 [00:00<00:00, 99.12it/s]\n",
            "Epoch 21/50 [Valid]: 100% 3/3 [00:00<00:00, 388.90it/s]\n",
            "Epoch [21/50] | Train Loss: 0.037392 | Validation Loss: 0.008938\n",
            "Epoch 22/50 [Train]: 100% 9/9 [00:00<00:00, 107.29it/s]\n",
            "Epoch 22/50 [Valid]: 100% 3/3 [00:00<00:00, 392.75it/s]\n",
            "Epoch [22/50] | Train Loss: 0.037610 | Validation Loss: 0.004370\n",
            "Epoch 23/50 [Train]: 100% 9/9 [00:00<00:00, 106.43it/s]\n",
            "Epoch 23/50 [Valid]: 100% 3/3 [00:00<00:00, 413.65it/s]\n",
            "Epoch [23/50] | Train Loss: 0.036415 | Validation Loss: 0.015123\n",
            "Epoch 24/50 [Train]: 100% 9/9 [00:00<00:00, 104.43it/s]\n",
            "Epoch 24/50 [Valid]: 100% 3/3 [00:00<00:00, 407.72it/s]\n",
            "Epoch [24/50] | Train Loss: 0.037440 | Validation Loss: 0.012695\n",
            "Epoch 25/50 [Train]: 100% 9/9 [00:00<00:00, 100.17it/s]\n",
            "Epoch 25/50 [Valid]: 100% 3/3 [00:00<00:00, 357.68it/s]\n",
            "Epoch [25/50] | Train Loss: 0.036915 | Validation Loss: 0.010367\n",
            "Epoch 26/50 [Train]: 100% 9/9 [00:00<00:00, 83.62it/s]\n",
            "Epoch 26/50 [Valid]: 100% 3/3 [00:00<00:00, 259.62it/s]\n",
            "Epoch [26/50] | Train Loss: 0.038865 | Validation Loss: 0.006366\n",
            "Epoch 27/50 [Train]: 100% 9/9 [00:00<00:00, 99.41it/s]\n",
            "Epoch 27/50 [Valid]: 100% 3/3 [00:00<00:00, 427.70it/s]\n",
            "Epoch [27/50] | Train Loss: 0.035979 | Validation Loss: 0.006176\n",
            "Epoch 28/50 [Train]: 100% 9/9 [00:00<00:00, 107.11it/s]\n",
            "Epoch 28/50 [Valid]: 100% 3/3 [00:00<00:00, 427.29it/s]\n",
            "Epoch [28/50] | Train Loss: 0.035361 | Validation Loss: 0.016217\n",
            "Epoch 29/50 [Train]: 100% 9/9 [00:00<00:00, 103.96it/s]\n",
            "Epoch 29/50 [Valid]: 100% 3/3 [00:00<00:00, 423.05it/s]\n",
            "Epoch [29/50] | Train Loss: 0.036157 | Validation Loss: 0.004897\n",
            "Epoch 30/50 [Train]: 100% 9/9 [00:00<00:00, 72.16it/s]\n",
            "Epoch 30/50 [Valid]: 100% 3/3 [00:00<00:00, 416.20it/s]\n",
            "Epoch [30/50] | Train Loss: 0.036940 | Validation Loss: 0.011907\n",
            "Epoch 31/50 [Train]: 100% 9/9 [00:00<00:00, 103.76it/s]\n",
            "Epoch 31/50 [Valid]: 100% 3/3 [00:00<00:00, 419.71it/s]\n",
            "Epoch [31/50] | Train Loss: 0.036750 | Validation Loss: 0.007819\n",
            "Epoch 32/50 [Train]: 100% 9/9 [00:00<00:00, 107.63it/s]\n",
            "Epoch 32/50 [Valid]: 100% 3/3 [00:00<00:00, 393.06it/s]\n",
            "Epoch [32/50] | Train Loss: 0.037632 | Validation Loss: 0.017556\n",
            "Epoch 33/50 [Train]: 100% 9/9 [00:00<00:00, 106.21it/s]\n",
            "Epoch 33/50 [Valid]: 100% 3/3 [00:00<00:00, 402.01it/s]\n",
            "Epoch [33/50] | Train Loss: 0.038912 | Validation Loss: 0.015610\n",
            "Epoch 34/50 [Train]: 100% 9/9 [00:00<00:00, 105.94it/s]\n",
            "Epoch 34/50 [Valid]: 100% 3/3 [00:00<00:00, 410.83it/s]\n",
            "Epoch [34/50] | Train Loss: 0.037242 | Validation Loss: 0.008161\n",
            "Epoch 35/50 [Train]: 100% 9/9 [00:00<00:00, 101.47it/s]\n",
            "Epoch 35/50 [Valid]: 100% 3/3 [00:00<00:00, 393.27it/s]\n",
            "Epoch [35/50] | Train Loss: 0.035496 | Validation Loss: 0.018227\n",
            "Epoch 36/50 [Train]: 100% 9/9 [00:00<00:00, 106.57it/s]\n",
            "Epoch 36/50 [Valid]: 100% 3/3 [00:00<00:00, 436.00it/s]\n",
            "Epoch [36/50] | Train Loss: 0.038077 | Validation Loss: 0.007279\n",
            "Epoch 37/50 [Train]: 100% 9/9 [00:00<00:00, 87.47it/s]\n",
            "Epoch 37/50 [Valid]: 100% 3/3 [00:00<00:00, 361.30it/s]\n",
            "Epoch [37/50] | Train Loss: 0.037043 | Validation Loss: 0.006419\n",
            "Epoch 38/50 [Train]: 100% 9/9 [00:00<00:00, 109.53it/s]\n",
            "Epoch 38/50 [Valid]: 100% 3/3 [00:00<00:00, 383.93it/s]\n",
            "Epoch [38/50] | Train Loss: 0.035614 | Validation Loss: 0.013309\n",
            "Epoch 39/50 [Train]: 100% 9/9 [00:00<00:00, 82.25it/s]\n",
            "Epoch 39/50 [Valid]: 100% 3/3 [00:00<00:00, 293.53it/s]\n",
            "Epoch [39/50] | Train Loss: 0.037760 | Validation Loss: 0.014261\n",
            "Epoch 40/50 [Train]: 100% 9/9 [00:00<00:00, 107.46it/s]\n",
            "Epoch 40/50 [Valid]: 100% 3/3 [00:00<00:00, 389.70it/s]\n",
            "Epoch [40/50] | Train Loss: 0.037344 | Validation Loss: 0.014474\n",
            "Epoch 41/50 [Train]: 100% 9/9 [00:00<00:00, 106.46it/s]\n",
            "Epoch 41/50 [Valid]: 100% 3/3 [00:00<00:00, 412.11it/s]\n",
            "Epoch [41/50] | Train Loss: 0.038288 | Validation Loss: 0.008317\n",
            "Epoch 42/50 [Train]: 100% 9/9 [00:00<00:00, 106.21it/s]\n",
            "Epoch 42/50 [Valid]: 100% 3/3 [00:00<00:00, 423.77it/s]\n",
            "Epoch [42/50] | Train Loss: 0.035819 | Validation Loss: 0.009478\n",
            "Epoch 43/50 [Train]: 100% 9/9 [00:00<00:00, 105.29it/s]\n",
            "Epoch 43/50 [Valid]: 100% 3/3 [00:00<00:00, 387.08it/s]\n",
            "Epoch [43/50] | Train Loss: 0.037534 | Validation Loss: 0.006483\n",
            "Epoch 44/50 [Train]: 100% 9/9 [00:00<00:00, 105.60it/s]\n",
            "Epoch 44/50 [Valid]: 100% 3/3 [00:00<00:00, 407.27it/s]\n",
            "Epoch [44/50] | Train Loss: 0.036859 | Validation Loss: 0.008407\n",
            "Epoch 45/50 [Train]: 100% 9/9 [00:00<00:00, 103.92it/s]\n",
            "Epoch 45/50 [Valid]: 100% 3/3 [00:00<00:00, 425.17it/s]\n",
            "Epoch [45/50] | Train Loss: 0.035221 | Validation Loss: 0.012612\n",
            "Epoch 46/50 [Train]: 100% 9/9 [00:00<00:00, 92.72it/s]\n",
            "Epoch 46/50 [Valid]: 100% 3/3 [00:00<00:00, 364.65it/s]\n",
            "Epoch [46/50] | Train Loss: 0.036828 | Validation Loss: 0.009421\n",
            "Epoch 47/50 [Train]: 100% 9/9 [00:00<00:00, 82.13it/s]\n",
            "Epoch 47/50 [Valid]: 100% 3/3 [00:00<00:00, 324.88it/s]\n",
            "Epoch [47/50] | Train Loss: 0.034655 | Validation Loss: 0.009992\n",
            "Epoch 48/50 [Train]: 100% 9/9 [00:00<00:00, 101.12it/s]\n",
            "Epoch 48/50 [Valid]: 100% 3/3 [00:00<00:00, 365.27it/s]\n",
            "Epoch [48/50] | Train Loss: 0.034862 | Validation Loss: 0.012069\n",
            "Epoch 49/50 [Train]: 100% 9/9 [00:00<00:00, 79.61it/s]\n",
            "Epoch 49/50 [Valid]: 100% 3/3 [00:00<00:00, 404.34it/s]\n",
            "Epoch [49/50] | Train Loss: 0.036830 | Validation Loss: 0.006667\n",
            "Epoch 50/50 [Train]: 100% 9/9 [00:00<00:00, 107.31it/s]\n",
            "Epoch 50/50 [Valid]: 100% 3/3 [00:00<00:00, 441.86it/s]\n",
            "Epoch [50/50] | Train Loss: 0.044091 | Validation Loss: 0.003992\n",
            "   -> Validation loss cải thiện. Đã lưu model tốt nhất vào 'mslstm_attention_model.pth'\n",
            "\n",
            "--- Huấn luyện Hoàn tất ---\n",
            "✅ Model (Attention) tốt nhất đã được lưu tại epoch có Validation Loss = 0.003992\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Evaluate sau train***"
      ],
      "metadata": {
        "id": "2RJ77CzmVdV7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile evaluate.py\n",
        "# evaluate.py\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from config import (\n",
        "    NUM_BASE_FEATURES, NUM_SCALES, LSTM_HIDDEN_UNITS, LSTM_NUM_LAYERS,\n",
        "    ATTENTION_NUM_HEADS,\n",
        "    TRAINED_MODEL_PATH\n",
        ")\n",
        "#import model mới\n",
        "from model import MSLSTMAttention\n",
        "from dataset import get_data_loaders\n",
        "\n",
        "\n",
        "def run_evaluation():\n",
        "    \"\"\"Hàm chính để đánh giá mô hình trên tập test.\"\"\"\n",
        "\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    print(f\"Sử dụng thiết bị: {device.upper()}\")\n",
        "\n",
        "    # 1. Tải dữ liệu (chỉ cần test_loader và scaler)\n",
        "    _, test_loader, _, target_scaler = get_data_loaders()\n",
        "    if not test_loader:\n",
        "        print(\"Dừng chương trình vì không tải được dữ liệu.\")\n",
        "        return\n",
        "\n",
        "    # 2. Tải lại mô hình đã huấn luyện\n",
        "    print(f\"Đang tải mô hình từ: {TRAINED_MODEL_PATH}\")\n",
        "    # Sửa đổi: Khởi tạo đúng class model mới\n",
        "    model = MSLSTMAttention(\n",
        "        input_feature_size=NUM_BASE_FEATURES,\n",
        "        num_scales=NUM_SCALES,\n",
        "        lstm_hidden_units=LSTM_HIDDEN_UNITS,\n",
        "        lstm_num_layers=LSTM_NUM_LAYERS,\n",
        "        num_heads=ATTENTION_NUM_HEADS\n",
        "    )\n",
        "    try:\n",
        "        model.load_state_dict(torch.load(TRAINED_MODEL_PATH, map_location=device))\n",
        "        model.to(device)\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Lỗi: Không tìm thấy file model tại '{TRAINED_MODEL_PATH}'.\")\n",
        "        print(\"Vui lòng chạy train.py trước.\")\n",
        "        return\n",
        "\n",
        "    # 3. Đánh giá trên tập Test\n",
        "    model.eval()\n",
        "    predictions, actuals = [], []\n",
        "    with torch.no_grad():\n",
        "        for features, labels in test_loader:\n",
        "            features, labels = features.to(device), labels.to(device)\n",
        "            outputs = model(features)\n",
        "\n",
        "            predictions.extend(outputs.cpu().numpy())\n",
        "            actuals.extend(labels.cpu().numpy())\n",
        "\n",
        "    # 4. Giải chuẩn hóa để so sánh\n",
        "    predictions = np.array(predictions).reshape(-1, 1)\n",
        "    actuals = np.array(actuals).reshape(-1, 1)\n",
        "\n",
        "    original_predictions = target_scaler.inverse_transform(predictions)\n",
        "    original_actuals = target_scaler.inverse_transform(actuals)\n",
        "\n",
        "    # 5. Tính toán sai số và in kết quả\n",
        "    mae = np.mean(np.abs(original_predictions - original_actuals))\n",
        "    print(f\"\\n--- Kết quả Đánh giá trên Tập Test (Model + Attention) ---\")\n",
        "    print(f\"Sai số Trung bình Tuyệt đối (MAE): {mae:.4f} (điểm VN-Index)\")\n",
        "\n",
        "    # 6. Vẽ biểu đồ so sánh\n",
        "    plt.figure(figsize=(15, 6))\n",
        "    plt.plot(original_actuals, label='Giá trị Thực tế (Actuals)', color='blue', marker='.', linestyle='-')\n",
        "    plt.plot(original_predictions, label='Giá trị Dự đoán (Predictions)', color='red', linestyle='--')\n",
        "    plt.title('So sánh Giá trị Thực tế và Dự đoán (Model + Attention)')\n",
        "    plt.xlabel('Ngày (trong tập Test)')\n",
        "    plt.ylabel('Giá đóng cửa VN-Index')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    output_image_path = 'prediction_vs_actual_attention.png'\n",
        "    plt.savefig(output_image_path)\n",
        "    print(f\"✅ Đã lưu biểu đồ so sánh vào file '{output_image_path}'\")\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    run_evaluation()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w--U4Lv8Vcwo",
        "outputId": "5b0267df-3ea0-494b-b5be-144f947902de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting evaluate.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python evaluate.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gu0DKsUSVrtF",
        "outputId": "58e9145f-9bd4-45fc-81a2-f4e87d31c025"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sử dụng thiết bị: CUDA\n",
            "Bắt đầu quá trình tạo DataLoader...\n",
            "-> Đang tạo đặc trưng đa quy mô với Wavelet (family: db4, level: 4)...\n",
            "-> Đang chuẩn hóa dữ liệu (scaling)...\n",
            "-> Đang tạo các chuỗi tuần tự với lookback window = 30...\n",
            "-> Kích thước tập Train: 270 mẫu\n",
            "-> Kích thước tập Test: 68 mẫu\n",
            "\n",
            "✅ Hoàn tất việc tạo DataLoader.\n",
            "Đang tải mô hình từ: mslstm_attention_model.pth\n",
            "\n",
            "--- Kết quả Đánh giá trên Tập Test (Model + Attention) ---\n",
            "Sai số Trung bình Tuyệt đối (MAE): 20.4384 (điểm VN-Index)\n",
            "✅ Đã lưu biểu đồ so sánh vào file 'prediction_vs_actual_attention.png'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***MAE thậm chí còn thấp hơn, bây giờ sẽ chỉnh sửa siêu tham số***"
      ],
      "metadata": {
        "id": "SyP91Lo8WQZy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile config.py\n",
        "# config.py\n",
        "\n",
        "# --- Đường dẫn file ---\n",
        "PROCESSED_DATA_PATH = 'vn_indices_processed.csv'\n",
        "# Đổi tên file model để lưu kết quả của lần chạy mới\n",
        "TRAINED_MODEL_PATH = 'mslstm_attention_tuned.pth'\n",
        "\n",
        "# --- Tham số tạo Dataset ---\n",
        "LOOKBACK_WINDOW = 30\n",
        "TARGET_COLUMN = 'VNINDEX_Close'\n",
        "TEST_SET_SIZE = 0.2\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# --- Tham số Biến đổi Wavelet ---\n",
        "WAVELET_FAMILY = 'db4'\n",
        "WAVELET_LEVEL = 4\n",
        "\n",
        "# --- Tham số Kiến trúc Model ---\n",
        "NUM_BASE_FEATURES = 30\n",
        "NUM_SCALES = WAVELET_LEVEL + 1\n",
        "# --- THAY ĐỔI ---\n",
        "LSTM_HIDDEN_UNITS = 128 #Tăng từ 64 lên 148 units\n",
        "LSTM_NUM_LAYERS = 2\n",
        "ATTENTION_NUM_HEADS = 4\n",
        "\n",
        "# --- Tham số Huấn luyện ---\n",
        "# --- THAY ĐỔI ---\n",
        "LEARNING_RATE = 0.0005 # Giảm lại learning rate\n",
        "NUM_EPOCHS = 100       # Tăng epoch để xem có phát huy được không"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_RpMcO4Wabj",
        "outputId": "f00a9299-76f1-4d3c-dae7-9c4d25c000f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting config.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Train và evaluate lại config mới***"
      ],
      "metadata": {
        "id": "3M5o5N88XCoC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile train.py\n",
        "# train.py\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "from config import (\n",
        "    NUM_BASE_FEATURES, NUM_SCALES, LSTM_HIDDEN_UNITS, LSTM_NUM_LAYERS,\n",
        "    ATTENTION_NUM_HEADS, # Thêm tham số attention\n",
        "    LEARNING_RATE, NUM_EPOCHS, TRAINED_MODEL_PATH\n",
        ")\n",
        "# Sửa đổi: import model mới\n",
        "from model import MSLSTMAttention\n",
        "from dataset import get_data_loaders\n",
        "\n",
        "\n",
        "def run_training():\n",
        "    \"\"\"Hàm chính để thực hiện toàn bộ quá trình huấn luyện.\"\"\"\n",
        "\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    print(f\"Sử dụng thiết bị: {device.upper()}\")\n",
        "\n",
        "    train_loader, test_loader, _, _ = get_data_loaders()\n",
        "    if not train_loader:\n",
        "        print(\"Dừng chương trình vì không tải được dữ liệu.\")\n",
        "        return\n",
        "\n",
        "    #Khởi tạo model MSLSTMAttention mới\n",
        "    model = MSLSTMAttention(\n",
        "        input_feature_size=NUM_BASE_FEATURES,\n",
        "        num_scales=NUM_SCALES,\n",
        "        lstm_hidden_units=LSTM_HIDDEN_UNITS,\n",
        "        lstm_num_layers=LSTM_NUM_LAYERS,\n",
        "        num_heads=ATTENTION_NUM_HEADS\n",
        "    ).to(device)\n",
        "\n",
        "    loss_function = nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "    print(\"\\n--- Bắt đầu Huấn luyện Model MS-LSTM + Attention ---\")\n",
        "    best_val_loss = float('inf')\n",
        "\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        for features, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS} [Train]\"):\n",
        "            features, labels = features.to(device), labels.to(device)\n",
        "            outputs = model(features)\n",
        "            loss = loss_function(outputs, labels)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for features, labels in tqdm(test_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS} [Valid]\"):\n",
        "                features, labels = features.to(device), labels.to(device)\n",
        "                outputs = model(features)\n",
        "                loss = loss_function(outputs, labels)\n",
        "                val_loss += loss.item()\n",
        "\n",
        "        avg_train_loss = train_loss / len(train_loader)\n",
        "        avg_val_loss = val_loss / len(test_loader)\n",
        "\n",
        "        print(f\"Epoch [{epoch+1:02d}/{NUM_EPOCHS}] | Train Loss: {avg_train_loss:.6f} | Validation Loss: {avg_val_loss:.6f}\")\n",
        "\n",
        "        if avg_val_loss < best_val_loss:\n",
        "            best_val_loss = avg_val_loss\n",
        "            torch.save(model.state_dict(), TRAINED_MODEL_PATH)\n",
        "            print(f\"   -> Validation loss cải thiện. Đã lưu model tốt nhất vào '{TRAINED_MODEL_PATH}'\")\n",
        "\n",
        "    print(f\"\\n--- Huấn luyện Hoàn tất ---\")\n",
        "    print(f\"✅ Model (Attention) tốt nhất đã được lưu tại epoch có Validation Loss = {best_val_loss:.6f}\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    run_training()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QxcM4qdPXAf_",
        "outputId": "8af63eaf-ae1f-444e-ce56-10f65612b485"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting train.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nw3zTl-uW9DB",
        "outputId": "f09e107b-71fa-4328-bc36-3e5acac7097b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sử dụng thiết bị: CUDA\n",
            "Bắt đầu quá trình tạo DataLoader...\n",
            "-> Đang tạo đặc trưng đa quy mô với Wavelet (family: db4, level: 4)...\n",
            "-> Đang chuẩn hóa dữ liệu (scaling)...\n",
            "-> Đang tạo các chuỗi tuần tự với lookback window = 30...\n",
            "-> Kích thước tập Train: 270 mẫu\n",
            "-> Kích thước tập Test: 68 mẫu\n",
            "\n",
            "✅ Hoàn tất việc tạo DataLoader.\n",
            "\n",
            "--- Bắt đầu Huấn luyện Model MS-LSTM + Attention ---\n",
            "Epoch 1/100 [Train]: 100% 9/9 [00:00<00:00, 26.19it/s]\n",
            "Epoch 1/100 [Valid]: 100% 3/3 [00:00<00:00, 130.50it/s]\n",
            "Epoch [01/100] | Train Loss: 0.105180 | Validation Loss: 0.050690\n",
            "   -> Validation loss cải thiện. Đã lưu model tốt nhất vào 'mslstm_attention_tuned.pth'\n",
            "Epoch 2/100 [Train]: 100% 9/9 [00:00<00:00, 85.90it/s]\n",
            "Epoch 2/100 [Valid]: 100% 3/3 [00:00<00:00, 225.87it/s]\n",
            "Epoch [02/100] | Train Loss: 0.056489 | Validation Loss: 0.012146\n",
            "   -> Validation loss cải thiện. Đã lưu model tốt nhất vào 'mslstm_attention_tuned.pth'\n",
            "Epoch 3/100 [Train]: 100% 9/9 [00:00<00:00, 86.77it/s]\n",
            "Epoch 3/100 [Valid]: 100% 3/3 [00:00<00:00, 312.46it/s]\n",
            "Epoch [03/100] | Train Loss: 0.047284 | Validation Loss: 0.004356\n",
            "   -> Validation loss cải thiện. Đã lưu model tốt nhất vào 'mslstm_attention_tuned.pth'\n",
            "Epoch 4/100 [Train]: 100% 9/9 [00:00<00:00, 101.10it/s]\n",
            "Epoch 4/100 [Valid]: 100% 3/3 [00:00<00:00, 299.09it/s]\n",
            "Epoch [04/100] | Train Loss: 0.042457 | Validation Loss: 0.021470\n",
            "Epoch 5/100 [Train]: 100% 9/9 [00:00<00:00, 104.45it/s]\n",
            "Epoch 5/100 [Valid]: 100% 3/3 [00:00<00:00, 311.11it/s]\n",
            "Epoch [05/100] | Train Loss: 0.038717 | Validation Loss: 0.010976\n",
            "Epoch 6/100 [Train]: 100% 9/9 [00:00<00:00, 87.43it/s]\n",
            "Epoch 6/100 [Valid]: 100% 3/3 [00:00<00:00, 304.52it/s]\n",
            "Epoch [06/100] | Train Loss: 0.038793 | Validation Loss: 0.004093\n",
            "   -> Validation loss cải thiện. Đã lưu model tốt nhất vào 'mslstm_attention_tuned.pth'\n",
            "Epoch 7/100 [Train]: 100% 9/9 [00:00<00:00, 100.92it/s]\n",
            "Epoch 7/100 [Valid]: 100% 3/3 [00:00<00:00, 306.65it/s]\n",
            "Epoch [07/100] | Train Loss: 0.040365 | Validation Loss: 0.017738\n",
            "Epoch 8/100 [Train]: 100% 9/9 [00:00<00:00, 102.02it/s]\n",
            "Epoch 8/100 [Valid]: 100% 3/3 [00:00<00:00, 302.70it/s]\n",
            "Epoch [08/100] | Train Loss: 0.037876 | Validation Loss: 0.009999\n",
            "Epoch 9/100 [Train]: 100% 9/9 [00:00<00:00, 105.97it/s]\n",
            "Epoch 9/100 [Valid]: 100% 3/3 [00:00<00:00, 310.04it/s]\n",
            "Epoch [09/100] | Train Loss: 0.036197 | Validation Loss: 0.009152\n",
            "Epoch 10/100 [Train]: 100% 9/9 [00:00<00:00, 102.11it/s]\n",
            "Epoch 10/100 [Valid]: 100% 3/3 [00:00<00:00, 300.14it/s]\n",
            "Epoch [10/100] | Train Loss: 0.035976 | Validation Loss: 0.018388\n",
            "Epoch 11/100 [Train]: 100% 9/9 [00:00<00:00, 91.37it/s]\n",
            "Epoch 11/100 [Valid]: 100% 3/3 [00:00<00:00, 261.08it/s]\n",
            "Epoch [11/100] | Train Loss: 0.036898 | Validation Loss: 0.004447\n",
            "Epoch 12/100 [Train]: 100% 9/9 [00:00<00:00, 99.05it/s]\n",
            "Epoch 12/100 [Valid]: 100% 3/3 [00:00<00:00, 302.65it/s]\n",
            "Epoch [12/100] | Train Loss: 0.040271 | Validation Loss: 0.006085\n",
            "Epoch 13/100 [Train]: 100% 9/9 [00:00<00:00, 100.81it/s]\n",
            "Epoch 13/100 [Valid]: 100% 3/3 [00:00<00:00, 307.93it/s]\n",
            "Epoch [13/100] | Train Loss: 0.038323 | Validation Loss: 0.021899\n",
            "Epoch 14/100 [Train]: 100% 9/9 [00:00<00:00, 107.77it/s]\n",
            "Epoch 14/100 [Valid]: 100% 3/3 [00:00<00:00, 299.95it/s]\n",
            "Epoch [14/100] | Train Loss: 0.038540 | Validation Loss: 0.010391\n",
            "Epoch 15/100 [Train]: 100% 9/9 [00:00<00:00, 107.76it/s]\n",
            "Epoch 15/100 [Valid]: 100% 3/3 [00:00<00:00, 297.98it/s]\n",
            "Epoch [15/100] | Train Loss: 0.037624 | Validation Loss: 0.010887\n",
            "Epoch 16/100 [Train]: 100% 9/9 [00:00<00:00, 91.84it/s]\n",
            "Epoch 16/100 [Valid]: 100% 3/3 [00:00<00:00, 302.93it/s]\n",
            "Epoch [16/100] | Train Loss: 0.036242 | Validation Loss: 0.009331\n",
            "Epoch 17/100 [Train]: 100% 9/9 [00:00<00:00, 106.45it/s]\n",
            "Epoch 17/100 [Valid]: 100% 3/3 [00:00<00:00, 297.95it/s]\n",
            "Epoch [17/100] | Train Loss: 0.036536 | Validation Loss: 0.006941\n",
            "Epoch 18/100 [Train]: 100% 9/9 [00:00<00:00, 106.60it/s]\n",
            "Epoch 18/100 [Valid]: 100% 3/3 [00:00<00:00, 300.32it/s]\n",
            "Epoch [18/100] | Train Loss: 0.036384 | Validation Loss: 0.010585\n",
            "Epoch 19/100 [Train]: 100% 9/9 [00:00<00:00, 106.04it/s]\n",
            "Epoch 19/100 [Valid]: 100% 3/3 [00:00<00:00, 307.49it/s]\n",
            "Epoch [19/100] | Train Loss: 0.038332 | Validation Loss: 0.006190\n",
            "Epoch 20/100 [Train]: 100% 9/9 [00:00<00:00, 107.00it/s]\n",
            "Epoch 20/100 [Valid]: 100% 3/3 [00:00<00:00, 294.78it/s]\n",
            "Epoch [20/100] | Train Loss: 0.037032 | Validation Loss: 0.016967\n",
            "Epoch 21/100 [Train]: 100% 9/9 [00:00<00:00, 99.20it/s]\n",
            "Epoch 21/100 [Valid]: 100% 3/3 [00:00<00:00, 302.94it/s]\n",
            "Epoch [21/100] | Train Loss: 0.036357 | Validation Loss: 0.004238\n",
            "Epoch 22/100 [Train]: 100% 9/9 [00:00<00:00, 104.42it/s]\n",
            "Epoch 22/100 [Valid]: 100% 3/3 [00:00<00:00, 308.59it/s]\n",
            "Epoch [22/100] | Train Loss: 0.037633 | Validation Loss: 0.006475\n",
            "Epoch 23/100 [Train]: 100% 9/9 [00:00<00:00, 100.74it/s]\n",
            "Epoch 23/100 [Valid]: 100% 3/3 [00:00<00:00, 283.05it/s]\n",
            "Epoch [23/100] | Train Loss: 0.036812 | Validation Loss: 0.017994\n",
            "Epoch 24/100 [Train]: 100% 9/9 [00:00<00:00, 93.49it/s]\n",
            "Epoch 24/100 [Valid]: 100% 3/3 [00:00<00:00, 312.23it/s]\n",
            "Epoch [24/100] | Train Loss: 0.037639 | Validation Loss: 0.007874\n",
            "Epoch 25/100 [Train]: 100% 9/9 [00:00<00:00, 105.68it/s]\n",
            "Epoch 25/100 [Valid]: 100% 3/3 [00:00<00:00, 301.08it/s]\n",
            "Epoch [25/100] | Train Loss: 0.036353 | Validation Loss: 0.009262\n",
            "Epoch 26/100 [Train]: 100% 9/9 [00:00<00:00, 88.97it/s]\n",
            "Epoch 26/100 [Valid]: 100% 3/3 [00:00<00:00, 311.30it/s]\n",
            "Epoch [26/100] | Train Loss: 0.035704 | Validation Loss: 0.009398\n",
            "Epoch 27/100 [Train]: 100% 9/9 [00:00<00:00, 104.75it/s]\n",
            "Epoch 27/100 [Valid]: 100% 3/3 [00:00<00:00, 287.98it/s]\n",
            "Epoch [27/100] | Train Loss: 0.036997 | Validation Loss: 0.008637\n",
            "Epoch 28/100 [Train]: 100% 9/9 [00:00<00:00, 102.66it/s]\n",
            "Epoch 28/100 [Valid]: 100% 3/3 [00:00<00:00, 309.78it/s]\n",
            "Epoch [28/100] | Train Loss: 0.035923 | Validation Loss: 0.004253\n",
            "Epoch 29/100 [Train]: 100% 9/9 [00:00<00:00, 102.16it/s]\n",
            "Epoch 29/100 [Valid]: 100% 3/3 [00:00<00:00, 302.57it/s]\n",
            "Epoch [29/100] | Train Loss: 0.039266 | Validation Loss: 0.011954\n",
            "Epoch 30/100 [Train]: 100% 9/9 [00:00<00:00, 104.27it/s]\n",
            "Epoch 30/100 [Valid]: 100% 3/3 [00:00<00:00, 299.47it/s]\n",
            "Epoch [30/100] | Train Loss: 0.038249 | Validation Loss: 0.010416\n",
            "Epoch 31/100 [Train]: 100% 9/9 [00:00<00:00, 99.46it/s]\n",
            "Epoch 31/100 [Valid]: 100% 3/3 [00:00<00:00, 308.19it/s]\n",
            "Epoch [31/100] | Train Loss: 0.035714 | Validation Loss: 0.021737\n",
            "Epoch 32/100 [Train]: 100% 9/9 [00:00<00:00, 95.78it/s]\n",
            "Epoch 32/100 [Valid]: 100% 3/3 [00:00<00:00, 315.72it/s]\n",
            "Epoch [32/100] | Train Loss: 0.038077 | Validation Loss: 0.008348\n",
            "Epoch 33/100 [Train]: 100% 9/9 [00:00<00:00, 103.60it/s]\n",
            "Epoch 33/100 [Valid]: 100% 3/3 [00:00<00:00, 301.11it/s]\n",
            "Epoch [33/100] | Train Loss: 0.034611 | Validation Loss: 0.013552\n",
            "Epoch 34/100 [Train]: 100% 9/9 [00:00<00:00, 108.55it/s]\n",
            "Epoch 34/100 [Valid]: 100% 3/3 [00:00<00:00, 299.29it/s]\n",
            "Epoch [34/100] | Train Loss: 0.035903 | Validation Loss: 0.004482\n",
            "Epoch 35/100 [Train]: 100% 9/9 [00:00<00:00, 109.64it/s]\n",
            "Epoch 35/100 [Valid]: 100% 3/3 [00:00<00:00, 304.80it/s]\n",
            "Epoch [35/100] | Train Loss: 0.035523 | Validation Loss: 0.010670\n",
            "Epoch 36/100 [Train]: 100% 9/9 [00:00<00:00, 104.87it/s]\n",
            "Epoch 36/100 [Valid]: 100% 3/3 [00:00<00:00, 224.03it/s]\n",
            "Epoch [36/100] | Train Loss: 0.036699 | Validation Loss: 0.010517\n",
            "Epoch 37/100 [Train]: 100% 9/9 [00:00<00:00, 97.07it/s]\n",
            "Epoch 37/100 [Valid]: 100% 3/3 [00:00<00:00, 310.54it/s]\n",
            "Epoch [37/100] | Train Loss: 0.037097 | Validation Loss: 0.014961\n",
            "Epoch 38/100 [Train]: 100% 9/9 [00:00<00:00, 107.55it/s]\n",
            "Epoch 38/100 [Valid]: 100% 3/3 [00:00<00:00, 302.74it/s]\n",
            "Epoch [38/100] | Train Loss: 0.035496 | Validation Loss: 0.018927\n",
            "Epoch 39/100 [Train]: 100% 9/9 [00:00<00:00, 101.12it/s]\n",
            "Epoch 39/100 [Valid]: 100% 3/3 [00:00<00:00, 292.59it/s]\n",
            "Epoch [39/100] | Train Loss: 0.038181 | Validation Loss: 0.005474\n",
            "Epoch 40/100 [Train]: 100% 9/9 [00:00<00:00, 105.35it/s]\n",
            "Epoch 40/100 [Valid]: 100% 3/3 [00:00<00:00, 293.66it/s]\n",
            "Epoch [40/100] | Train Loss: 0.038578 | Validation Loss: 0.004318\n",
            "Epoch 41/100 [Train]: 100% 9/9 [00:00<00:00, 104.39it/s]\n",
            "Epoch 41/100 [Valid]: 100% 3/3 [00:00<00:00, 306.81it/s]\n",
            "Epoch [41/100] | Train Loss: 0.037841 | Validation Loss: 0.013638\n",
            "Epoch 42/100 [Train]: 100% 9/9 [00:00<00:00, 90.30it/s]\n",
            "Epoch 42/100 [Valid]: 100% 3/3 [00:00<00:00, 314.08it/s]\n",
            "Epoch [42/100] | Train Loss: 0.037802 | Validation Loss: 0.029586\n",
            "Epoch 43/100 [Train]: 100% 9/9 [00:00<00:00, 104.45it/s]\n",
            "Epoch 43/100 [Valid]: 100% 3/3 [00:00<00:00, 292.85it/s]\n",
            "Epoch [43/100] | Train Loss: 0.038591 | Validation Loss: 0.004719\n",
            "Epoch 44/100 [Train]: 100% 9/9 [00:00<00:00, 103.86it/s]\n",
            "Epoch 44/100 [Valid]: 100% 3/3 [00:00<00:00, 303.44it/s]\n",
            "Epoch [44/100] | Train Loss: 0.040626 | Validation Loss: 0.004221\n",
            "Epoch 45/100 [Train]: 100% 9/9 [00:00<00:00, 108.25it/s]\n",
            "Epoch 45/100 [Valid]: 100% 3/3 [00:00<00:00, 298.61it/s]\n",
            "Epoch [45/100] | Train Loss: 0.043420 | Validation Loss: 0.023871\n",
            "Epoch 46/100 [Train]: 100% 9/9 [00:00<00:00, 105.97it/s]\n",
            "Epoch 46/100 [Valid]: 100% 3/3 [00:00<00:00, 293.92it/s]\n",
            "Epoch [46/100] | Train Loss: 0.035905 | Validation Loss: 0.006964\n",
            "Epoch 47/100 [Train]: 100% 9/9 [00:00<00:00, 91.60it/s]\n",
            "Epoch 47/100 [Valid]: 100% 3/3 [00:00<00:00, 314.61it/s]\n",
            "Epoch [47/100] | Train Loss: 0.038527 | Validation Loss: 0.004469\n",
            "Epoch 48/100 [Train]: 100% 9/9 [00:00<00:00, 108.00it/s]\n",
            "Epoch 48/100 [Valid]: 100% 3/3 [00:00<00:00, 304.20it/s]\n",
            "Epoch [48/100] | Train Loss: 0.037774 | Validation Loss: 0.009162\n",
            "Epoch 49/100 [Train]: 100% 9/9 [00:00<00:00, 104.32it/s]\n",
            "Epoch 49/100 [Valid]: 100% 3/3 [00:00<00:00, 303.07it/s]\n",
            "Epoch [49/100] | Train Loss: 0.035174 | Validation Loss: 0.016073\n",
            "Epoch 50/100 [Train]: 100% 9/9 [00:00<00:00, 102.28it/s]\n",
            "Epoch 50/100 [Valid]: 100% 3/3 [00:00<00:00, 298.43it/s]\n",
            "Epoch [50/100] | Train Loss: 0.036575 | Validation Loss: 0.009047\n",
            "Epoch 51/100 [Train]: 100% 9/9 [00:00<00:00, 89.55it/s]\n",
            "Epoch 51/100 [Valid]: 100% 3/3 [00:00<00:00, 300.77it/s]\n",
            "Epoch [51/100] | Train Loss: 0.033764 | Validation Loss: 0.013746\n",
            "Epoch 52/100 [Train]: 100% 9/9 [00:00<00:00, 106.12it/s]\n",
            "Epoch 52/100 [Valid]: 100% 3/3 [00:00<00:00, 295.74it/s]\n",
            "Epoch [52/100] | Train Loss: 0.035865 | Validation Loss: 0.015624\n",
            "Epoch 53/100 [Train]: 100% 9/9 [00:00<00:00, 101.64it/s]\n",
            "Epoch 53/100 [Valid]: 100% 3/3 [00:00<00:00, 309.18it/s]\n",
            "Epoch [53/100] | Train Loss: 0.036312 | Validation Loss: 0.004005\n",
            "   -> Validation loss cải thiện. Đã lưu model tốt nhất vào 'mslstm_attention_tuned.pth'\n",
            "Epoch 54/100 [Train]: 100% 9/9 [00:00<00:00, 104.74it/s]\n",
            "Epoch 54/100 [Valid]: 100% 3/3 [00:00<00:00, 295.68it/s]\n",
            "Epoch [54/100] | Train Loss: 0.036713 | Validation Loss: 0.014421\n",
            "Epoch 55/100 [Train]: 100% 9/9 [00:00<00:00, 103.36it/s]\n",
            "Epoch 55/100 [Valid]: 100% 3/3 [00:00<00:00, 293.77it/s]\n",
            "Epoch [55/100] | Train Loss: 0.035564 | Validation Loss: 0.005621\n",
            "Epoch 56/100 [Train]: 100% 9/9 [00:00<00:00, 105.32it/s]\n",
            "Epoch 56/100 [Valid]: 100% 3/3 [00:00<00:00, 303.61it/s]\n",
            "Epoch [56/100] | Train Loss: 0.035967 | Validation Loss: 0.006278\n",
            "Epoch 57/100 [Train]: 100% 9/9 [00:00<00:00, 91.47it/s]\n",
            "Epoch 57/100 [Valid]: 100% 3/3 [00:00<00:00, 306.40it/s]\n",
            "Epoch [57/100] | Train Loss: 0.036649 | Validation Loss: 0.006559\n",
            "Epoch 58/100 [Train]: 100% 9/9 [00:00<00:00, 98.80it/s]\n",
            "Epoch 58/100 [Valid]: 100% 3/3 [00:00<00:00, 304.17it/s]\n",
            "Epoch [58/100] | Train Loss: 0.033944 | Validation Loss: 0.008897\n",
            "Epoch 59/100 [Train]: 100% 9/9 [00:00<00:00, 101.32it/s]\n",
            "Epoch 59/100 [Valid]: 100% 3/3 [00:00<00:00, 304.47it/s]\n",
            "Epoch [59/100] | Train Loss: 0.035398 | Validation Loss: 0.004466\n",
            "Epoch 60/100 [Train]: 100% 9/9 [00:00<00:00, 92.99it/s]\n",
            "Epoch 60/100 [Valid]: 100% 3/3 [00:00<00:00, 304.60it/s]\n",
            "Epoch [60/100] | Train Loss: 0.035271 | Validation Loss: 0.013877\n",
            "Epoch 61/100 [Train]: 100% 9/9 [00:00<00:00, 102.57it/s]\n",
            "Epoch 61/100 [Valid]: 100% 3/3 [00:00<00:00, 309.92it/s]\n",
            "Epoch [61/100] | Train Loss: 0.034064 | Validation Loss: 0.008279\n",
            "Epoch 62/100 [Train]: 100% 9/9 [00:00<00:00, 106.54it/s]\n",
            "Epoch 62/100 [Valid]: 100% 3/3 [00:00<00:00, 303.08it/s]\n",
            "Epoch [62/100] | Train Loss: 0.035407 | Validation Loss: 0.003982\n",
            "   -> Validation loss cải thiện. Đã lưu model tốt nhất vào 'mslstm_attention_tuned.pth'\n",
            "Epoch 63/100 [Train]: 100% 9/9 [00:00<00:00, 101.47it/s]\n",
            "Epoch 63/100 [Valid]: 100% 3/3 [00:00<00:00, 298.36it/s]\n",
            "Epoch [63/100] | Train Loss: 0.037145 | Validation Loss: 0.004001\n",
            "Epoch 64/100 [Train]: 100% 9/9 [00:00<00:00, 103.51it/s]\n",
            "Epoch 64/100 [Valid]: 100% 3/3 [00:00<00:00, 300.85it/s]\n",
            "Epoch [64/100] | Train Loss: 0.039688 | Validation Loss: 0.004580\n",
            "Epoch 65/100 [Train]: 100% 9/9 [00:00<00:00, 107.37it/s]\n",
            "Epoch 65/100 [Valid]: 100% 3/3 [00:00<00:00, 301.06it/s]\n",
            "Epoch [65/100] | Train Loss: 0.039874 | Validation Loss: 0.030205\n",
            "Epoch 66/100 [Train]: 100% 9/9 [00:00<00:00, 103.74it/s]\n",
            "Epoch 66/100 [Valid]: 100% 3/3 [00:00<00:00, 291.78it/s]\n",
            "Epoch [66/100] | Train Loss: 0.041015 | Validation Loss: 0.009076\n",
            "Epoch 67/100 [Train]: 100% 9/9 [00:00<00:00, 90.91it/s]\n",
            "Epoch 67/100 [Valid]: 100% 3/3 [00:00<00:00, 311.52it/s]\n",
            "Epoch [67/100] | Train Loss: 0.035187 | Validation Loss: 0.005809\n",
            "Epoch 68/100 [Train]: 100% 9/9 [00:00<00:00, 74.01it/s]\n",
            "Epoch 68/100 [Valid]: 100% 3/3 [00:00<00:00, 269.55it/s]\n",
            "Epoch [68/100] | Train Loss: 0.036590 | Validation Loss: 0.006435\n",
            "Epoch 69/100 [Train]: 100% 9/9 [00:00<00:00, 70.77it/s]\n",
            "Epoch 69/100 [Valid]: 100% 3/3 [00:00<00:00, 263.38it/s]\n",
            "Epoch [69/100] | Train Loss: 0.037227 | Validation Loss: 0.007624\n",
            "Epoch 70/100 [Train]: 100% 9/9 [00:00<00:00, 68.28it/s]\n",
            "Epoch 70/100 [Valid]: 100% 3/3 [00:00<00:00, 282.41it/s]\n",
            "Epoch [70/100] | Train Loss: 0.036521 | Validation Loss: 0.019659\n",
            "Epoch 71/100 [Train]: 100% 9/9 [00:00<00:00, 69.28it/s]\n",
            "Epoch 71/100 [Valid]: 100% 3/3 [00:00<00:00, 280.45it/s]\n",
            "Epoch [71/100] | Train Loss: 0.035372 | Validation Loss: 0.008957\n",
            "Epoch 72/100 [Train]: 100% 9/9 [00:00<00:00, 74.68it/s]\n",
            "Epoch 72/100 [Valid]: 100% 3/3 [00:00<00:00, 291.10it/s]\n",
            "Epoch [72/100] | Train Loss: 0.035259 | Validation Loss: 0.006244\n",
            "Epoch 73/100 [Train]: 100% 9/9 [00:00<00:00, 75.93it/s]\n",
            "Epoch 73/100 [Valid]: 100% 3/3 [00:00<00:00, 289.96it/s]\n",
            "Epoch [73/100] | Train Loss: 0.032883 | Validation Loss: 0.013667\n",
            "Epoch 74/100 [Train]: 100% 9/9 [00:00<00:00, 73.54it/s]\n",
            "Epoch 74/100 [Valid]: 100% 3/3 [00:00<00:00, 275.98it/s]\n",
            "Epoch [74/100] | Train Loss: 0.034478 | Validation Loss: 0.004057\n",
            "Epoch 75/100 [Train]: 100% 9/9 [00:00<00:00, 64.37it/s]\n",
            "Epoch 75/100 [Valid]: 100% 3/3 [00:00<00:00, 287.66it/s]\n",
            "Epoch [75/100] | Train Loss: 0.037744 | Validation Loss: 0.003984\n",
            "Epoch 76/100 [Train]: 100% 9/9 [00:00<00:00, 73.29it/s]\n",
            "Epoch 76/100 [Valid]: 100% 3/3 [00:00<00:00, 229.64it/s]\n",
            "Epoch [76/100] | Train Loss: 0.037787 | Validation Loss: 0.013522\n",
            "Epoch 77/100 [Train]: 100% 9/9 [00:00<00:00, 63.60it/s]\n",
            "Epoch 77/100 [Valid]: 100% 3/3 [00:00<00:00, 293.06it/s]\n",
            "Epoch [77/100] | Train Loss: 0.035268 | Validation Loss: 0.010300\n",
            "Epoch 78/100 [Train]: 100% 9/9 [00:00<00:00, 70.79it/s]\n",
            "Epoch 78/100 [Valid]: 100% 3/3 [00:00<00:00, 270.30it/s]\n",
            "Epoch [78/100] | Train Loss: 0.034616 | Validation Loss: 0.015840\n",
            "Epoch 79/100 [Train]: 100% 9/9 [00:00<00:00, 64.98it/s]\n",
            "Epoch 79/100 [Valid]: 100% 3/3 [00:00<00:00, 288.83it/s]\n",
            "Epoch [79/100] | Train Loss: 0.036463 | Validation Loss: 0.005215\n",
            "Epoch 80/100 [Train]: 100% 9/9 [00:00<00:00, 72.64it/s]\n",
            "Epoch 80/100 [Valid]: 100% 3/3 [00:00<00:00, 255.36it/s]\n",
            "Epoch [80/100] | Train Loss: 0.032222 | Validation Loss: 0.005682\n",
            "Epoch 81/100 [Train]: 100% 9/9 [00:00<00:00, 62.55it/s]\n",
            "Epoch 81/100 [Valid]: 100% 3/3 [00:00<00:00, 259.63it/s]\n",
            "Epoch [81/100] | Train Loss: 0.038293 | Validation Loss: 0.004905\n",
            "Epoch 82/100 [Train]: 100% 9/9 [00:00<00:00, 63.83it/s]\n",
            "Epoch 82/100 [Valid]: 100% 3/3 [00:00<00:00, 248.59it/s]\n",
            "Epoch [82/100] | Train Loss: 0.036515 | Validation Loss: 0.026112\n",
            "Epoch 83/100 [Train]: 100% 9/9 [00:00<00:00, 62.27it/s]\n",
            "Epoch 83/100 [Valid]: 100% 3/3 [00:00<00:00, 299.08it/s]\n",
            "Epoch [83/100] | Train Loss: 0.040439 | Validation Loss: 0.014536\n",
            "Epoch 84/100 [Train]: 100% 9/9 [00:00<00:00, 103.45it/s]\n",
            "Epoch 84/100 [Valid]: 100% 3/3 [00:00<00:00, 306.27it/s]\n",
            "Epoch [84/100] | Train Loss: 0.039214 | Validation Loss: 0.004008\n",
            "Epoch 85/100 [Train]: 100% 9/9 [00:00<00:00, 104.71it/s]\n",
            "Epoch 85/100 [Valid]: 100% 3/3 [00:00<00:00, 302.92it/s]\n",
            "Epoch [85/100] | Train Loss: 0.035196 | Validation Loss: 0.013026\n",
            "Epoch 86/100 [Train]: 100% 9/9 [00:00<00:00, 101.62it/s]\n",
            "Epoch 86/100 [Valid]: 100% 3/3 [00:00<00:00, 302.66it/s]\n",
            "Epoch [86/100] | Train Loss: 0.034934 | Validation Loss: 0.008802\n",
            "Epoch 87/100 [Train]: 100% 9/9 [00:00<00:00, 106.59it/s]\n",
            "Epoch 87/100 [Valid]: 100% 3/3 [00:00<00:00, 269.96it/s]\n",
            "Epoch [87/100] | Train Loss: 0.032881 | Validation Loss: 0.019331\n",
            "Epoch 88/100 [Train]: 100% 9/9 [00:00<00:00, 106.63it/s]\n",
            "Epoch 88/100 [Valid]: 100% 3/3 [00:00<00:00, 295.43it/s]\n",
            "Epoch [88/100] | Train Loss: 0.035638 | Validation Loss: 0.004371\n",
            "Epoch 89/100 [Train]: 100% 9/9 [00:00<00:00, 107.30it/s]\n",
            "Epoch 89/100 [Valid]: 100% 3/3 [00:00<00:00, 298.70it/s]\n",
            "Epoch [89/100] | Train Loss: 0.036562 | Validation Loss: 0.004136\n",
            "Epoch 90/100 [Train]: 100% 9/9 [00:00<00:00, 105.70it/s]\n",
            "Epoch 90/100 [Valid]: 100% 3/3 [00:00<00:00, 300.51it/s]\n",
            "Epoch [90/100] | Train Loss: 0.034119 | Validation Loss: 0.017567\n",
            "Epoch 91/100 [Train]: 100% 9/9 [00:00<00:00, 98.96it/s]\n",
            "Epoch 91/100 [Valid]: 100% 3/3 [00:00<00:00, 300.87it/s]\n",
            "Epoch [91/100] | Train Loss: 0.031416 | Validation Loss: 0.022742\n",
            "Epoch 92/100 [Train]: 100% 9/9 [00:00<00:00, 108.22it/s]\n",
            "Epoch 92/100 [Valid]: 100% 3/3 [00:00<00:00, 256.58it/s]\n",
            "Epoch [92/100] | Train Loss: 0.036087 | Validation Loss: 0.021768\n",
            "Epoch 93/100 [Train]: 100% 9/9 [00:00<00:00, 92.11it/s]\n",
            "Epoch 93/100 [Valid]: 100% 3/3 [00:00<00:00, 297.79it/s]\n",
            "Epoch [93/100] | Train Loss: 0.035740 | Validation Loss: 0.004892\n",
            "Epoch 94/100 [Train]: 100% 9/9 [00:00<00:00, 102.11it/s]\n",
            "Epoch 94/100 [Valid]: 100% 3/3 [00:00<00:00, 289.61it/s]\n",
            "Epoch [94/100] | Train Loss: 0.031765 | Validation Loss: 0.003981\n",
            "   -> Validation loss cải thiện. Đã lưu model tốt nhất vào 'mslstm_attention_tuned.pth'\n",
            "Epoch 95/100 [Train]: 100% 9/9 [00:00<00:00, 101.99it/s]\n",
            "Epoch 95/100 [Valid]: 100% 3/3 [00:00<00:00, 294.35it/s]\n",
            "Epoch [95/100] | Train Loss: 0.034797 | Validation Loss: 0.004749\n",
            "Epoch 96/100 [Train]: 100% 9/9 [00:00<00:00, 100.21it/s]\n",
            "Epoch 96/100 [Valid]: 100% 3/3 [00:00<00:00, 300.32it/s]\n",
            "Epoch [96/100] | Train Loss: 0.033439 | Validation Loss: 0.005520\n",
            "Epoch 97/100 [Train]: 100% 9/9 [00:00<00:00, 107.36it/s]\n",
            "Epoch 97/100 [Valid]: 100% 3/3 [00:00<00:00, 296.09it/s]\n",
            "Epoch [97/100] | Train Loss: 0.032726 | Validation Loss: 0.008154\n",
            "Epoch 98/100 [Train]: 100% 9/9 [00:00<00:00, 100.10it/s]\n",
            "Epoch 98/100 [Valid]: 100% 3/3 [00:00<00:00, 303.54it/s]\n",
            "Epoch [98/100] | Train Loss: 0.032995 | Validation Loss: 0.013737\n",
            "Epoch 99/100 [Train]: 100% 9/9 [00:00<00:00, 106.65it/s]\n",
            "Epoch 99/100 [Valid]: 100% 3/3 [00:00<00:00, 295.07it/s]\n",
            "Epoch [99/100] | Train Loss: 0.031896 | Validation Loss: 0.005957\n",
            "Epoch 100/100 [Train]: 100% 9/9 [00:00<00:00, 106.25it/s]\n",
            "Epoch 100/100 [Valid]: 100% 3/3 [00:00<00:00, 293.52it/s]\n",
            "Epoch [100/100] | Train Loss: 0.030009 | Validation Loss: 0.003997\n",
            "\n",
            "--- Huấn luyện Hoàn tất ---\n",
            "✅ Model (Attention) tốt nhất đã được lưu tại epoch có Validation Loss = 0.003981\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Evalute lại***"
      ],
      "metadata": {
        "id": "GWVZ55rOXT42"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile evaluate.py\n",
        "# evaluate.py\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from config import (\n",
        "    NUM_BASE_FEATURES, NUM_SCALES, LSTM_HIDDEN_UNITS, LSTM_NUM_LAYERS,\n",
        "    ATTENTION_NUM_HEADS,\n",
        "    TRAINED_MODEL_PATH\n",
        ")\n",
        "#import model mới\n",
        "from model import MSLSTMAttention\n",
        "from dataset import get_data_loaders\n",
        "\n",
        "\n",
        "def run_evaluation():\n",
        "    \"\"\"Hàm chính để đánh giá mô hình trên tập test.\"\"\"\n",
        "\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    print(f\"Sử dụng thiết bị: {device.upper()}\")\n",
        "\n",
        "    # 1. Tải dữ liệu (chỉ cần test_loader và scaler)\n",
        "    _, test_loader, _, target_scaler = get_data_loaders()\n",
        "    if not test_loader:\n",
        "        print(\"Dừng chương trình vì không tải được dữ liệu.\")\n",
        "        return\n",
        "\n",
        "    # 2. Tải lại mô hình đã huấn luyện\n",
        "    print(f\"Đang tải mô hình từ: {TRAINED_MODEL_PATH}\")\n",
        "    # Sửa đổi: Khởi tạo đúng class model mới\n",
        "    model = MSLSTMAttention(\n",
        "        input_feature_size=NUM_BASE_FEATURES,\n",
        "        num_scales=NUM_SCALES,\n",
        "        lstm_hidden_units=LSTM_HIDDEN_UNITS,\n",
        "        lstm_num_layers=LSTM_NUM_LAYERS,\n",
        "        num_heads=ATTENTION_NUM_HEADS\n",
        "    )\n",
        "    try:\n",
        "        model.load_state_dict(torch.load(TRAINED_MODEL_PATH, map_location=device))\n",
        "        model.to(device)\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Lỗi: Không tìm thấy file model tại '{TRAINED_MODEL_PATH}'.\")\n",
        "        print(\"Vui lòng chạy train.py trước.\")\n",
        "        return\n",
        "\n",
        "    # 3. Đánh giá trên tập Test\n",
        "    model.eval()\n",
        "    predictions, actuals = [], []\n",
        "    with torch.no_grad():\n",
        "        for features, labels in test_loader:\n",
        "            features, labels = features.to(device), labels.to(device)\n",
        "            outputs = model(features)\n",
        "\n",
        "            predictions.extend(outputs.cpu().numpy())\n",
        "            actuals.extend(labels.cpu().numpy())\n",
        "\n",
        "    # 4. Giải chuẩn hóa để so sánh\n",
        "    predictions = np.array(predictions).reshape(-1, 1)\n",
        "    actuals = np.array(actuals).reshape(-1, 1)\n",
        "\n",
        "    original_predictions = target_scaler.inverse_transform(predictions)\n",
        "    original_actuals = target_scaler.inverse_transform(actuals)\n",
        "\n",
        "    # 5. Tính toán sai số và in kết quả\n",
        "    mae = np.mean(np.abs(original_predictions - original_actuals))\n",
        "    print(f\"\\n--- Kết quả Đánh giá trên Tập Test (Model + Attention) ---\")\n",
        "    print(f\"Sai số Trung bình Tuyệt đối (MAE): {mae:.4f} (điểm VN-Index)\")\n",
        "\n",
        "    # 6. Vẽ biểu đồ so sánh\n",
        "    plt.figure(figsize=(15, 6))\n",
        "    plt.plot(original_actuals, label='Giá trị Thực tế (Actuals)', color='blue', marker='.', linestyle='-')\n",
        "    plt.plot(original_predictions, label='Giá trị Dự đoán (Predictions)', color='red', linestyle='--')\n",
        "    plt.title('So sánh Giá trị Thực tế và Dự đoán (Model + Attention)')\n",
        "    plt.xlabel('Ngày (trong tập Test)')\n",
        "    plt.ylabel('Giá đóng cửa VN-Index')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    output_image_path = 'prediction_vs_actual_attention.png'\n",
        "    plt.savefig(output_image_path)\n",
        "    print(f\"✅ Đã lưu biểu đồ so sánh vào file '{output_image_path}'\")\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    run_evaluation()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j580yRKFXW2s",
        "outputId": "96a6aedc-99ed-4c39-817e-6dc224acb180"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting evaluate.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python evaluate.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rlk983tdXb7w",
        "outputId": "305dc1d1-73e2-4fbe-afe3-6c202fff094e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sử dụng thiết bị: CUDA\n",
            "Bắt đầu quá trình tạo DataLoader...\n",
            "-> Đang tạo đặc trưng đa quy mô với Wavelet (family: db4, level: 4)...\n",
            "-> Đang chuẩn hóa dữ liệu (scaling)...\n",
            "-> Đang tạo các chuỗi tuần tự với lookback window = 30...\n",
            "-> Kích thước tập Train: 270 mẫu\n",
            "-> Kích thước tập Test: 68 mẫu\n",
            "\n",
            "✅ Hoàn tất việc tạo DataLoader.\n",
            "Đang tải mô hình từ: mslstm_attention_tuned.pth\n",
            "\n",
            "--- Kết quả Đánh giá trên Tập Test (Model + Attention) ---\n",
            "Sai số Trung bình Tuyệt đối (MAE): 20.2117 (điểm VN-Index)\n",
            "✅ Đã lưu biểu đồ so sánh vào file 'prediction_vs_actual_attention.png'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Kết quả ra không ổn lắm, thử qua Hierachical để xem phân cấp phụ thuộc có ổn không?***"
      ],
      "metadata": {
        "id": "r3aD-qOaXuYI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile dataset.py\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pywt\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "from config import (\n",
        "    PROCESSED_DATA_PATH, LOOKBACK_WINDOW, TARGET_COLUMN,\n",
        "    WAVELET_FAMILY, WAVELET_LEVEL, TEST_SET_SIZE, BATCH_SIZE\n",
        ")\n",
        "\n",
        "def create_multiscale_features(data, wavelet_family, level):\n",
        "    \"\"\"Phân rã mỗi cột thành các thành phần đa quy mô bằng Wavelet.\"\"\"\n",
        "    coeffs_df_list = []\n",
        "    # Dữ liệu đầu vào `data` bây giờ sẽ là 30 cột gốc\n",
        "    for column in data.columns:\n",
        "        series = data[column].values\n",
        "        coeffs = pywt.wavedec(series, wavelet_family, level=level)\n",
        "        for i, c in enumerate(coeffs):\n",
        "            c_padded = np.pad(c, (0, len(data) - len(c)), 'constant')\n",
        "            coeffs_df_list.append(pd.DataFrame({f\"{column}_wavelet_L{i}\": c_padded}, index=data.index))\n",
        "    return pd.concat(coeffs_df_list, axis=1)\n",
        "\n",
        "def create_multitask_labels(df, target_col, lookback_window):\n",
        "    \"\"\"Tạo ra 3 loại nhãn cho bài toán đa nhiệm.\"\"\"\n",
        "    price_labels = df[target_col].values\n",
        "    trend_labels = (df[target_col].diff() > 0).astype(int).values\n",
        "    daily_returns = df[target_col].pct_change()\n",
        "    volatility_labels = daily_returns.rolling(window=lookback_window).std().values\n",
        "    return price_labels, trend_labels, volatility_labels\n",
        "\n",
        "def create_sequences(features, price_labels, trend_labels, vol_labels, lookback):\n",
        "    \"\"\"Tạo các chuỗi tuần tự cho cả features và 3 loại labels.\"\"\"\n",
        "    X, y_price, y_trend, y_vol = [], [], [], []\n",
        "    for i in range(len(features) - lookback):\n",
        "        X.append(features[i:(i + lookback)])\n",
        "        y_price.append(price_labels[i + lookback])\n",
        "        y_trend.append(trend_labels[i + lookback])\n",
        "        y_vol.append(vol_labels[i + lookback])\n",
        "    return np.array(X), np.array(y_price), np.array(y_trend), np.array(y_vol)\n",
        "\n",
        "class StockDataset(Dataset):\n",
        "    \"\"\"Dataset tùy chỉnh cho bài toán đa nhiệm.\"\"\"\n",
        "    def __init__(self, features, price_lbl, trend_lbl, vol_lbl):\n",
        "        self.features = torch.tensor(features, dtype=torch.float32)\n",
        "        self.price_lbl = torch.tensor(price_lbl, dtype=torch.float32)\n",
        "        self.trend_lbl = torch.tensor(trend_lbl, dtype=torch.float32)\n",
        "        self.vol_lbl = torch.tensor(vol_lbl, dtype=torch.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.features)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return (self.features[idx],\n",
        "                (self.price_lbl[idx], self.trend_lbl[idx], self.vol_lbl[idx]))\n",
        "\n",
        "def get_data_loaders():\n",
        "    \"\"\"Hàm chính để tải, xử lý và tạo ra các DataLoader đa nhiệm.\"\"\"\n",
        "    try:\n",
        "        df = pd.read_csv(PROCESSED_DATA_PATH, index_col='Date', parse_dates=True)\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Lỗi: Không tìm thấy file {PROCESSED_DATA_PATH}. Vui lòng chạy các bước trước.\")\n",
        "        return None, None, None, None\n",
        "\n",
        "    # === LOGIC ĐÃ ĐƯỢC SỬA LẠI ===\n",
        "    # 1. Tạo đặc trưng Wavelet từ TOÀN BỘ 30 cột gốc\n",
        "    # df ở đây có 30 cột đặc trưng đã tính toán (OHLCV + indicators cho 3 symbols)\n",
        "    multiscale_df = create_multiscale_features(df, WAVELET_FAMILY, WAVELET_LEVEL)\n",
        "    # => multiscale_df bây giờ sẽ có đúng 30 * 5 = 150 cột\n",
        "\n",
        "    # 2. Tạo các nhãn một cách riêng biệt\n",
        "    price_lbl, trend_lbl, vol_lbl = create_multitask_labels(df, TARGET_COLUMN, LOOKBACK_WINDOW)\n",
        "\n",
        "    # 3. Kết hợp features và labels vào một DataFrame để dropna đồng bộ\n",
        "    labels_df = pd.DataFrame({\n",
        "        'price_label': price_lbl,\n",
        "        'trend_label': trend_lbl,\n",
        "        'volatility_label': vol_lbl\n",
        "    }, index=df.index)\n",
        "\n",
        "    full_df = pd.concat([multiscale_df, labels_df], axis=1)\n",
        "    full_df.dropna(inplace=True)\n",
        "\n",
        "    # 4. Tách lại features và labels sau khi đã làm sạch\n",
        "    final_features = full_df.drop(columns=['price_label', 'trend_label', 'volatility_label']).values\n",
        "    final_price_lbl = full_df['price_label'].values\n",
        "    final_trend_lbl = full_df['trend_label'].values\n",
        "    final_vol_lbl = full_df['volatility_label'].values\n",
        "\n",
        "    # 5. Chuẩn hóa dữ liệu\n",
        "    feature_scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "    scaled_features = feature_scaler.fit_transform(final_features)\n",
        "\n",
        "    target_scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "    scaled_price_lbl = target_scaler.fit_transform(final_price_lbl.reshape(-1, 1)).flatten()\n",
        "\n",
        "    volatility_scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "    scaled_vol_lbl = volatility_scaler.fit_transform(final_vol_lbl.reshape(-1, 1)).flatten()\n",
        "\n",
        "    # 6. Tạo chuỗi và DataLoader như cũ\n",
        "    X, y_p, y_t, y_v = create_sequences(scaled_features, scaled_price_lbl, final_trend_lbl, scaled_vol_lbl, LOOKBACK_WINDOW)\n",
        "    split = int(len(X) * (1 - TEST_SET_SIZE))\n",
        "    train_dataset = StockDataset(X[:split], y_p[:split], y_t[:split], y_v[:split])\n",
        "    test_dataset = StockDataset(X[split:], y_p[split:], y_t[split:], y_v[split:])\n",
        "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "    print(\"✅ DataLoader đa nhiệm đã sẵn sàng.\")\n",
        "    return train_loader, test_loader, target_scaler, volatility_scaler"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GnRt_KHjYMxa",
        "outputId": "f62c8b5d-6490-49d3-b620-a61ee088b589"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting dataset.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python dataset.py"
      ],
      "metadata": {
        "id": "mF5M4Q1tYfk_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile config.py\n",
        "# config.py\n",
        "\n",
        "# --- Đường dẫn file ---\n",
        "PROCESSED_DATA_PATH = 'vn_indices_processed.csv'\n",
        "# Đây là file model cuối cùng\n",
        "TRAINED_MODEL_PATH = 'final_hierarchical_model.pth'\n",
        "\n",
        "# --- Tham số tạo Dataset ---\n",
        "LOOKBACK_WINDOW = 30\n",
        "# Cột mục tiêu chính vẫn là VNINDEX Close\n",
        "TARGET_COLUMN = 'VNINDEX_Close'\n",
        "TEST_SET_SIZE = 0.2\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# --- Tham số Biến đổi Wavelet ---\n",
        "WAVELET_FAMILY = 'db4'\n",
        "WAVELET_LEVEL = 4\n",
        "\n",
        "# --- Tham số Kiến trúc Model ---\n",
        "NUM_BASE_FEATURES = 30\n",
        "NUM_SCALES = WAVELET_LEVEL + 1\n",
        "LSTM_HIDDEN_UNITS = 128\n",
        "LSTM_NUM_LAYERS = 2\n",
        "ATTENTION_NUM_HEADS = 4\n",
        "\n",
        "# --- THAM SỐ MỚI CHO MULTI-TASK LEARNING ---\n",
        "LOSS_WEIGHTS = {\n",
        "    'price': 0.6,\n",
        "    'trend': 0.3,\n",
        "    'volatility': 0.1\n",
        "}\n",
        "\n",
        "# --- Tham số Huấn luyện ---\n",
        "LEARNING_RATE = 0.0005\n",
        "NUM_EPOCHS = 100"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCcg8fOPX5k-",
        "outputId": "d2147536-932f-4f82-a992-47e81059d3cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting config.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile model.py\n",
        "# model.py\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from config import BATCH_SIZE, LOOKBACK_WINDOW # Chỉ import những gì cần cho việc test\n",
        "\n",
        "class FinalModel(nn.Module):\n",
        "    def __init__(self, input_feature_size, num_scales, lstm_hidden_units, lstm_num_layers, num_heads):\n",
        "        super(FinalModel, self).__init__()\n",
        "\n",
        "        # SỬA LỖI: Lưu lại các tham số kiến trúc làm thuộc tính của class\n",
        "        self.input_feature_size = input_feature_size\n",
        "        self.num_scales = num_scales\n",
        "\n",
        "        # --- Phần thân chung (Shared Body) ---\n",
        "        self.lstm_branches = nn.ModuleList([\n",
        "            nn.LSTM(input_size=self.input_feature_size, hidden_size=lstm_hidden_units,\n",
        "                    num_layers=lstm_num_layers, batch_first=True, dropout=0.2 if lstm_num_layers > 1 else 0)\n",
        "            for _ in range(self.num_scales)\n",
        "        ])\n",
        "        self.attention = nn.MultiheadAttention(embed_dim=lstm_hidden_units * self.num_scales,\n",
        "                                             num_heads=num_heads, batch_first=True)\n",
        "\n",
        "        shared_feature_dim = lstm_hidden_units * self.num_scales\n",
        "        self.intermediate_layer = nn.Sequential(\n",
        "            nn.Linear(shared_feature_dim, shared_feature_dim // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3)\n",
        "        )\n",
        "\n",
        "        # --- Các Đầu ra Đa nhiệm (Multi-Task Heads) ---\n",
        "        self.price_head = nn.Linear(shared_feature_dim // 2, 1)\n",
        "        self.trend_head = nn.Sequential(\n",
        "            nn.Linear(shared_feature_dim // 2, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 1)\n",
        "        )\n",
        "        self.volatility_head = nn.Linear(shared_feature_dim // 2, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        branch_outputs = []\n",
        "        for i in range(self.num_scales):\n",
        "            # SỬA LỖI: Dùng thuộc tính của class (self.input_feature_size) thay vì biến toàn cục\n",
        "            start_idx = i * self.input_feature_size\n",
        "            end_idx = (i + 1) * self.input_feature_size\n",
        "\n",
        "            branch_input = x[:, :, start_idx:end_idx]\n",
        "            output, _ = self.lstm_branches[i](branch_input)\n",
        "            branch_outputs.append(output)\n",
        "\n",
        "        concatenated_output = torch.cat(branch_outputs, dim=2)\n",
        "        attention_output, _ = self.attention(concatenated_output, concatenated_output, concatenated_output)\n",
        "        shared_features = self.intermediate_layer(attention_output[:, -1, :])\n",
        "\n",
        "        price_prediction = self.price_head(shared_features)\n",
        "        trend_prediction = self.trend_head(shared_features)\n",
        "        volatility_prediction = self.volatility_head(shared_features)\n",
        "\n",
        "        return price_prediction.squeeze(), trend_prediction.squeeze(), volatility_prediction.squeeze()\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Đoạn test này cần import từ config\n",
        "    from config import NUM_BASE_FEATURES, NUM_SCALES, LSTM_HIDDEN_UNITS, LSTM_NUM_LAYERS, ATTENTION_NUM_HEADS\n",
        "\n",
        "    print(\"--- Kiểm tra kiến trúc Final Model (đã sửa lỗi) ---\")\n",
        "    model = FinalModel(\n",
        "        input_feature_size=NUM_BASE_FEATURES, num_scales=NUM_SCALES,\n",
        "        lstm_hidden_units=LSTM_HIDDEN_UNITS, lstm_num_layers=LSTM_NUM_LAYERS,\n",
        "        num_heads=ATTENTION_NUM_HEADS\n",
        "    )\n",
        "    print(model)\n",
        "    dummy_input = torch.randn(BATCH_SIZE, LOOKBACK_WINDOW, NUM_BASE_FEATURES * NUM_SCALES)\n",
        "    price, trend, volatility = model(dummy_input)\n",
        "\n",
        "    print(f\"\\nShape của input: {dummy_input.shape}\")\n",
        "    print(f\"Shape đầu ra Price: {price.shape}\")\n",
        "    print(f\"Shape đầu ra Trend: {trend.shape}\")\n",
        "    print(f\"Shape đầu ra Volatility: {volatility.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONA_-rfVYEEk",
        "outputId": "e7ff095c-67ee-479d-c638-d4084f3e6a20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting model.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python model.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQrbJw3DYG_a",
        "outputId": "8f9209f0-e829-4aa6-8eec-fd4077be2567"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Kiểm tra kiến trúc Final Model (đã sửa lỗi) ---\n",
            "FinalModel(\n",
            "  (lstm_branches): ModuleList(\n",
            "    (0-4): 5 x LSTM(30, 128, num_layers=2, batch_first=True, dropout=0.2)\n",
            "  )\n",
            "  (attention): MultiheadAttention(\n",
            "    (out_proj): NonDynamicallyQuantizableLinear(in_features=640, out_features=640, bias=True)\n",
            "  )\n",
            "  (intermediate_layer): Sequential(\n",
            "    (0): Linear(in_features=640, out_features=320, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.3, inplace=False)\n",
            "  )\n",
            "  (price_head): Linear(in_features=320, out_features=1, bias=True)\n",
            "  (trend_head): Sequential(\n",
            "    (0): Linear(in_features=320, out_features=32, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=32, out_features=1, bias=True)\n",
            "  )\n",
            "  (volatility_head): Linear(in_features=320, out_features=1, bias=True)\n",
            ")\n",
            "\n",
            "Shape của input: torch.Size([32, 30, 150])\n",
            "Shape đầu ra Price: torch.Size([32])\n",
            "Shape đầu ra Trend: torch.Size([32])\n",
            "Shape đầu ra Volatility: torch.Size([32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile train.py\n",
        "# train.py\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "\n",
        "from config import (\n",
        "    NUM_BASE_FEATURES, NUM_SCALES, LSTM_HIDDEN_UNITS, LSTM_NUM_LAYERS,\n",
        "    ATTENTION_NUM_HEADS, LOSS_WEIGHTS,\n",
        "    LEARNING_RATE, NUM_EPOCHS, TRAINED_MODEL_PATH\n",
        ")\n",
        "from model import FinalModel\n",
        "from dataset import get_data_loaders\n",
        "\n",
        "def run_training():\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    print(f\"Sử dụng thiết bị: {device.upper()}\")\n",
        "\n",
        "    train_loader, test_loader, _, _ = get_data_loaders()\n",
        "    if not train_loader: return\n",
        "\n",
        "    model = FinalModel(\n",
        "        input_feature_size=NUM_BASE_FEATURES, num_scales=NUM_SCALES,\n",
        "        lstm_hidden_units=LSTM_HIDDEN_UNITS, lstm_num_layers=LSTM_NUM_LAYERS,\n",
        "        num_heads=ATTENTION_NUM_HEADS\n",
        "    ).to(device)\n",
        "\n",
        "    # Định nghĩa các hàm loss cho từng nhiệm vụ\n",
        "    price_loss_fn = nn.MSELoss() # Cho giá (hồi quy)\n",
        "    # Dùng BCEWithLogitsLoss cho độ ổn định số học, nó đã tích hợp sẵn Sigmoid\n",
        "    trend_loss_fn = nn.BCEWithLogitsLoss() # Cho xu hướng (phân loại)\n",
        "    vol_loss_fn = nn.MSELoss() # Cho độ biến động (hồi quy)\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "    print(\"\\n--- Bắt đầu Huấn luyện Model Cuối cùng (Hierarchical + Multi-Task) ---\")\n",
        "    best_val_loss = float('inf')\n",
        "\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        # --- PHA HUẤN LUYỆN ---\n",
        "        model.train()\n",
        "        total_train_loss = 0\n",
        "        for features, (price_lbl, trend_lbl, vol_lbl) in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS} [Train]\"):\n",
        "            features = features.to(device)\n",
        "            price_lbl, trend_lbl, vol_lbl = price_lbl.to(device), trend_lbl.to(device), vol_lbl.to(device)\n",
        "\n",
        "            # Lấy 3 đầu ra từ model\n",
        "            price_pred, trend_pred, vol_pred = model(features)\n",
        "\n",
        "            # Tính toán loss cho từng nhiệm vụ\n",
        "            loss_p = price_loss_fn(price_pred, price_lbl)\n",
        "            loss_t = trend_loss_fn(trend_pred, trend_lbl)\n",
        "            loss_v = vol_loss_fn(vol_pred, vol_lbl)\n",
        "\n",
        "            # Tính loss tổng hợp dựa trên trọng số\n",
        "            total_loss = (LOSS_WEIGHTS['price'] * loss_p +\n",
        "                          LOSS_WEIGHTS['trend'] * loss_t +\n",
        "                          LOSS_WEIGHTS['volatility'] * loss_v)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            total_loss.backward()\n",
        "            optimizer.step()\n",
        "            total_train_loss += total_loss.item()\n",
        "\n",
        "        # --- PHA KIỂM ĐỊNH ---\n",
        "        model.eval()\n",
        "        total_val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for features, (price_lbl, trend_lbl, vol_lbl) in tqdm(test_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS} [Valid]\"):\n",
        "                features = features.to(device)\n",
        "                price_lbl, trend_lbl, vol_lbl = price_lbl.to(device), trend_lbl.to(device), vol_lbl.to(device)\n",
        "\n",
        "                price_pred, trend_pred, vol_pred = model(features)\n",
        "\n",
        "                loss_p = price_loss_fn(price_pred, price_lbl)\n",
        "                loss_t = trend_loss_fn(trend_pred, trend_lbl)\n",
        "                loss_v = vol_loss_fn(vol_pred, vol_lbl)\n",
        "\n",
        "                total_loss = (LOSS_WEIGHTS['price'] * loss_p +\n",
        "                              LOSS_WEIGHTS['trend'] * loss_t +\n",
        "                              LOSS_WEIGHTS['volatility'] * loss_v)\n",
        "                total_val_loss += total_loss.item()\n",
        "\n",
        "        avg_train_loss = total_train_loss / len(train_loader)\n",
        "        avg_val_loss = total_val_loss / len(test_loader)\n",
        "\n",
        "        print(f\"Epoch [{epoch+1:02d}/{NUM_EPOCHS}] | Train Loss: {avg_train_loss:.6f} | Validation Loss: {avg_val_loss:.6f}\")\n",
        "\n",
        "        if avg_val_loss < best_val_loss:\n",
        "            best_val_loss = avg_val_loss\n",
        "            torch.save(model.state_dict(), TRAINED_MODEL_PATH)\n",
        "            print(f\"   -> Validation loss cải thiện. Đã lưu model tốt nhất vào '{TRAINED_MODEL_PATH}'\")\n",
        "\n",
        "    print(f\"\\n--- Huấn luyện Hoàn tất ---\")\n",
        "    print(f\"✅ Model cuối cùng đã được lưu tại epoch có Validation Loss = {best_val_loss:.6f}\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    run_training()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4uQY0WgYmQP",
        "outputId": "0a5c458d-0efe-4b6d-c412-da6b08bbaa72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting train.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2ibCuSWYqOu",
        "outputId": "ce8d0447-1cc6-4013-ea15-76bc37626fcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sử dụng thiết bị: CUDA\n",
            "✅ DataLoader đa nhiệm đã sẵn sàng.\n",
            "\n",
            "--- Bắt đầu Huấn luyện Model Cuối cùng (Hierarchical + Multi-Task) ---\n",
            "Epoch 1/100 [Train]: 100% 8/8 [00:00<00:00, 13.22it/s]\n",
            "Epoch 1/100 [Valid]: 100% 2/2 [00:00<00:00, 142.25it/s]\n",
            "Epoch [01/100] | Train Loss: 0.287770 | Validation Loss: 0.220904\n",
            "   -> Validation loss cải thiện. Đã lưu model tốt nhất vào 'final_hierarchical_model.pth'\n",
            "Epoch 2/100 [Train]: 100% 8/8 [00:00<00:00, 66.65it/s]\n",
            "Epoch 2/100 [Valid]: 100% 2/2 [00:00<00:00, 148.36it/s]\n",
            "Epoch [02/100] | Train Loss: 0.250243 | Validation Loss: 0.207669\n",
            "   -> Validation loss cải thiện. Đã lưu model tốt nhất vào 'final_hierarchical_model.pth'\n",
            "Epoch 3/100 [Train]: 100% 8/8 [00:00<00:00, 86.52it/s]\n",
            "Epoch 3/100 [Valid]: 100% 2/2 [00:00<00:00, 240.69it/s]\n",
            "Epoch [03/100] | Train Loss: 0.243089 | Validation Loss: 0.214556\n",
            "Epoch 4/100 [Train]: 100% 8/8 [00:00<00:00, 87.85it/s]\n",
            "Epoch 4/100 [Valid]: 100% 2/2 [00:00<00:00, 246.72it/s]\n",
            "Epoch [04/100] | Train Loss: 0.244731 | Validation Loss: 0.208783\n",
            "Epoch 5/100 [Train]: 100% 8/8 [00:00<00:00, 88.75it/s]\n",
            "Epoch 5/100 [Valid]: 100% 2/2 [00:00<00:00, 243.62it/s]\n",
            "Epoch [05/100] | Train Loss: 0.246188 | Validation Loss: 0.207600\n",
            "   -> Validation loss cải thiện. Đã lưu model tốt nhất vào 'final_hierarchical_model.pth'\n",
            "Epoch 6/100 [Train]: 100% 8/8 [00:00<00:00, 87.90it/s]\n",
            "Epoch 6/100 [Valid]: 100% 2/2 [00:00<00:00, 238.46it/s]\n",
            "Epoch [06/100] | Train Loss: 0.244371 | Validation Loss: 0.214120\n",
            "Epoch 7/100 [Train]: 100% 8/8 [00:00<00:00, 92.30it/s]\n",
            "Epoch 7/100 [Valid]: 100% 2/2 [00:00<00:00, 251.56it/s]\n",
            "Epoch [07/100] | Train Loss: 0.241459 | Validation Loss: 0.207056\n",
            "   -> Validation loss cải thiện. Đã lưu model tốt nhất vào 'final_hierarchical_model.pth'\n",
            "Epoch 8/100 [Train]: 100% 8/8 [00:00<00:00, 74.22it/s]\n",
            "Epoch 8/100 [Valid]: 100% 2/2 [00:00<00:00, 249.97it/s]\n",
            "Epoch [08/100] | Train Loss: 0.240903 | Validation Loss: 0.212709\n",
            "Epoch 9/100 [Train]: 100% 8/8 [00:00<00:00, 81.76it/s]\n",
            "Epoch 9/100 [Valid]: 100% 2/2 [00:00<00:00, 252.06it/s]\n",
            "Epoch [09/100] | Train Loss: 0.243484 | Validation Loss: 0.208768\n",
            "Epoch 10/100 [Train]: 100% 8/8 [00:00<00:00, 92.04it/s]\n",
            "Epoch 10/100 [Valid]: 100% 2/2 [00:00<00:00, 252.05it/s]\n",
            "Epoch [10/100] | Train Loss: 0.243340 | Validation Loss: 0.213215\n",
            "Epoch 11/100 [Train]: 100% 8/8 [00:00<00:00, 92.45it/s]\n",
            "Epoch 11/100 [Valid]: 100% 2/2 [00:00<00:00, 247.04it/s]\n",
            "Epoch [11/100] | Train Loss: 0.243338 | Validation Loss: 0.206705\n",
            "   -> Validation loss cải thiện. Đã lưu model tốt nhất vào 'final_hierarchical_model.pth'\n",
            "Epoch 12/100 [Train]: 100% 8/8 [00:00<00:00, 90.44it/s]\n",
            "Epoch 12/100 [Valid]: 100% 2/2 [00:00<00:00, 256.04it/s]\n",
            "Epoch [12/100] | Train Loss: 0.244715 | Validation Loss: 0.210774\n",
            "Epoch 13/100 [Train]: 100% 8/8 [00:00<00:00, 90.59it/s]\n",
            "Epoch 13/100 [Valid]: 100% 2/2 [00:00<00:00, 241.91it/s]\n",
            "Epoch [13/100] | Train Loss: 0.241956 | Validation Loss: 0.210429\n",
            "Epoch 14/100 [Train]: 100% 8/8 [00:00<00:00, 89.11it/s]\n",
            "Epoch 14/100 [Valid]: 100% 2/2 [00:00<00:00, 248.53it/s]\n",
            "Epoch [14/100] | Train Loss: 0.242866 | Validation Loss: 0.207854\n",
            "Epoch 15/100 [Train]: 100% 8/8 [00:00<00:00, 90.86it/s]\n",
            "Epoch 15/100 [Valid]: 100% 2/2 [00:00<00:00, 251.93it/s]\n",
            "Epoch [15/100] | Train Loss: 0.242383 | Validation Loss: 0.207116\n",
            "Epoch 16/100 [Train]: 100% 8/8 [00:00<00:00, 91.27it/s]\n",
            "Epoch 16/100 [Valid]: 100% 2/2 [00:00<00:00, 243.59it/s]\n",
            "Epoch [16/100] | Train Loss: 0.243426 | Validation Loss: 0.209690\n",
            "Epoch 17/100 [Train]: 100% 8/8 [00:00<00:00, 88.55it/s]\n",
            "Epoch 17/100 [Valid]: 100% 2/2 [00:00<00:00, 249.53it/s]\n",
            "Epoch [17/100] | Train Loss: 0.240933 | Validation Loss: 0.208431\n",
            "Epoch 18/100 [Train]: 100% 8/8 [00:00<00:00, 72.29it/s]\n",
            "Epoch 18/100 [Valid]: 100% 2/2 [00:00<00:00, 251.49it/s]\n",
            "Epoch [18/100] | Train Loss: 0.242966 | Validation Loss: 0.212962\n",
            "Epoch 19/100 [Train]: 100% 8/8 [00:00<00:00, 90.08it/s]\n",
            "Epoch 19/100 [Valid]: 100% 2/2 [00:00<00:00, 253.21it/s]\n",
            "Epoch [19/100] | Train Loss: 0.242629 | Validation Loss: 0.210273\n",
            "Epoch 20/100 [Train]: 100% 8/8 [00:00<00:00, 85.27it/s]\n",
            "Epoch 20/100 [Valid]: 100% 2/2 [00:00<00:00, 254.90it/s]\n",
            "Epoch [20/100] | Train Loss: 0.244659 | Validation Loss: 0.207468\n",
            "Epoch 21/100 [Train]: 100% 8/8 [00:00<00:00, 94.75it/s]\n",
            "Epoch 21/100 [Valid]: 100% 2/2 [00:00<00:00, 253.23it/s]\n",
            "Epoch [21/100] | Train Loss: 0.242879 | Validation Loss: 0.209203\n",
            "Epoch 22/100 [Train]: 100% 8/8 [00:00<00:00, 90.34it/s]\n",
            "Epoch 22/100 [Valid]: 100% 2/2 [00:00<00:00, 245.95it/s]\n",
            "Epoch [22/100] | Train Loss: 0.242157 | Validation Loss: 0.213583\n",
            "Epoch 23/100 [Train]: 100% 8/8 [00:00<00:00, 84.99it/s]\n",
            "Epoch 23/100 [Valid]: 100% 2/2 [00:00<00:00, 244.79it/s]\n",
            "Epoch [23/100] | Train Loss: 0.242506 | Validation Loss: 0.209736\n",
            "Epoch 24/100 [Train]: 100% 8/8 [00:00<00:00, 92.43it/s]\n",
            "Epoch 24/100 [Valid]: 100% 2/2 [00:00<00:00, 248.37it/s]\n",
            "Epoch [24/100] | Train Loss: 0.243234 | Validation Loss: 0.207213\n",
            "Epoch 25/100 [Train]: 100% 8/8 [00:00<00:00, 89.39it/s]\n",
            "Epoch 25/100 [Valid]: 100% 2/2 [00:00<00:00, 236.35it/s]\n",
            "Epoch [25/100] | Train Loss: 0.242065 | Validation Loss: 0.212099\n",
            "Epoch 26/100 [Train]: 100% 8/8 [00:00<00:00, 90.38it/s]\n",
            "Epoch 26/100 [Valid]: 100% 2/2 [00:00<00:00, 246.30it/s]\n",
            "Epoch [26/100] | Train Loss: 0.242432 | Validation Loss: 0.209915\n",
            "Epoch 27/100 [Train]: 100% 8/8 [00:00<00:00, 91.78it/s]\n",
            "Epoch 27/100 [Valid]: 100% 2/2 [00:00<00:00, 235.32it/s]\n",
            "Epoch [27/100] | Train Loss: 0.242737 | Validation Loss: 0.206815\n",
            "Epoch 28/100 [Train]: 100% 8/8 [00:00<00:00, 87.96it/s]\n",
            "Epoch 28/100 [Valid]: 100% 2/2 [00:00<00:00, 250.77it/s]\n",
            "Epoch [28/100] | Train Loss: 0.243840 | Validation Loss: 0.212737\n",
            "Epoch 29/100 [Train]: 100% 8/8 [00:00<00:00, 71.16it/s]\n",
            "Epoch 29/100 [Valid]: 100% 2/2 [00:00<00:00, 236.20it/s]\n",
            "Epoch [29/100] | Train Loss: 0.242839 | Validation Loss: 0.211004\n",
            "Epoch 30/100 [Train]: 100% 8/8 [00:00<00:00, 93.06it/s]\n",
            "Epoch 30/100 [Valid]: 100% 2/2 [00:00<00:00, 246.89it/s]\n",
            "Epoch [30/100] | Train Loss: 0.241963 | Validation Loss: 0.209935\n",
            "Epoch 31/100 [Train]: 100% 8/8 [00:00<00:00, 91.61it/s]\n",
            "Epoch 31/100 [Valid]: 100% 2/2 [00:00<00:00, 251.00it/s]\n",
            "Epoch [31/100] | Train Loss: 0.242057 | Validation Loss: 0.207840\n",
            "Epoch 32/100 [Train]: 100% 8/8 [00:00<00:00, 92.96it/s]\n",
            "Epoch 32/100 [Valid]: 100% 2/2 [00:00<00:00, 250.71it/s]\n",
            "Epoch [32/100] | Train Loss: 0.242504 | Validation Loss: 0.212019\n",
            "Epoch 33/100 [Train]: 100% 8/8 [00:00<00:00, 90.52it/s]\n",
            "Epoch 33/100 [Valid]: 100% 2/2 [00:00<00:00, 249.88it/s]\n",
            "Epoch [33/100] | Train Loss: 0.241690 | Validation Loss: 0.210865\n",
            "Epoch 34/100 [Train]: 100% 8/8 [00:00<00:00, 88.70it/s]\n",
            "Epoch 34/100 [Valid]: 100% 2/2 [00:00<00:00, 249.29it/s]\n",
            "Epoch [34/100] | Train Loss: 0.242144 | Validation Loss: 0.207158\n",
            "Epoch 35/100 [Train]: 100% 8/8 [00:00<00:00, 91.65it/s]\n",
            "Epoch 35/100 [Valid]: 100% 2/2 [00:00<00:00, 247.95it/s]\n",
            "Epoch [35/100] | Train Loss: 0.244936 | Validation Loss: 0.207796\n",
            "Epoch 36/100 [Train]: 100% 8/8 [00:00<00:00, 89.58it/s]\n",
            "Epoch 36/100 [Valid]: 100% 2/2 [00:00<00:00, 245.60it/s]\n",
            "Epoch [36/100] | Train Loss: 0.240874 | Validation Loss: 0.211869\n",
            "Epoch 37/100 [Train]: 100% 8/8 [00:00<00:00, 88.28it/s]\n",
            "Epoch 37/100 [Valid]: 100% 2/2 [00:00<00:00, 228.48it/s]\n",
            "Epoch [37/100] | Train Loss: 0.241931 | Validation Loss: 0.207195\n",
            "Epoch 38/100 [Train]: 100% 8/8 [00:00<00:00, 89.83it/s]\n",
            "Epoch 38/100 [Valid]: 100% 2/2 [00:00<00:00, 241.70it/s]\n",
            "Epoch [38/100] | Train Loss: 0.242514 | Validation Loss: 0.210089\n",
            "Epoch 39/100 [Train]: 100% 8/8 [00:00<00:00, 69.52it/s]\n",
            "Epoch 39/100 [Valid]: 100% 2/2 [00:00<00:00, 251.85it/s]\n",
            "Epoch [39/100] | Train Loss: 0.241992 | Validation Loss: 0.216148\n",
            "Epoch 40/100 [Train]: 100% 8/8 [00:00<00:00, 91.08it/s]\n",
            "Epoch 40/100 [Valid]: 100% 2/2 [00:00<00:00, 248.68it/s]\n",
            "Epoch [40/100] | Train Loss: 0.243269 | Validation Loss: 0.206813\n",
            "Epoch 41/100 [Train]: 100% 8/8 [00:00<00:00, 94.79it/s]\n",
            "Epoch 41/100 [Valid]: 100% 2/2 [00:00<00:00, 243.30it/s]\n",
            "Epoch [41/100] | Train Loss: 0.244851 | Validation Loss: 0.209013\n",
            "Epoch 42/100 [Train]: 100% 8/8 [00:00<00:00, 88.67it/s]\n",
            "Epoch 42/100 [Valid]: 100% 2/2 [00:00<00:00, 244.97it/s]\n",
            "Epoch [42/100] | Train Loss: 0.242888 | Validation Loss: 0.212184\n",
            "Epoch 43/100 [Train]: 100% 8/8 [00:00<00:00, 82.87it/s]\n",
            "Epoch 43/100 [Valid]: 100% 2/2 [00:00<00:00, 247.88it/s]\n",
            "Epoch [43/100] | Train Loss: 0.241690 | Validation Loss: 0.207360\n",
            "Epoch 44/100 [Train]: 100% 8/8 [00:00<00:00, 92.97it/s]\n",
            "Epoch 44/100 [Valid]: 100% 2/2 [00:00<00:00, 252.82it/s]\n",
            "Epoch [44/100] | Train Loss: 0.242172 | Validation Loss: 0.212587\n",
            "Epoch 45/100 [Train]: 100% 8/8 [00:00<00:00, 93.35it/s]\n",
            "Epoch 45/100 [Valid]: 100% 2/2 [00:00<00:00, 241.40it/s]\n",
            "Epoch [45/100] | Train Loss: 0.242665 | Validation Loss: 0.208254\n",
            "Epoch 46/100 [Train]: 100% 8/8 [00:00<00:00, 87.56it/s]\n",
            "Epoch 46/100 [Valid]: 100% 2/2 [00:00<00:00, 224.88it/s]\n",
            "Epoch [46/100] | Train Loss: 0.242106 | Validation Loss: 0.207316\n",
            "Epoch 47/100 [Train]: 100% 8/8 [00:00<00:00, 88.86it/s]\n",
            "Epoch 47/100 [Valid]: 100% 2/2 [00:00<00:00, 245.09it/s]\n",
            "Epoch [47/100] | Train Loss: 0.241532 | Validation Loss: 0.207641\n",
            "Epoch 48/100 [Train]: 100% 8/8 [00:00<00:00, 89.96it/s]\n",
            "Epoch 48/100 [Valid]: 100% 2/2 [00:00<00:00, 234.78it/s]\n",
            "Epoch [48/100] | Train Loss: 0.241384 | Validation Loss: 0.206961\n",
            "Epoch 49/100 [Train]: 100% 8/8 [00:00<00:00, 70.56it/s]\n",
            "Epoch 49/100 [Valid]: 100% 2/2 [00:00<00:00, 255.63it/s]\n",
            "Epoch [49/100] | Train Loss: 0.242992 | Validation Loss: 0.207145\n",
            "Epoch 50/100 [Train]: 100% 8/8 [00:00<00:00, 93.75it/s]\n",
            "Epoch 50/100 [Valid]: 100% 2/2 [00:00<00:00, 243.04it/s]\n",
            "Epoch [50/100] | Train Loss: 0.243866 | Validation Loss: 0.214831\n",
            "Epoch 51/100 [Train]: 100% 8/8 [00:00<00:00, 92.24it/s]\n",
            "Epoch 51/100 [Valid]: 100% 2/2 [00:00<00:00, 249.32it/s]\n",
            "Epoch [51/100] | Train Loss: 0.242061 | Validation Loss: 0.207110\n",
            "Epoch 52/100 [Train]: 100% 8/8 [00:00<00:00, 93.49it/s]\n",
            "Epoch 52/100 [Valid]: 100% 2/2 [00:00<00:00, 248.82it/s]\n",
            "Epoch [52/100] | Train Loss: 0.242102 | Validation Loss: 0.209796\n",
            "Epoch 53/100 [Train]: 100% 8/8 [00:00<00:00, 93.44it/s]\n",
            "Epoch 53/100 [Valid]: 100% 2/2 [00:00<00:00, 230.93it/s]\n",
            "Epoch [53/100] | Train Loss: 0.241739 | Validation Loss: 0.206739\n",
            "Epoch 54/100 [Train]: 100% 8/8 [00:00<00:00, 89.17it/s]\n",
            "Epoch 54/100 [Valid]: 100% 2/2 [00:00<00:00, 241.77it/s]\n",
            "Epoch [54/100] | Train Loss: 0.239786 | Validation Loss: 0.208379\n",
            "Epoch 55/100 [Train]: 100% 8/8 [00:00<00:00, 93.66it/s]\n",
            "Epoch 55/100 [Valid]: 100% 2/2 [00:00<00:00, 253.77it/s]\n",
            "Epoch [55/100] | Train Loss: 0.242535 | Validation Loss: 0.219919\n",
            "Epoch 56/100 [Train]: 100% 8/8 [00:00<00:00, 91.31it/s]\n",
            "Epoch 56/100 [Valid]: 100% 2/2 [00:00<00:00, 246.85it/s]\n",
            "Epoch [56/100] | Train Loss: 0.241474 | Validation Loss: 0.212738\n",
            "Epoch 57/100 [Train]: 100% 8/8 [00:00<00:00, 90.44it/s]\n",
            "Epoch 57/100 [Valid]: 100% 2/2 [00:00<00:00, 240.89it/s]\n",
            "Epoch [57/100] | Train Loss: 0.238007 | Validation Loss: 0.218315\n",
            "Epoch 58/100 [Train]: 100% 8/8 [00:00<00:00, 91.07it/s]\n",
            "Epoch 58/100 [Valid]: 100% 2/2 [00:00<00:00, 239.43it/s]\n",
            "Epoch [58/100] | Train Loss: 0.237313 | Validation Loss: 0.211628\n",
            "Epoch 59/100 [Train]: 100% 8/8 [00:00<00:00, 87.57it/s]\n",
            "Epoch 59/100 [Valid]: 100% 2/2 [00:00<00:00, 249.93it/s]\n",
            "Epoch [59/100] | Train Loss: 0.246645 | Validation Loss: 0.222563\n",
            "Epoch 60/100 [Train]: 100% 8/8 [00:00<00:00, 75.80it/s]\n",
            "Epoch 60/100 [Valid]: 100% 2/2 [00:00<00:00, 227.20it/s]\n",
            "Epoch [60/100] | Train Loss: 0.244610 | Validation Loss: 0.209833\n",
            "Epoch 61/100 [Train]: 100% 8/8 [00:00<00:00, 91.51it/s]\n",
            "Epoch 61/100 [Valid]: 100% 2/2 [00:00<00:00, 239.26it/s]\n",
            "Epoch [61/100] | Train Loss: 0.241957 | Validation Loss: 0.207806\n",
            "Epoch 62/100 [Train]: 100% 8/8 [00:00<00:00, 92.13it/s]\n",
            "Epoch 62/100 [Valid]: 100% 2/2 [00:00<00:00, 246.99it/s]\n",
            "Epoch [62/100] | Train Loss: 0.241688 | Validation Loss: 0.211908\n",
            "Epoch 63/100 [Train]: 100% 8/8 [00:00<00:00, 84.20it/s]\n",
            "Epoch 63/100 [Valid]: 100% 2/2 [00:00<00:00, 247.27it/s]\n",
            "Epoch [63/100] | Train Loss: 0.242445 | Validation Loss: 0.212168\n",
            "Epoch 64/100 [Train]: 100% 8/8 [00:00<00:00, 90.06it/s]\n",
            "Epoch 64/100 [Valid]: 100% 2/2 [00:00<00:00, 246.35it/s]\n",
            "Epoch [64/100] | Train Loss: 0.242466 | Validation Loss: 0.207167\n",
            "Epoch 65/100 [Train]: 100% 8/8 [00:00<00:00, 79.23it/s]\n",
            "Epoch 65/100 [Valid]: 100% 2/2 [00:00<00:00, 206.95it/s]\n",
            "Epoch [65/100] | Train Loss: 0.242096 | Validation Loss: 0.207574\n",
            "Epoch 66/100 [Train]: 100% 8/8 [00:00<00:00, 85.72it/s]\n",
            "Epoch 66/100 [Valid]: 100% 2/2 [00:00<00:00, 244.03it/s]\n",
            "Epoch [66/100] | Train Loss: 0.241925 | Validation Loss: 0.212066\n",
            "Epoch 67/100 [Train]: 100% 8/8 [00:00<00:00, 89.51it/s]\n",
            "Epoch 67/100 [Valid]: 100% 2/2 [00:00<00:00, 213.52it/s]\n",
            "Epoch [67/100] | Train Loss: 0.241323 | Validation Loss: 0.207450\n",
            "Epoch 68/100 [Train]: 100% 8/8 [00:00<00:00, 80.80it/s]\n",
            "Epoch 68/100 [Valid]: 100% 2/2 [00:00<00:00, 243.22it/s]\n",
            "Epoch [68/100] | Train Loss: 0.241250 | Validation Loss: 0.207282\n",
            "Epoch 69/100 [Train]: 100% 8/8 [00:00<00:00, 86.87it/s]\n",
            "Epoch 69/100 [Valid]: 100% 2/2 [00:00<00:00, 249.47it/s]\n",
            "Epoch [69/100] | Train Loss: 0.240878 | Validation Loss: 0.207090\n",
            "Epoch 70/100 [Train]: 100% 8/8 [00:00<00:00, 79.53it/s]\n",
            "Epoch 70/100 [Valid]: 100% 2/2 [00:00<00:00, 256.02it/s]\n",
            "Epoch [70/100] | Train Loss: 0.243024 | Validation Loss: 0.207296\n",
            "Epoch 71/100 [Train]: 100% 8/8 [00:00<00:00, 93.80it/s]\n",
            "Epoch 71/100 [Valid]: 100% 2/2 [00:00<00:00, 243.18it/s]\n",
            "Epoch [71/100] | Train Loss: 0.243736 | Validation Loss: 0.208182\n",
            "Epoch 72/100 [Train]: 100% 8/8 [00:00<00:00, 91.29it/s]\n",
            "Epoch 72/100 [Valid]: 100% 2/2 [00:00<00:00, 243.54it/s]\n",
            "Epoch [72/100] | Train Loss: 0.242401 | Validation Loss: 0.208034\n",
            "Epoch 73/100 [Train]: 100% 8/8 [00:00<00:00, 92.72it/s]\n",
            "Epoch 73/100 [Valid]: 100% 2/2 [00:00<00:00, 246.80it/s]\n",
            "Epoch [73/100] | Train Loss: 0.241451 | Validation Loss: 0.208731\n",
            "Epoch 74/100 [Train]: 100% 8/8 [00:00<00:00, 94.90it/s]\n",
            "Epoch 74/100 [Valid]: 100% 2/2 [00:00<00:00, 240.16it/s]\n",
            "Epoch [74/100] | Train Loss: 0.241216 | Validation Loss: 0.209736\n",
            "Epoch 75/100 [Train]: 100% 8/8 [00:00<00:00, 89.98it/s]\n",
            "Epoch 75/100 [Valid]: 100% 2/2 [00:00<00:00, 251.28it/s]\n",
            "Epoch [75/100] | Train Loss: 0.241635 | Validation Loss: 0.208838\n",
            "Epoch 76/100 [Train]: 100% 8/8 [00:00<00:00, 82.76it/s]\n",
            "Epoch 76/100 [Valid]: 100% 2/2 [00:00<00:00, 213.53it/s]\n",
            "Epoch [76/100] | Train Loss: 0.241392 | Validation Loss: 0.207521\n",
            "Epoch 77/100 [Train]: 100% 8/8 [00:00<00:00, 87.23it/s]\n",
            "Epoch 77/100 [Valid]: 100% 2/2 [00:00<00:00, 225.09it/s]\n",
            "Epoch [77/100] | Train Loss: 0.240849 | Validation Loss: 0.218892\n",
            "Epoch 78/100 [Train]: 100% 8/8 [00:00<00:00, 94.20it/s]\n",
            "Epoch 78/100 [Valid]: 100% 2/2 [00:00<00:00, 246.48it/s]\n",
            "Epoch [78/100] | Train Loss: 0.245068 | Validation Loss: 0.209630\n",
            "Epoch 79/100 [Train]: 100% 8/8 [00:00<00:00, 92.47it/s]\n",
            "Epoch 79/100 [Valid]: 100% 2/2 [00:00<00:00, 235.82it/s]\n",
            "Epoch [79/100] | Train Loss: 0.244308 | Validation Loss: 0.206951\n",
            "Epoch 80/100 [Train]: 100% 8/8 [00:00<00:00, 79.75it/s]\n",
            "Epoch 80/100 [Valid]: 100% 2/2 [00:00<00:00, 248.54it/s]\n",
            "Epoch [80/100] | Train Loss: 0.241130 | Validation Loss: 0.211463\n",
            "Epoch 81/100 [Train]: 100% 8/8 [00:00<00:00, 92.76it/s]\n",
            "Epoch 81/100 [Valid]: 100% 2/2 [00:00<00:00, 253.63it/s]\n",
            "Epoch [81/100] | Train Loss: 0.239249 | Validation Loss: 0.214535\n",
            "Epoch 82/100 [Train]: 100% 8/8 [00:00<00:00, 91.11it/s]\n",
            "Epoch 82/100 [Valid]: 100% 2/2 [00:00<00:00, 249.94it/s]\n",
            "Epoch [82/100] | Train Loss: 0.242016 | Validation Loss: 0.211358\n",
            "Epoch 83/100 [Train]: 100% 8/8 [00:00<00:00, 87.49it/s]\n",
            "Epoch 83/100 [Valid]: 100% 2/2 [00:00<00:00, 244.36it/s]\n",
            "Epoch [83/100] | Train Loss: 0.242576 | Validation Loss: 0.207373\n",
            "Epoch 84/100 [Train]: 100% 8/8 [00:00<00:00, 91.52it/s]\n",
            "Epoch 84/100 [Valid]: 100% 2/2 [00:00<00:00, 250.43it/s]\n",
            "Epoch [84/100] | Train Loss: 0.244205 | Validation Loss: 0.209236\n",
            "Epoch 85/100 [Train]: 100% 8/8 [00:00<00:00, 86.04it/s]\n",
            "Epoch 85/100 [Valid]: 100% 2/2 [00:00<00:00, 241.28it/s]\n",
            "Epoch [85/100] | Train Loss: 0.243732 | Validation Loss: 0.217229\n",
            "Epoch 86/100 [Train]: 100% 8/8 [00:00<00:00, 77.99it/s]\n",
            "Epoch 86/100 [Valid]: 100% 2/2 [00:00<00:00, 249.73it/s]\n",
            "Epoch [86/100] | Train Loss: 0.243316 | Validation Loss: 0.207946\n",
            "Epoch 87/100 [Train]: 100% 8/8 [00:00<00:00, 85.53it/s]\n",
            "Epoch 87/100 [Valid]: 100% 2/2 [00:00<00:00, 240.62it/s]\n",
            "Epoch [87/100] | Train Loss: 0.241975 | Validation Loss: 0.208688\n",
            "Epoch 88/100 [Train]: 100% 8/8 [00:00<00:00, 91.88it/s]\n",
            "Epoch 88/100 [Valid]: 100% 2/2 [00:00<00:00, 246.71it/s]\n",
            "Epoch [88/100] | Train Loss: 0.242925 | Validation Loss: 0.212133\n",
            "Epoch 89/100 [Train]: 100% 8/8 [00:00<00:00, 89.94it/s]\n",
            "Epoch 89/100 [Valid]: 100% 2/2 [00:00<00:00, 249.42it/s]\n",
            "Epoch [89/100] | Train Loss: 0.241876 | Validation Loss: 0.208002\n",
            "Epoch 90/100 [Train]: 100% 8/8 [00:00<00:00, 89.62it/s]\n",
            "Epoch 90/100 [Valid]: 100% 2/2 [00:00<00:00, 183.37it/s]\n",
            "Epoch [90/100] | Train Loss: 0.240915 | Validation Loss: 0.209495\n",
            "Epoch 91/100 [Train]: 100% 8/8 [00:00<00:00, 80.42it/s]\n",
            "Epoch 91/100 [Valid]: 100% 2/2 [00:00<00:00, 250.29it/s]\n",
            "Epoch [91/100] | Train Loss: 0.241713 | Validation Loss: 0.210447\n",
            "Epoch 92/100 [Train]: 100% 8/8 [00:00<00:00, 91.45it/s]\n",
            "Epoch 92/100 [Valid]: 100% 2/2 [00:00<00:00, 242.54it/s]\n",
            "Epoch [92/100] | Train Loss: 0.239538 | Validation Loss: 0.207288\n",
            "Epoch 93/100 [Train]: 100% 8/8 [00:00<00:00, 92.46it/s]\n",
            "Epoch 93/100 [Valid]: 100% 2/2 [00:00<00:00, 252.29it/s]\n",
            "Epoch [93/100] | Train Loss: 0.239820 | Validation Loss: 0.210353\n",
            "Epoch 94/100 [Train]: 100% 8/8 [00:00<00:00, 86.37it/s]\n",
            "Epoch 94/100 [Valid]: 100% 2/2 [00:00<00:00, 254.39it/s]\n",
            "Epoch [94/100] | Train Loss: 0.238581 | Validation Loss: 0.207769\n",
            "Epoch 95/100 [Train]: 100% 8/8 [00:00<00:00, 89.47it/s]\n",
            "Epoch 95/100 [Valid]: 100% 2/2 [00:00<00:00, 243.69it/s]\n",
            "Epoch [95/100] | Train Loss: 0.238985 | Validation Loss: 0.254745\n",
            "Epoch 96/100 [Train]: 100% 8/8 [00:00<00:00, 78.04it/s]\n",
            "Epoch 96/100 [Valid]: 100% 2/2 [00:00<00:00, 229.86it/s]\n",
            "Epoch [96/100] | Train Loss: 0.247846 | Validation Loss: 0.215098\n",
            "Epoch 97/100 [Train]: 100% 8/8 [00:00<00:00, 90.58it/s]\n",
            "Epoch 97/100 [Valid]: 100% 2/2 [00:00<00:00, 250.53it/s]\n",
            "Epoch [97/100] | Train Loss: 0.242486 | Validation Loss: 0.207760\n",
            "Epoch 98/100 [Train]: 100% 8/8 [00:00<00:00, 93.81it/s]\n",
            "Epoch 98/100 [Valid]: 100% 2/2 [00:00<00:00, 243.88it/s]\n",
            "Epoch [98/100] | Train Loss: 0.240618 | Validation Loss: 0.208304\n",
            "Epoch 99/100 [Train]: 100% 8/8 [00:00<00:00, 62.41it/s]\n",
            "Epoch 99/100 [Valid]: 100% 2/2 [00:00<00:00, 205.44it/s]\n",
            "Epoch [99/100] | Train Loss: 0.241437 | Validation Loss: 0.209335\n",
            "Epoch 100/100 [Train]: 100% 8/8 [00:00<00:00, 59.47it/s]\n",
            "Epoch 100/100 [Valid]: 100% 2/2 [00:00<00:00, 195.51it/s]\n",
            "Epoch [100/100] | Train Loss: 0.240706 | Validation Loss: 0.209151\n",
            "\n",
            "--- Huấn luyện Hoàn tất ---\n",
            "✅ Model cuối cùng đã được lưu tại epoch có Validation Loss = 0.206705\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile evaluate.py\n",
        "# evaluate.py\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "from config import (\n",
        "    NUM_BASE_FEATURES, NUM_SCALES, LSTM_HIDDEN_UNITS, LSTM_NUM_LAYERS,\n",
        "    ATTENTION_NUM_HEADS, TRAINED_MODEL_PATH\n",
        ")\n",
        "from model import FinalModel\n",
        "from dataset import get_data_loaders\n",
        "\n",
        "def run_evaluation():\n",
        "    \"\"\"Hàm chính để đánh giá mô hình đa nhiệm trên tập test.\"\"\"\n",
        "\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    print(f\"Sử dụng thiết bị: {device.upper()}\")\n",
        "\n",
        "    # 1. Tải dữ liệu\n",
        "    _, test_loader, target_scaler, volatility_scaler = get_data_loaders()\n",
        "    if not test_loader:\n",
        "        print(\"Dừng chương trình vì không tải được dữ liệu.\")\n",
        "        return\n",
        "\n",
        "    # 2. Tải lại mô hình đã huấn luyện\n",
        "    print(f\"Đang tải mô hình từ: {TRAINED_MODEL_PATH}\")\n",
        "    model = FinalModel(\n",
        "        input_feature_size=NUM_BASE_FEATURES, num_scales=NUM_SCALES,\n",
        "        lstm_hidden_units=LSTM_HIDDEN_UNITS, lstm_num_layers=LSTM_NUM_LAYERS,\n",
        "        num_heads=ATTENTION_NUM_HEADS\n",
        "    )\n",
        "    try:\n",
        "        model.load_state_dict(torch.load(TRAINED_MODEL_PATH, map_location=device))\n",
        "        model.to(device)\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Lỗi: Không tìm thấy file model tại '{TRAINED_MODEL_PATH}'. Vui lòng chạy train.py trước.\")\n",
        "        return\n",
        "\n",
        "    # 3. Đánh giá trên tập Test\n",
        "    model.eval()\n",
        "    all_price_preds, all_trend_preds, all_vol_preds = [], [], []\n",
        "    all_price_lbls, all_trend_lbls, all_vol_lbls = [], [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for features, (price_lbl, trend_lbl, vol_lbl) in test_loader:\n",
        "            features = features.to(device)\n",
        "\n",
        "            price_pred, trend_pred, vol_pred = model(features)\n",
        "\n",
        "            # Lưu lại kết quả dự đoán và nhãn thực tế\n",
        "            all_price_preds.extend(price_pred.cpu().numpy())\n",
        "            all_trend_preds.extend(trend_pred.cpu().numpy())\n",
        "\n",
        "            all_price_lbls.extend(price_lbl.numpy())\n",
        "            all_trend_lbls.extend(trend_lbl.numpy())\n",
        "\n",
        "    # 4. Xử lý và Giải chuẩn hóa\n",
        "    # --- Xử lý cho Dự đoán Giá ---\n",
        "    price_preds = np.array(all_price_preds).reshape(-1, 1)\n",
        "    price_actuals = np.array(all_price_lbls).reshape(-1, 1)\n",
        "    original_price_preds = target_scaler.inverse_transform(price_preds)\n",
        "    original_price_actuals = target_scaler.inverse_transform(price_actuals)\n",
        "\n",
        "    # --- Xử lý cho Dự đoán Xu hướng ---\n",
        "    # Chuyển đổi output của model (logits) thành xác suất rồi thành nhãn (0 hoặc 1)\n",
        "    trend_probs = torch.sigmoid(torch.tensor(all_trend_preds)).numpy()\n",
        "    trend_preds_labels = (trend_probs > 0.5).astype(int)\n",
        "    trend_actuals = np.array(all_trend_lbls)\n",
        "\n",
        "    # 5. Tính toán các chỉ số và in kết quả\n",
        "    print(\"\\n--- Kết quả Đánh giá trên Tập Test (Model Cuối cùng) ---\")\n",
        "\n",
        "    # --- Nhiệm vụ 1: Dự đoán Giá ---\n",
        "    mae = np.mean(np.abs(original_price_preds - original_price_actuals))\n",
        "    print(f\"🎯 [Giá] Sai số Trung bình Tuyệt đối (MAE): {mae:.4f} (điểm VN-Index)\")\n",
        "\n",
        "    # --- Nhiệm vụ 2: Dự đoán Xu hướng ---\n",
        "    accuracy = accuracy_score(trend_actuals, trend_preds_labels)\n",
        "    print(f\"🎯 [Xu hướng] Độ chính xác (Accuracy): {accuracy * 100:.2f}%\")\n",
        "\n",
        "    # 6. Vẽ biểu đồ\n",
        "    # --- Biểu đồ 1: So sánh Giá ---\n",
        "    plt.figure(figsize=(15, 6))\n",
        "    plt.plot(original_price_actuals, label='Giá trị Thực tế', color='blue', marker='.', linestyle='-')\n",
        "    plt.plot(original_price_preds, label='Giá trị Dự đoán', color='red', linestyle='--')\n",
        "    plt.title('So sánh Giá trị Thực tế và Dự đoán (Model Cuối cùng)')\n",
        "    plt.xlabel('Ngày (trong tập Test)')\n",
        "    plt.ylabel('Giá đóng cửa VN-Index')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig('final_prediction_vs_actual.png')\n",
        "    print(\"\\n✅ Đã lưu biểu đồ so sánh giá vào file 'final_prediction_vs_actual.png'\")\n",
        "\n",
        "    # --- Biểu đồ 2: Ma trận nhầm lẫn cho Xu hướng ---\n",
        "    cm = confusion_matrix(trend_actuals, trend_preds_labels)\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Giảm', 'Tăng'])\n",
        "    fig, ax = plt.subplots(figsize=(6, 6))\n",
        "    disp.plot(ax=ax, cmap=plt.cm.Blues)\n",
        "    ax.set_title('Ma trận Nhầm lẫn - Dự đoán Xu hướng')\n",
        "    plt.savefig('final_confusion_matrix.png')\n",
        "    print(\"✅ Đã lưu ma trận nhầm lẫn vào file 'final_confusion_matrix.png'\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    run_evaluation()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zjJkk5rZpZH",
        "outputId": "a9707295-753d-48ac-c6d5-031e905ae05f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting evaluate.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python evaluate.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hphM-ljBZqXv",
        "outputId": "1f41edca-111c-46c4-f957-7dcadf7a8a7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sử dụng thiết bị: CUDA\n",
            "✅ DataLoader đa nhiệm đã sẵn sàng.\n",
            "Đang tải mô hình từ: final_hierarchical_model.pth\n",
            "\n",
            "--- Kết quả Đánh giá trên Tập Test (Model Cuối cùng) ---\n",
            "🎯 [Giá] Sai số Trung bình Tuyệt đối (MAE): 18.6659 (điểm VN-Index)\n",
            "🎯 [Xu hướng] Độ chính xác (Accuracy): 61.29%\n",
            "\n",
            "✅ Đã lưu biểu đồ so sánh giá vào file 'final_prediction_vs_actual.png'\n",
            "✅ Đã lưu ma trận nhầm lẫn vào file 'final_confusion_matrix.png'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Bây giờ áp dụng tự động kỹ thuật tối ưu tham số***"
      ],
      "metadata": {
        "id": "WJiVhwjScBL4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile model.py\n",
        "# model.py\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from config import BATCH_SIZE, LOOKBACK_WINDOW # Chỉ import những gì cần cho việc test\n",
        "\n",
        "class FinalModel(nn.Module):\n",
        "    def __init__(self, input_feature_size, num_scales, lstm_hidden_units, lstm_num_layers, num_heads):\n",
        "        super(FinalModel, self).__init__()\n",
        "\n",
        "        # SỬA LỖI: Lưu lại các tham số kiến trúc làm thuộc tính của class\n",
        "        self.input_feature_size = input_feature_size\n",
        "        self.num_scales = num_scales\n",
        "\n",
        "        # --- Phần thân chung (Shared Body) ---\n",
        "        self.lstm_branches = nn.ModuleList([\n",
        "            nn.LSTM(input_size=self.input_feature_size, hidden_size=lstm_hidden_units,\n",
        "                    num_layers=lstm_num_layers, batch_first=True, dropout=0.2 if lstm_num_layers > 1 else 0)\n",
        "            for _ in range(self.num_scales)\n",
        "        ])\n",
        "        self.attention = nn.MultiheadAttention(embed_dim=lstm_hidden_units * self.num_scales,\n",
        "                                             num_heads=num_heads, batch_first=True)\n",
        "\n",
        "        shared_feature_dim = lstm_hidden_units * self.num_scales\n",
        "        self.intermediate_layer = nn.Sequential(\n",
        "            nn.Linear(shared_feature_dim, shared_feature_dim // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3)\n",
        "        )\n",
        "\n",
        "        # --- Các Đầu ra Đa nhiệm (Multi-Task Heads) ---\n",
        "        self.price_head = nn.Linear(shared_feature_dim // 2, 1)\n",
        "        self.trend_head = nn.Sequential(\n",
        "            nn.Linear(shared_feature_dim // 2, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 1)\n",
        "        )\n",
        "        self.volatility_head = nn.Linear(shared_feature_dim // 2, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        branch_outputs = []\n",
        "        for i in range(self.num_scales):\n",
        "            # SỬA LỖI: Dùng thuộc tính của class (self.input_feature_size) thay vì biến toàn cục\n",
        "            start_idx = i * self.input_feature_size\n",
        "            end_idx = (i + 1) * self.input_feature_size\n",
        "\n",
        "            branch_input = x[:, :, start_idx:end_idx]\n",
        "            output, _ = self.lstm_branches[i](branch_input)\n",
        "            branch_outputs.append(output)\n",
        "\n",
        "        concatenated_output = torch.cat(branch_outputs, dim=2)\n",
        "        attention_output, _ = self.attention(concatenated_output, concatenated_output, concatenated_output)\n",
        "        shared_features = self.intermediate_layer(attention_output[:, -1, :])\n",
        "\n",
        "        price_prediction = self.price_head(shared_features)\n",
        "        trend_prediction = self.trend_head(shared_features)\n",
        "        volatility_prediction = self.volatility_head(shared_features)\n",
        "\n",
        "        return price_prediction.squeeze(), trend_prediction.squeeze(), volatility_prediction.squeeze()\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Đoạn test này cần import từ config\n",
        "    from config import NUM_BASE_FEATURES, NUM_SCALES, LSTM_HIDDEN_UNITS, LSTM_NUM_LAYERS, ATTENTION_NUM_HEADS\n",
        "\n",
        "    print(\"--- Kiểm tra kiến trúc Final Model (đã sửa lỗi) ---\")\n",
        "    model = FinalModel(\n",
        "        input_feature_size=NUM_BASE_FEATURES, num_scales=NUM_SCALES,\n",
        "        lstm_hidden_units=LSTM_HIDDEN_UNITS, lstm_num_layers=LSTM_NUM_LAYERS,\n",
        "        num_heads=ATTENTION_NUM_HEADS\n",
        "    )\n",
        "    print(model)\n",
        "    dummy_input = torch.randn(BATCH_SIZE, LOOKBACK_WINDOW, NUM_BASE_FEATURES * NUM_SCALES)\n",
        "    price, trend, volatility = model(dummy_input)\n",
        "\n",
        "    print(f\"\\nShape của input: {dummy_input.shape}\")\n",
        "    print(f\"Shape đầu ra Price: {price.shape}\")\n",
        "    print(f\"Shape đầu ra Trend: {trend.shape}\")\n",
        "    print(f\"Shape đầu ra Volatility: {volatility.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gw7VJVcyd_l2",
        "outputId": "32327270-caa9-46a7-b101-e437b19651e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting model.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile config.py\n",
        "# config.py\n",
        "\n",
        "# --- Đường dẫn file ---\n",
        "# SỬA LỖI: Trỏ đến đúng file dữ liệu đã được xử lý (có 30 cột)\n",
        "PROCESSED_DATA_PATH = 'vn_indices_processed.csv'\n",
        "TRAINED_MODEL_PATH = 'final_optimized_model.pth'\n",
        "\n",
        "# --- Tham số tạo Dataset ---\n",
        "LOOKBACK_WINDOW = 30\n",
        "TARGET_COLUMN = 'VNINDEX_Close'\n",
        "TEST_SET_SIZE = 0.2\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# --- Tham số Biến đổi Wavelet ---\n",
        "WAVELET_FAMILY = 'db4'\n",
        "WAVELET_LEVEL = 4\n",
        "\n",
        "# --- Tham số Kiến trúc Mặc định ---\n",
        "NUM_BASE_FEATURES = 30\n",
        "NUM_SCALES = WAVELET_LEVEL + 1\n",
        "LSTM_HIDDEN_UNITS = 128\n",
        "LSTM_NUM_LAYERS = 2\n",
        "ATTENTION_NUM_HEADS = 4\n",
        "\n",
        "# --- Tham số cho Multi-Task Learning ---\n",
        "LOSS_WEIGHTS = {\n",
        "    'price': 0.6,\n",
        "    'trend': 0.3,\n",
        "    'volatility': 0.1\n",
        "}\n",
        "\n",
        "# --- Cấu hình cho Optuna ---\n",
        "OPTUNA_N_TRIALS = 50"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmuDAV-_cp8l",
        "outputId": "7681d90e-6397-432e-bef9-3ae288d74ecc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting config.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna -q"
      ],
      "metadata": {
        "id": "Pt92_k8vcKn7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile train_tuner.py\n",
        "# train_tuner.py\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import optuna\n",
        "import numpy as np\n",
        "\n",
        "from config import (\n",
        "    NUM_BASE_FEATURES, NUM_SCALES, LOSS_WEIGHTS,\n",
        "    OPTUNA_N_TRIALS, TRAINED_MODEL_PATH\n",
        ")\n",
        "from model import FinalModel\n",
        "from dataset import get_data_loaders\n",
        "\n",
        "# 1. Định nghĩa Hàm Mục tiêu (Objective Function)\n",
        "def objective(trial):\n",
        "    \"\"\"\n",
        "    Hàm này được Optuna gọi trong mỗi lần thử nghiệm.\n",
        "    Nó sẽ huấn luyện mô hình với bộ tham số do `trial` đề xuất và trả về val_loss.\n",
        "    \"\"\"\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "    # --- Optuna đề xuất các siêu tham số ---\n",
        "    # `trial.suggest_` sẽ chọn các giá trị trong khoảng cho trước\n",
        "    lstm_hidden = trial.suggest_int(\"lstm_hidden_units\", 64, 256, step=32)\n",
        "    lstm_layers = trial.suggest_int(\"lstm_num_layers\", 1, 3)\n",
        "    attention_heads = trial.suggest_categorical(\"attention_num_heads\", [2, 4, 8])\n",
        "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-4, 1e-2, log=True)\n",
        "\n",
        "    # 2. Tải dữ liệu và khởi tạo model với các tham số mới\n",
        "    train_loader, test_loader, _, _ = get_data_loaders()\n",
        "    model = FinalModel(\n",
        "        input_feature_size=NUM_BASE_FEATURES,\n",
        "        num_scales=NUM_SCALES,\n",
        "        lstm_hidden_units=lstm_hidden,\n",
        "        lstm_num_layers=lstm_layers,\n",
        "        num_heads=attention_heads\n",
        "    ).to(device)\n",
        "\n",
        "    price_loss_fn = nn.MSELoss()\n",
        "    trend_loss_fn = nn.BCEWithLogitsLoss()\n",
        "    vol_loss_fn = nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    # Giảm số epoch trong mỗi lần thử để chạy nhanh hơn\n",
        "    num_epochs = 30\n",
        "    best_val_loss = float('inf')\n",
        "\n",
        "    # 3. Vòng lặp huấn luyện rút gọn\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        for features, (p_lbl, t_lbl, v_lbl) in train_loader:\n",
        "            features, p_lbl, t_lbl, v_lbl = features.to(device), p_lbl.to(device), t_lbl.to(device), v_lbl.to(device)\n",
        "            p_pred, t_pred, v_pred = model(features)\n",
        "            loss = (LOSS_WEIGHTS['price'] * price_loss_fn(p_pred, p_lbl) +\n",
        "                    LOSS_WEIGHTS['trend'] * trend_loss_fn(t_pred, t_lbl) +\n",
        "                    LOSS_WEIGHTS['volatility'] * vol_loss_fn(v_pred, v_lbl))\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # Đánh giá trên tập validation sau mỗi epoch\n",
        "        model.eval()\n",
        "        current_val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for features, (p_lbl, t_lbl, v_lbl) in test_loader:\n",
        "                features, p_lbl, t_lbl, v_lbl = features.to(device), p_lbl.to(device), t_lbl.to(device), v_lbl.to(device)\n",
        "                p_pred, t_pred, v_pred = model(features)\n",
        "                loss = (LOSS_WEIGHTS['price'] * price_loss_fn(p_pred, p_lbl) +\n",
        "                        LOSS_WEIGHTS['trend'] * trend_loss_fn(t_pred, t_lbl) +\n",
        "                        LOSS_WEIGHTS['volatility'] * vol_loss_fn(v_pred, v_lbl))\n",
        "                current_val_loss += loss.item()\n",
        "\n",
        "        avg_val_loss = current_val_loss / len(test_loader)\n",
        "\n",
        "        # Báo cáo kết quả cho Optuna\n",
        "        trial.report(avg_val_loss, epoch)\n",
        "\n",
        "        # Cắt tỉa (Pruning): Dừng sớm những lần thử không có triển vọng\n",
        "        if trial.should_prune():\n",
        "            raise optuna.exceptions.TrialPruned()\n",
        "\n",
        "        if avg_val_loss < best_val_loss:\n",
        "            best_val_loss = avg_val_loss\n",
        "\n",
        "    # Hàm objective trả về validation loss cuối cùng của lần thử này\n",
        "    return best_val_loss\n",
        "\n",
        "# 4. Chạy Cuộc tìm kiếm (Study)\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"--- Bắt đầu Tối ưu hóa Siêu tham số với Optuna ---\")\n",
        "\n",
        "    # Tạo một \"study\" với mục tiêu là \"minimize\" (tối thiểu hóa) hàm objective\n",
        "    study = optuna.create_study(direction=\"minimize\", pruner=optuna.pruners.MedianPruner())\n",
        "\n",
        "    # Bắt đầu chạy N_TRIALS lần thử\n",
        "    study.optimize(objective, n_trials=OPTUNA_N_TRIALS)\n",
        "\n",
        "    # In ra kết quả\n",
        "    pruned_trials = study.get_trials(deepcopy=False, states=[optuna.trial.TrialState.PRUNED])\n",
        "    complete_trials = study.get_trials(deepcopy=False, states=[optuna.trial.TrialState.COMPLETE])\n",
        "\n",
        "    print(\"\\n--- Tối ưu hóa Hoàn tất ---\")\n",
        "    print(\"Study statistics: \")\n",
        "    print(f\"  Số lần thử hoàn thành: {len(complete_trials)}\")\n",
        "    print(f\"  Số lần thử bị cắt tỉa (dừng sớm): {len(pruned_trials)}\")\n",
        "\n",
        "    print(\"\\n🏆 BỘ THAM SỐ TỐT NHẤT:\")\n",
        "    best_params = study.best_trial.params\n",
        "    for key, value in best_params.items():\n",
        "        print(f\"  {key}: {value}\")\n",
        "\n",
        "    print(f\"\\nGiá trị Validation Loss tốt nhất: {study.best_value:.6f}\")\n",
        "    print(\"\\n=> Gợi ý: Hãy cập nhật các tham số này vào file config.py và chạy lại file train.py chính thức để huấn luyện mô hình cuối cùng.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L940aSNscO28",
        "outputId": "823e1a8d-3033-4469-9141-b0d78ecf64b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting train_tuner.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train_tuner.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3jc4C0vcVh5",
        "outputId": "84021589-620a-4402-c837-7fa7e3d28b03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Bắt đầu Tối ưu hóa Siêu tham số với Optuna ---\n",
            "\u001b[32m[I 2025-07-09 13:57:29,154]\u001b[0m A new study created in memory with name: no-name-5cd36d74-5a33-4460-ba86-d9f0954f3479\u001b[0m\n",
            "✅ DataLoader đa nhiệm đã sẵn sàng.\n",
            "\u001b[32m[I 2025-07-09 13:57:38,735]\u001b[0m Trial 0 finished with value: 0.20590250194072723 and parameters: {'lstm_hidden_units': 224, 'lstm_num_layers': 3, 'attention_num_heads': 4, 'learning_rate': 0.0009194168469382918}. Best is trial 0 with value: 0.20590250194072723.\u001b[0m\n",
            "✅ DataLoader đa nhiệm đã sẵn sàng.\n",
            "\u001b[32m[I 2025-07-09 13:57:48,096]\u001b[0m Trial 1 finished with value: 0.20616554468870163 and parameters: {'lstm_hidden_units': 256, 'lstm_num_layers': 3, 'attention_num_heads': 2, 'learning_rate': 0.0005738733779054687}. Best is trial 0 with value: 0.20590250194072723.\u001b[0m\n",
            "✅ DataLoader đa nhiệm đã sẵn sàng.\n",
            "\u001b[32m[I 2025-07-09 13:57:54,001]\u001b[0m Trial 2 finished with value: 0.20579843968153 and parameters: {'lstm_hidden_units': 192, 'lstm_num_layers': 1, 'attention_num_heads': 8, 'learning_rate': 0.0022088373370435133}. Best is trial 2 with value: 0.20579843968153.\u001b[0m\n",
            "✅ DataLoader đa nhiệm đã sẵn sàng.\n",
            "\u001b[32m[I 2025-07-09 13:57:57,506]\u001b[0m Trial 3 finished with value: 0.21266303211450577 and parameters: {'lstm_hidden_units': 128, 'lstm_num_layers': 3, 'attention_num_heads': 4, 'learning_rate': 0.009764102472444075}. Best is trial 2 with value: 0.20579843968153.\u001b[0m\n",
            "✅ DataLoader đa nhiệm đã sẵn sàng.\n",
            "\u001b[32m[I 2025-07-09 13:58:07,180]\u001b[0m Trial 4 finished with value: 0.20623130351305008 and parameters: {'lstm_hidden_units': 256, 'lstm_num_layers': 3, 'attention_num_heads': 2, 'learning_rate': 0.00031495121036367884}. Best is trial 2 with value: 0.20579843968153.\u001b[0m\n",
            "✅ DataLoader đa nhiệm đã sẵn sàng.\n",
            "\u001b[32m[I 2025-07-09 13:58:07,346]\u001b[0m Trial 5 pruned. \u001b[0m\n",
            "✅ DataLoader đa nhiệm đã sẵn sàng.\n",
            "\u001b[32m[I 2025-07-09 13:58:07,859]\u001b[0m Trial 6 pruned. \u001b[0m\n",
            "✅ DataLoader đa nhiệm đã sẵn sàng.\n",
            "\u001b[32m[I 2025-07-09 13:58:08,031]\u001b[0m Trial 7 pruned. \u001b[0m\n",
            "✅ DataLoader đa nhiệm đã sẵn sàng.\n",
            "\u001b[32m[I 2025-07-09 13:58:11,397]\u001b[0m Trial 8 finished with value: 0.2060781791806221 and parameters: {'lstm_hidden_units': 96, 'lstm_num_layers': 3, 'attention_num_heads': 4, 'learning_rate': 0.0023009554850280628}. Best is trial 2 with value: 0.20579843968153.\u001b[0m\n",
            "✅ DataLoader đa nhiệm đã sẵn sàng.\n",
            "\u001b[32m[I 2025-07-09 13:58:11,586]\u001b[0m Trial 9 pruned. \u001b[0m\n",
            "✅ DataLoader đa nhiệm đã sẵn sàng.\n",
            "\u001b[32m[I 2025-07-09 13:58:11,870]\u001b[0m Trial 10 pruned. \u001b[0m\n",
            "✅ DataLoader đa nhiệm đã sẵn sàng.\n",
            "\u001b[32m[I 2025-07-09 13:58:17,841]\u001b[0m Trial 11 finished with value: 0.20584291219711304 and parameters: {'lstm_hidden_units': 192, 'lstm_num_layers': 1, 'attention_num_heads': 4, 'learning_rate': 0.0014804013260213255}. Best is trial 2 with value: 0.20579843968153.\u001b[0m\n",
            "✅ DataLoader đa nhiệm đã sẵn sàng.\n",
            "\u001b[32m[I 2025-07-09 13:58:18,314]\u001b[0m Trial 12 pruned. \u001b[0m\n",
            "✅ DataLoader đa nhiệm đã sẵn sàng.\n",
            "\u001b[32m[I 2025-07-09 13:58:18,609]\u001b[0m Trial 13 pruned. \u001b[0m\n",
            "✅ DataLoader đa nhiệm đã sẵn sàng.\n",
            "\u001b[32m[I 2025-07-09 13:58:22,735]\u001b[0m Trial 14 finished with value: 0.20658081769943237 and parameters: {'lstm_hidden_units': 160, 'lstm_num_layers': 1, 'attention_num_heads': 8, 'learning_rate': 0.0011737729977820092}. Best is trial 2 with value: 0.20579843968153.\u001b[0m\n",
            "✅ DataLoader đa nhiệm đã sẵn sàng.\n",
            "\u001b[32m[I 2025-07-09 13:58:26,922]\u001b[0m Trial 15 finished with value: 0.20649652928113937 and parameters: {'lstm_hidden_units': 160, 'lstm_num_layers': 1, 'attention_num_heads': 4, 'learning_rate': 0.0011240116336460214}. Best is trial 2 with value: 0.20579843968153.\u001b[0m\n",
            "✅ DataLoader đa nhiệm đã sẵn sàng.\n",
            "\u001b[32m[I 2025-07-09 13:58:27,240]\u001b[0m Trial 16 pruned. \u001b[0m\n",
            "✅ DataLoader đa nhiệm đã sẵn sàng.\n",
            "\u001b[32m[I 2025-07-09 13:58:27,619]\u001b[0m Trial 17 pruned. \u001b[0m\n",
            "✅ DataLoader đa nhiệm đã sẵn sàng.\n",
            "\u001b[32m[I 2025-07-09 13:58:27,970]\u001b[0m Trial 18 pruned. \u001b[0m\n",
            "✅ DataLoader đa nhiệm đã sẵn sàng.\n",
            "\u001b[32m[I 2025-07-09 13:58:34,331]\u001b[0m Trial 19 finished with value: 0.20660246163606644 and parameters: {'lstm_hidden_units': 224, 'lstm_num_layers': 2, 'attention_num_heads': 2, 'learning_rate': 0.0006705080131930841}. Best is trial 2 with value: 0.20579843968153.\u001b[0m\n",
            "✅ DataLoader đa nhiệm đã sẵn sàng.\n",
            "\u001b[32m[I 2025-07-09 13:58:34,468]\u001b[0m Trial 20 pruned. \u001b[0m\n",
            "✅ DataLoader đa nhiệm đã sẵn sàng.\n",
            "\u001b[32m[I 2025-07-09 13:58:34,999]\u001b[0m Trial 21 pruned. \u001b[0m\n",
            "✅ DataLoader đa nhiệm đã sẵn sàng.\n",
            "\u001b[32m[I 2025-07-09 13:58:35,376]\u001b[0m Trial 22 pruned. \u001b[0m\n",
            "✅ DataLoader đa nhiệm đã sẵn sàng.\n",
            "\u001b[32m[I 2025-07-09 13:58:35,670]\u001b[0m Trial 23 pruned. \u001b[0m\n",
            "✅ DataLoader đa nhiệm đã sẵn sàng.\n",
            "\u001b[32m[I 2025-07-09 13:58:36,076]\u001b[0m Trial 24 pruned. \u001b[0m\n",
            "✅ DataLoader đa nhiệm đã sẵn sàng.\n",
            "\u001b[32m[I 2025-07-09 13:58:36,294]\u001b[0m Trial 25 pruned. \u001b[0m\n",
            "✅ DataLoader đa nhiệm đã sẵn sàng.\n",
            "\u001b[32m[I 2025-07-09 13:58:36,749]\u001b[0m Trial 26 pruned. \u001b[0m\n",
            "✅ DataLoader đa nhiệm đã sẵn sàng.\n",
            "\u001b[32m[I 2025-07-09 13:58:36,998]\u001b[0m Trial 27 pruned. \u001b[0m\n",
            "✅ DataLoader đa nhiệm đã sẵn sàng.\n",
            "\u001b[32m[I 2025-07-09 13:58:44,742]\u001b[0m Trial 28 finished with value: 0.20630258321762085 and parameters: {'lstm_hidden_units': 256, 'lstm_num_layers': 2, 'attention_num_heads': 2, 'learning_rate': 0.0009718987976502385}. Best is trial 2 with value: 0.20579843968153.\u001b[0m\n",
            "✅ DataLoader đa nhiệm đã sẵn sàng.\n",
            "\u001b[32m[I 2025-07-09 13:58:45,146]\u001b[0m Trial 29 pruned. \u001b[0m\n",
            "✅ DataLoader đa nhiệm đã sẵn sàng.\n",
            "\u001b[32m[I 2025-07-09 13:58:45,639]\u001b[0m Trial 30 pruned. \u001b[0m\n",
            "✅ DataLoader đa nhiệm đã sẵn sàng.\n",
            "\u001b[32m[I 2025-07-09 13:58:45,811]\u001b[0m Trial 31 pruned. \u001b[0m\n",
            "✅ DataLoader đa nhiệm đã sẵn sàng.\n",
            "\u001b[32m[I 2025-07-09 13:58:46,102]\u001b[0m Trial 32 pruned. \u001b[0m\n",
            "✅ DataLoader đa nhiệm đã sẵn sàng.\n",
            "\u001b[32m[I 2025-07-09 13:58:46,445]\u001b[0m Trial 33 pruned. \u001b[0m\n",
            "✅ DataLoader đa nhiệm đã sẵn sàng.\n",
            "\u001b[32m[I 2025-07-09 13:58:46,646]\u001b[0m Trial 34 pruned. \u001b[0m\n",
            "✅ DataLoader đa nhiệm đã sẵn sàng.\n",
            "\u001b[32m[I 2025-07-09 13:58:47,236]\u001b[0m Trial 35 pruned. \u001b[0m\n",
            "✅ DataLoader đa nhiệm đã sẵn sàng.\n",
            "\u001b[32m[I 2025-07-09 13:58:47,423]\u001b[0m Trial 36 pruned. \u001b[0m\n",
            "✅ DataLoader đa nhiệm đã sẵn sàng.\n",
            "\u001b[32m[I 2025-07-09 13:58:47,765]\u001b[0m Trial 37 pruned. \u001b[0m\n",
            "✅ DataLoader đa nhiệm đã sẵn sàng.\n",
            "\u001b[32m[I 2025-07-09 13:58:47,939]\u001b[0m Trial 38 pruned. \u001b[0m\n",
            "✅ DataLoader đa nhiệm đã sẵn sàng.\n",
            "\u001b[32m[I 2025-07-09 13:58:48,520]\u001b[0m Trial 39 pruned. \u001b[0m\n",
            "✅ DataLoader đa nhiệm đã sẵn sàng.\n",
            "\u001b[32m[I 2025-07-09 13:58:48,671]\u001b[0m Trial 40 pruned. \u001b[0m\n",
            "✅ DataLoader đa nhiệm đã sẵn sàng.\n",
            "\u001b[32m[I 2025-07-09 13:58:49,149]\u001b[0m Trial 41 pruned. \u001b[0m\n",
            "✅ DataLoader đa nhiệm đã sẵn sàng.\n",
            "\u001b[32m[I 2025-07-09 13:58:49,660]\u001b[0m Trial 42 pruned. \u001b[0m\n",
            "✅ DataLoader đa nhiệm đã sẵn sàng.\n",
            "\u001b[32m[I 2025-07-09 13:58:50,129]\u001b[0m Trial 43 pruned. \u001b[0m\n",
            "✅ DataLoader đa nhiệm đã sẵn sàng.\n",
            "\u001b[32m[I 2025-07-09 13:58:51,040]\u001b[0m Trial 44 pruned. \u001b[0m\n",
            "✅ DataLoader đa nhiệm đã sẵn sàng.\n",
            "\u001b[32m[I 2025-07-09 13:58:51,389]\u001b[0m Trial 45 pruned. \u001b[0m\n",
            "✅ DataLoader đa nhiệm đã sẵn sàng.\n",
            "\u001b[32m[I 2025-07-09 13:58:52,025]\u001b[0m Trial 46 pruned. \u001b[0m\n",
            "✅ DataLoader đa nhiệm đã sẵn sàng.\n",
            "\u001b[32m[I 2025-07-09 13:58:52,919]\u001b[0m Trial 47 pruned. \u001b[0m\n",
            "✅ DataLoader đa nhiệm đã sẵn sàng.\n",
            "\u001b[32m[I 2025-07-09 13:58:59,418]\u001b[0m Trial 48 finished with value: 0.20631743222475052 and parameters: {'lstm_hidden_units': 224, 'lstm_num_layers': 2, 'attention_num_heads': 8, 'learning_rate': 0.0017515664567020995}. Best is trial 2 with value: 0.20579843968153.\u001b[0m\n",
            "✅ DataLoader đa nhiệm đã sẵn sàng.\n",
            "\u001b[32m[I 2025-07-09 13:58:59,822]\u001b[0m Trial 49 pruned. \u001b[0m\n",
            "\n",
            "--- Tối ưu hóa Hoàn tất ---\n",
            "Study statistics: \n",
            "  Số lần thử hoàn thành: 12\n",
            "  Số lần thử bị cắt tỉa (dừng sớm): 38\n",
            "\n",
            "🏆 BỘ THAM SỐ TỐT NHẤT:\n",
            "  lstm_hidden_units: 192\n",
            "  lstm_num_layers: 1\n",
            "  attention_num_heads: 8\n",
            "  learning_rate: 0.0022088373370435133\n",
            "\n",
            "Giá trị Validation Loss tốt nhất: 0.205798\n",
            "\n",
            "=> Gợi ý: Hãy cập nhật các tham số này vào file config.py và chạy lại file train.py chính thức để huấn luyện mô hình cuối cùng.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Giờ test thử siêu tham số mới***"
      ],
      "metadata": {
        "id": "YnVezlzefMLA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile model.py\n",
        "# model.py\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from config import BATCH_SIZE, LOOKBACK_WINDOW # Chỉ import những gì cần cho việc test\n",
        "\n",
        "class FinalModel(nn.Module):\n",
        "    def __init__(self, input_feature_size, num_scales, lstm_hidden_units, lstm_num_layers, num_heads):\n",
        "        super(FinalModel, self).__init__()\n",
        "\n",
        "        # SỬA LỖI: Lưu lại các tham số kiến trúc làm thuộc tính của class\n",
        "        self.input_feature_size = input_feature_size\n",
        "        self.num_scales = num_scales\n",
        "\n",
        "        # --- Phần thân chung (Shared Body) ---\n",
        "        self.lstm_branches = nn.ModuleList([\n",
        "            nn.LSTM(input_size=self.input_feature_size, hidden_size=lstm_hidden_units,\n",
        "                    num_layers=lstm_num_layers, batch_first=True, dropout=0.2 if lstm_num_layers > 1 else 0)\n",
        "            for _ in range(self.num_scales)\n",
        "        ])\n",
        "        self.attention = nn.MultiheadAttention(embed_dim=lstm_hidden_units * self.num_scales,\n",
        "                                             num_heads=num_heads, batch_first=True)\n",
        "\n",
        "        shared_feature_dim = lstm_hidden_units * self.num_scales\n",
        "        self.intermediate_layer = nn.Sequential(\n",
        "            nn.Linear(shared_feature_dim, shared_feature_dim // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3)\n",
        "        )\n",
        "\n",
        "        # --- Các Đầu ra Đa nhiệm (Multi-Task Heads) ---\n",
        "        self.price_head = nn.Linear(shared_feature_dim // 2, 1)\n",
        "        self.trend_head = nn.Sequential(\n",
        "            nn.Linear(shared_feature_dim // 2, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 1)\n",
        "        )\n",
        "        self.volatility_head = nn.Linear(shared_feature_dim // 2, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        branch_outputs = []\n",
        "        for i in range(self.num_scales):\n",
        "            # SỬA LỖI: Dùng thuộc tính của class (self.input_feature_size) thay vì biến toàn cục\n",
        "            start_idx = i * self.input_feature_size\n",
        "            end_idx = (i + 1) * self.input_feature_size\n",
        "\n",
        "            branch_input = x[:, :, start_idx:end_idx]\n",
        "            output, _ = self.lstm_branches[i](branch_input)\n",
        "            branch_outputs.append(output)\n",
        "\n",
        "        concatenated_output = torch.cat(branch_outputs, dim=2)\n",
        "        attention_output, _ = self.attention(concatenated_output, concatenated_output, concatenated_output)\n",
        "        shared_features = self.intermediate_layer(attention_output[:, -1, :])\n",
        "\n",
        "        price_prediction = self.price_head(shared_features)\n",
        "        trend_prediction = self.trend_head(shared_features)\n",
        "        volatility_prediction = self.volatility_head(shared_features)\n",
        "\n",
        "        return price_prediction.squeeze(), trend_prediction.squeeze(), volatility_prediction.squeeze()\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Đoạn test này cần import từ config\n",
        "    from config import NUM_BASE_FEATURES, NUM_SCALES, LSTM_HIDDEN_UNITS, LSTM_NUM_LAYERS, ATTENTION_NUM_HEADS\n",
        "\n",
        "    print(\"--- Kiểm tra kiến trúc Final Model (đã sửa lỗi) ---\")\n",
        "    model = FinalModel(\n",
        "        input_feature_size=NUM_BASE_FEATURES, num_scales=NUM_SCALES,\n",
        "        lstm_hidden_units=LSTM_HIDDEN_UNITS, lstm_num_layers=LSTM_NUM_LAYERS,\n",
        "        num_heads=ATTENTION_NUM_HEADS\n",
        "    )\n",
        "    print(model)\n",
        "    dummy_input = torch.randn(BATCH_SIZE, LOOKBACK_WINDOW, NUM_BASE_FEATURES * NUM_SCALES)\n",
        "    price, trend, volatility = model(dummy_input)\n",
        "\n",
        "    print(f\"\\nShape của input: {dummy_input.shape}\")\n",
        "    print(f\"Shape đầu ra Price: {price.shape}\")\n",
        "    print(f\"Shape đầu ra Trend: {trend.shape}\")\n",
        "    print(f\"Shape đầu ra Volatility: {volatility.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDkbEg0IfSwx",
        "outputId": "c4e4df11-4962-425b-d96d-083711423c64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting model.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python model.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwXI7qYDfYwY",
        "outputId": "e7b8c1b1-7ee6-4118-e965-7f39bce776a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Kiểm tra kiến trúc Final Model (đã sửa lỗi) ---\n",
            "FinalModel(\n",
            "  (lstm_branches): ModuleList(\n",
            "    (0-4): 5 x LSTM(30, 128, num_layers=2, batch_first=True, dropout=0.2)\n",
            "  )\n",
            "  (attention): MultiheadAttention(\n",
            "    (out_proj): NonDynamicallyQuantizableLinear(in_features=640, out_features=640, bias=True)\n",
            "  )\n",
            "  (intermediate_layer): Sequential(\n",
            "    (0): Linear(in_features=640, out_features=320, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.3, inplace=False)\n",
            "  )\n",
            "  (price_head): Linear(in_features=320, out_features=1, bias=True)\n",
            "  (trend_head): Sequential(\n",
            "    (0): Linear(in_features=320, out_features=32, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=32, out_features=1, bias=True)\n",
            "  )\n",
            "  (volatility_head): Linear(in_features=320, out_features=1, bias=True)\n",
            ")\n",
            "\n",
            "Shape của input: torch.Size([32, 30, 150])\n",
            "Shape đầu ra Price: torch.Size([32])\n",
            "Shape đầu ra Trend: torch.Size([32])\n",
            "Shape đầu ra Volatility: torch.Size([32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile config.py\n",
        "# config.py\n",
        "\n",
        "# --- Đường dẫn file ---\n",
        "PROCESSED_DATA_PATH = 'vn_indices_processed.csv'\n",
        "# File model cuối cùng sau khi đã được tối ưu\n",
        "TRAINED_MODEL_PATH = 'final_optimized_model.pth'\n",
        "\n",
        "# --- Tham số tạo Dataset ---\n",
        "LOOKBACK_WINDOW = 30\n",
        "TARGET_COLUMN = 'VNINDEX_Close'\n",
        "TEST_SET_SIZE = 0.2\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# --- Tham số Biến đổi Wavelet ---\n",
        "WAVELET_FAMILY = 'db4'\n",
        "WAVELET_LEVEL = 4\n",
        "\n",
        "# --- THAM SỐ KIẾN TRÚC TỐT NHẤT TỪ OPTUNA ---\n",
        "NUM_BASE_FEATURES = 30\n",
        "NUM_SCALES = WAVELET_LEVEL + 1\n",
        "LSTM_HIDDEN_UNITS = 192   # <--- CẬP NHẬT\n",
        "LSTM_NUM_LAYERS = 1       # <--- CẬP NHẬT\n",
        "ATTENTION_NUM_HEADS = 8   # <--- CẬP NHẬT\n",
        "\n",
        "# --- Tham số cho Multi-Task Learning ---\n",
        "LOSS_WEIGHTS = {\n",
        "    'price': 0.6,\n",
        "    'trend': 0.3,\n",
        "    'volatility': 0.1\n",
        "}\n",
        "\n",
        "# --- Tham số Huấn luyện TỐT NHẤT TỪ OPTUNA ---\n",
        "LEARNING_RATE = 0.0022088373370435133 # <--- CẬP NHẬT\n",
        "NUM_EPOCHS = 100 # Giữ nguyên 100 epoch để học sâu hơn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "947Jx0Asfchk",
        "outputId": "8d701759-749e-4788-8f7f-b59b59f94ce5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting config.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile train.py\n",
        "# train.py\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "\n",
        "from config import (\n",
        "    NUM_BASE_FEATURES, NUM_SCALES, LSTM_HIDDEN_UNITS, LSTM_NUM_LAYERS,\n",
        "    ATTENTION_NUM_HEADS, LOSS_WEIGHTS,\n",
        "    LEARNING_RATE, NUM_EPOCHS, TRAINED_MODEL_PATH\n",
        ")\n",
        "from model import FinalModel\n",
        "from dataset import get_data_loaders\n",
        "\n",
        "def run_training():\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    print(f\"Sử dụng thiết bị: {device.upper()}\")\n",
        "\n",
        "    train_loader, test_loader, _, _ = get_data_loaders()\n",
        "    if not train_loader: return\n",
        "\n",
        "    model = FinalModel(\n",
        "        input_feature_size=NUM_BASE_FEATURES, num_scales=NUM_SCALES,\n",
        "        lstm_hidden_units=LSTM_HIDDEN_UNITS, lstm_num_layers=LSTM_NUM_LAYERS,\n",
        "        num_heads=ATTENTION_NUM_HEADS\n",
        "    ).to(device)\n",
        "\n",
        "    # Định nghĩa các hàm loss cho từng nhiệm vụ\n",
        "    price_loss_fn = nn.MSELoss() # Cho giá (hồi quy)\n",
        "    # Dùng BCEWithLogitsLoss cho độ ổn định số học, nó đã tích hợp sẵn Sigmoid\n",
        "    trend_loss_fn = nn.BCEWithLogitsLoss() # Cho xu hướng (phân loại)\n",
        "    vol_loss_fn = nn.MSELoss() # Cho độ biến động (hồi quy)\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "    print(\"\\n--- Bắt đầu Huấn luyện Model Cuối cùng (Hierarchical + Multi-Task) ---\")\n",
        "    best_val_loss = float('inf')\n",
        "\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        # --- PHA HUẤN LUYỆN ---\n",
        "        model.train()\n",
        "        total_train_loss = 0\n",
        "        for features, (price_lbl, trend_lbl, vol_lbl) in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS} [Train]\"):\n",
        "            features = features.to(device)\n",
        "            price_lbl, trend_lbl, vol_lbl = price_lbl.to(device), trend_lbl.to(device), vol_lbl.to(device)\n",
        "\n",
        "            # Lấy 3 đầu ra từ model\n",
        "            price_pred, trend_pred, vol_pred = model(features)\n",
        "\n",
        "            # Tính toán loss cho từng nhiệm vụ\n",
        "            loss_p = price_loss_fn(price_pred, price_lbl)\n",
        "            loss_t = trend_loss_fn(trend_pred, trend_lbl)\n",
        "            loss_v = vol_loss_fn(vol_pred, vol_lbl)\n",
        "\n",
        "            # Tính loss tổng hợp dựa trên trọng số\n",
        "            total_loss = (LOSS_WEIGHTS['price'] * loss_p +\n",
        "                          LOSS_WEIGHTS['trend'] * loss_t +\n",
        "                          LOSS_WEIGHTS['volatility'] * loss_v)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            total_loss.backward()\n",
        "            optimizer.step()\n",
        "            total_train_loss += total_loss.item()\n",
        "\n",
        "        # --- PHA KIỂM ĐỊNH ---\n",
        "        model.eval()\n",
        "        total_val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for features, (price_lbl, trend_lbl, vol_lbl) in tqdm(test_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS} [Valid]\"):\n",
        "                features = features.to(device)\n",
        "                price_lbl, trend_lbl, vol_lbl = price_lbl.to(device), trend_lbl.to(device), vol_lbl.to(device)\n",
        "\n",
        "                price_pred, trend_pred, vol_pred = model(features)\n",
        "\n",
        "                loss_p = price_loss_fn(price_pred, price_lbl)\n",
        "                loss_t = trend_loss_fn(trend_pred, trend_lbl)\n",
        "                loss_v = vol_loss_fn(vol_pred, vol_lbl)\n",
        "\n",
        "                total_loss = (LOSS_WEIGHTS['price'] * loss_p +\n",
        "                              LOSS_WEIGHTS['trend'] * loss_t +\n",
        "                              LOSS_WEIGHTS['volatility'] * loss_v)\n",
        "                total_val_loss += total_loss.item()\n",
        "\n",
        "        avg_train_loss = total_train_loss / len(train_loader)\n",
        "        avg_val_loss = total_val_loss / len(test_loader)\n",
        "\n",
        "        print(f\"Epoch [{epoch+1:02d}/{NUM_EPOCHS}] | Train Loss: {avg_train_loss:.6f} | Validation Loss: {avg_val_loss:.6f}\")\n",
        "\n",
        "        if avg_val_loss < best_val_loss:\n",
        "            best_val_loss = avg_val_loss\n",
        "            torch.save(model.state_dict(), TRAINED_MODEL_PATH)\n",
        "            print(f\"   -> Validation loss cải thiện. Đã lưu model tốt nhất vào '{TRAINED_MODEL_PATH}'\")\n",
        "\n",
        "    print(f\"\\n--- Huấn luyện Hoàn tất ---\")\n",
        "    print(f\"✅ Model cuối cùng đã được lưu tại epoch có Validation Loss = {best_val_loss:.6f}\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    run_training()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbk01oqUfqwr",
        "outputId": "ff2ba4e6-1d51-46ec-9b27-809b6da347b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting train.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swMdOaG_fv7o",
        "outputId": "b51e0a92-923a-4ed9-9347-e4cdc4f12cf8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sử dụng thiết bị: CUDA\n",
            "✅ DataLoader đa nhiệm đã sẵn sàng.\n",
            "\n",
            "--- Bắt đầu Huấn luyện Model Cuối cùng (Hierarchical + Multi-Task) ---\n",
            "Epoch 1/100 [Train]: 100% 8/8 [00:00<00:00, 17.59it/s]\n",
            "Epoch 1/100 [Valid]: 100% 2/2 [00:00<00:00, 73.48it/s]\n",
            "Epoch [01/100] | Train Loss: 0.445531 | Validation Loss: 0.222070\n",
            "   -> Validation loss cải thiện. Đã lưu model tốt nhất vào 'final_optimized_model.pth'\n",
            "Epoch 2/100 [Train]: 100% 8/8 [00:00<00:00, 43.60it/s]\n",
            "Epoch 2/100 [Valid]: 100% 2/2 [00:00<00:00, 77.30it/s]\n",
            "Epoch [02/100] | Train Loss: 0.273318 | Validation Loss: 0.207194\n",
            "   -> Validation loss cải thiện. Đã lưu model tốt nhất vào 'final_optimized_model.pth'\n",
            "Epoch 3/100 [Train]: 100% 8/8 [00:00<00:00, 45.33it/s]\n",
            "Epoch 3/100 [Valid]: 100% 2/2 [00:00<00:00, 77.78it/s]\n",
            "Epoch [03/100] | Train Loss: 0.245420 | Validation Loss: 0.220386\n",
            "Epoch 4/100 [Train]: 100% 8/8 [00:00<00:00, 45.12it/s]\n",
            "Epoch 4/100 [Valid]: 100% 2/2 [00:00<00:00, 75.73it/s]\n",
            "Epoch [04/100] | Train Loss: 0.253762 | Validation Loss: 0.210849\n",
            "Epoch 5/100 [Train]: 100% 8/8 [00:00<00:00, 45.32it/s]\n",
            "Epoch 5/100 [Valid]: 100% 2/2 [00:00<00:00, 78.07it/s]\n",
            "Epoch [05/100] | Train Loss: 0.245228 | Validation Loss: 0.219912\n",
            "Epoch 6/100 [Train]: 100% 8/8 [00:00<00:00, 45.40it/s]\n",
            "Epoch 6/100 [Valid]: 100% 2/2 [00:00<00:00, 77.68it/s]\n",
            "Epoch [06/100] | Train Loss: 0.243556 | Validation Loss: 0.213404\n",
            "Epoch 7/100 [Train]: 100% 8/8 [00:00<00:00, 44.30it/s]\n",
            "Epoch 7/100 [Valid]: 100% 2/2 [00:00<00:00, 77.94it/s]\n",
            "Epoch [07/100] | Train Loss: 0.244947 | Validation Loss: 0.207900\n",
            "Epoch 8/100 [Train]: 100% 8/8 [00:00<00:00, 45.22it/s]\n",
            "Epoch 8/100 [Valid]: 100% 2/2 [00:00<00:00, 77.91it/s]\n",
            "Epoch [08/100] | Train Loss: 0.244304 | Validation Loss: 0.211158\n",
            "Epoch 9/100 [Train]: 100% 8/8 [00:00<00:00, 45.25it/s]\n",
            "Epoch 9/100 [Valid]: 100% 2/2 [00:00<00:00, 77.08it/s]\n",
            "Epoch [09/100] | Train Loss: 0.248317 | Validation Loss: 0.210626\n",
            "Epoch 10/100 [Train]: 100% 8/8 [00:00<00:00, 45.50it/s]\n",
            "Epoch 10/100 [Valid]: 100% 2/2 [00:00<00:00, 74.68it/s]\n",
            "Epoch [10/100] | Train Loss: 0.247588 | Validation Loss: 0.206120\n",
            "   -> Validation loss cải thiện. Đã lưu model tốt nhất vào 'final_optimized_model.pth'\n",
            "Epoch 11/100 [Train]: 100% 8/8 [00:00<00:00, 44.78it/s]\n",
            "Epoch 11/100 [Valid]: 100% 2/2 [00:00<00:00, 74.67it/s]\n",
            "Epoch [11/100] | Train Loss: 0.245616 | Validation Loss: 0.205983\n",
            "   -> Validation loss cải thiện. Đã lưu model tốt nhất vào 'final_optimized_model.pth'\n",
            "Epoch 12/100 [Train]: 100% 8/8 [00:00<00:00, 44.67it/s]\n",
            "Epoch 12/100 [Valid]: 100% 2/2 [00:00<00:00, 75.47it/s]\n",
            "Epoch [12/100] | Train Loss: 0.244543 | Validation Loss: 0.216944\n",
            "Epoch 13/100 [Train]: 100% 8/8 [00:00<00:00, 44.16it/s]\n",
            "Epoch 13/100 [Valid]: 100% 2/2 [00:00<00:00, 70.20it/s]\n",
            "Epoch [13/100] | Train Loss: 0.245771 | Validation Loss: 0.207393\n",
            "Epoch 14/100 [Train]: 100% 8/8 [00:00<00:00, 45.24it/s]\n",
            "Epoch 14/100 [Valid]: 100% 2/2 [00:00<00:00, 73.42it/s]\n",
            "Epoch [14/100] | Train Loss: 0.244729 | Validation Loss: 0.206506\n",
            "Epoch 15/100 [Train]: 100% 8/8 [00:00<00:00, 44.89it/s]\n",
            "Epoch 15/100 [Valid]: 100% 2/2 [00:00<00:00, 74.72it/s]\n",
            "Epoch [15/100] | Train Loss: 0.242426 | Validation Loss: 0.208122\n",
            "Epoch 16/100 [Train]: 100% 8/8 [00:00<00:00, 43.66it/s]\n",
            "Epoch 16/100 [Valid]: 100% 2/2 [00:00<00:00, 76.38it/s]\n",
            "Epoch [16/100] | Train Loss: 0.243383 | Validation Loss: 0.210802\n",
            "Epoch 17/100 [Train]: 100% 8/8 [00:00<00:00, 44.32it/s]\n",
            "Epoch 17/100 [Valid]: 100% 2/2 [00:00<00:00, 74.81it/s]\n",
            "Epoch [17/100] | Train Loss: 0.242694 | Validation Loss: 0.208918\n",
            "Epoch 18/100 [Train]: 100% 8/8 [00:00<00:00, 44.74it/s]\n",
            "Epoch 18/100 [Valid]: 100% 2/2 [00:00<00:00, 73.12it/s]\n",
            "Epoch [18/100] | Train Loss: 0.243548 | Validation Loss: 0.215109\n",
            "Epoch 19/100 [Train]: 100% 8/8 [00:00<00:00, 38.99it/s]\n",
            "Epoch 19/100 [Valid]: 100% 2/2 [00:00<00:00, 78.02it/s]\n",
            "Epoch [19/100] | Train Loss: 0.242515 | Validation Loss: 0.223670\n",
            "Epoch 20/100 [Train]: 100% 8/8 [00:00<00:00, 45.08it/s]\n",
            "Epoch 20/100 [Valid]: 100% 2/2 [00:00<00:00, 78.07it/s]\n",
            "Epoch [20/100] | Train Loss: 0.244431 | Validation Loss: 0.222460\n",
            "Epoch 21/100 [Train]: 100% 8/8 [00:00<00:00, 45.14it/s]\n",
            "Epoch 21/100 [Valid]: 100% 2/2 [00:00<00:00, 77.66it/s]\n",
            "Epoch [21/100] | Train Loss: 0.245102 | Validation Loss: 0.206558\n",
            "Epoch 22/100 [Train]: 100% 8/8 [00:00<00:00, 45.09it/s]\n",
            "Epoch 22/100 [Valid]: 100% 2/2 [00:00<00:00, 77.99it/s]\n",
            "Epoch [22/100] | Train Loss: 0.243092 | Validation Loss: 0.206584\n",
            "Epoch 23/100 [Train]: 100% 8/8 [00:00<00:00, 44.71it/s]\n",
            "Epoch 23/100 [Valid]: 100% 2/2 [00:00<00:00, 72.86it/s]\n",
            "Epoch [23/100] | Train Loss: 0.243170 | Validation Loss: 0.211526\n",
            "Epoch 24/100 [Train]: 100% 8/8 [00:00<00:00, 44.89it/s]\n",
            "Epoch 24/100 [Valid]: 100% 2/2 [00:00<00:00, 75.55it/s]\n",
            "Epoch [24/100] | Train Loss: 0.242578 | Validation Loss: 0.210839\n",
            "Epoch 25/100 [Train]: 100% 8/8 [00:00<00:00, 44.97it/s]\n",
            "Epoch 25/100 [Valid]: 100% 2/2 [00:00<00:00, 76.89it/s]\n",
            "Epoch [25/100] | Train Loss: 0.237878 | Validation Loss: 0.210074\n",
            "Epoch 26/100 [Train]: 100% 8/8 [00:00<00:00, 44.97it/s]\n",
            "Epoch 26/100 [Valid]: 100% 2/2 [00:00<00:00, 77.71it/s]\n",
            "Epoch [26/100] | Train Loss: 0.232718 | Validation Loss: 0.218818\n",
            "Epoch 27/100 [Train]: 100% 8/8 [00:00<00:00, 45.24it/s]\n",
            "Epoch 27/100 [Valid]: 100% 2/2 [00:00<00:00, 76.01it/s]\n",
            "Epoch [27/100] | Train Loss: 0.227765 | Validation Loss: 0.215888\n",
            "Epoch 28/100 [Train]: 100% 8/8 [00:00<00:00, 44.49it/s]\n",
            "Epoch 28/100 [Valid]: 100% 2/2 [00:00<00:00, 73.49it/s]\n",
            "Epoch [28/100] | Train Loss: 0.223231 | Validation Loss: 0.246875\n",
            "Epoch 29/100 [Train]: 100% 8/8 [00:00<00:00, 45.08it/s]\n",
            "Epoch 29/100 [Valid]: 100% 2/2 [00:00<00:00, 77.47it/s]\n",
            "Epoch [29/100] | Train Loss: 0.220913 | Validation Loss: 0.235044\n",
            "Epoch 30/100 [Train]: 100% 8/8 [00:00<00:00, 45.17it/s]\n",
            "Epoch 30/100 [Valid]: 100% 2/2 [00:00<00:00, 77.24it/s]\n",
            "Epoch [30/100] | Train Loss: 0.221161 | Validation Loss: 0.210256\n",
            "Epoch 31/100 [Train]: 100% 8/8 [00:00<00:00, 45.06it/s]\n",
            "Epoch 31/100 [Valid]: 100% 2/2 [00:00<00:00, 74.88it/s]\n",
            "Epoch [31/100] | Train Loss: 0.222053 | Validation Loss: 0.216139\n",
            "Epoch 32/100 [Train]: 100% 8/8 [00:00<00:00, 45.48it/s]\n",
            "Epoch 32/100 [Valid]: 100% 2/2 [00:00<00:00, 76.69it/s]\n",
            "Epoch [32/100] | Train Loss: 0.215965 | Validation Loss: 0.232141\n",
            "Epoch 33/100 [Train]: 100% 8/8 [00:00<00:00, 44.62it/s]\n",
            "Epoch 33/100 [Valid]: 100% 2/2 [00:00<00:00, 72.32it/s]\n",
            "Epoch [33/100] | Train Loss: 0.216985 | Validation Loss: 0.219683\n",
            "Epoch 34/100 [Train]: 100% 8/8 [00:00<00:00, 44.72it/s]\n",
            "Epoch 34/100 [Valid]: 100% 2/2 [00:00<00:00, 77.11it/s]\n",
            "Epoch [34/100] | Train Loss: 0.214753 | Validation Loss: 0.240517\n",
            "Epoch 35/100 [Train]: 100% 8/8 [00:00<00:00, 44.74it/s]\n",
            "Epoch 35/100 [Valid]: 100% 2/2 [00:00<00:00, 77.88it/s]\n",
            "Epoch [35/100] | Train Loss: 0.214258 | Validation Loss: 0.255711\n",
            "Epoch 36/100 [Train]: 100% 8/8 [00:00<00:00, 44.98it/s]\n",
            "Epoch 36/100 [Valid]: 100% 2/2 [00:00<00:00, 77.03it/s]\n",
            "Epoch [36/100] | Train Loss: 0.214292 | Validation Loss: 0.229426\n",
            "Epoch 37/100 [Train]: 100% 8/8 [00:00<00:00, 45.29it/s]\n",
            "Epoch 37/100 [Valid]: 100% 2/2 [00:00<00:00, 76.88it/s]\n",
            "Epoch [37/100] | Train Loss: 0.214139 | Validation Loss: 0.219777\n",
            "Epoch 38/100 [Train]: 100% 8/8 [00:00<00:00, 45.12it/s]\n",
            "Epoch 38/100 [Valid]: 100% 2/2 [00:00<00:00, 73.52it/s]\n",
            "Epoch [38/100] | Train Loss: 0.215188 | Validation Loss: 0.219038\n",
            "Epoch 39/100 [Train]: 100% 8/8 [00:00<00:00, 44.62it/s]\n",
            "Epoch 39/100 [Valid]: 100% 2/2 [00:00<00:00, 75.67it/s]\n",
            "Epoch [39/100] | Train Loss: 0.215622 | Validation Loss: 0.222630\n",
            "Epoch 40/100 [Train]: 100% 8/8 [00:00<00:00, 44.79it/s]\n",
            "Epoch 40/100 [Valid]: 100% 2/2 [00:00<00:00, 76.30it/s]\n",
            "Epoch [40/100] | Train Loss: 0.215791 | Validation Loss: 0.228439\n",
            "Epoch 41/100 [Train]: 100% 8/8 [00:00<00:00, 44.96it/s]\n",
            "Epoch 41/100 [Valid]: 100% 2/2 [00:00<00:00, 77.81it/s]\n",
            "Epoch [41/100] | Train Loss: 0.214301 | Validation Loss: 0.220298\n",
            "Epoch 42/100 [Train]: 100% 8/8 [00:00<00:00, 44.65it/s]\n",
            "Epoch 42/100 [Valid]: 100% 2/2 [00:00<00:00, 77.08it/s]\n",
            "Epoch [42/100] | Train Loss: 0.214710 | Validation Loss: 0.226856\n",
            "Epoch 43/100 [Train]: 100% 8/8 [00:00<00:00, 45.04it/s]\n",
            "Epoch 43/100 [Valid]: 100% 2/2 [00:00<00:00, 75.31it/s]\n",
            "Epoch [43/100] | Train Loss: 0.213809 | Validation Loss: 0.218974\n",
            "Epoch 44/100 [Train]: 100% 8/8 [00:00<00:00, 44.86it/s]\n",
            "Epoch 44/100 [Valid]: 100% 2/2 [00:00<00:00, 75.28it/s]\n",
            "Epoch [44/100] | Train Loss: 0.213410 | Validation Loss: 0.222600\n",
            "Epoch 45/100 [Train]: 100% 8/8 [00:00<00:00, 45.02it/s]\n",
            "Epoch 45/100 [Valid]: 100% 2/2 [00:00<00:00, 74.70it/s]\n",
            "Epoch [45/100] | Train Loss: 0.214894 | Validation Loss: 0.222993\n",
            "Epoch 46/100 [Train]: 100% 8/8 [00:00<00:00, 44.76it/s]\n",
            "Epoch 46/100 [Valid]: 100% 2/2 [00:00<00:00, 76.92it/s]\n",
            "Epoch [46/100] | Train Loss: 0.212926 | Validation Loss: 0.232039\n",
            "Epoch 47/100 [Train]: 100% 8/8 [00:00<00:00, 44.68it/s]\n",
            "Epoch 47/100 [Valid]: 100% 2/2 [00:00<00:00, 77.35it/s]\n",
            "Epoch [47/100] | Train Loss: 0.214418 | Validation Loss: 0.224698\n",
            "Epoch 48/100 [Train]: 100% 8/8 [00:00<00:00, 44.73it/s]\n",
            "Epoch 48/100 [Valid]: 100% 2/2 [00:00<00:00, 75.97it/s]\n",
            "Epoch [48/100] | Train Loss: 0.212121 | Validation Loss: 0.235244\n",
            "Epoch 49/100 [Train]: 100% 8/8 [00:00<00:00, 44.87it/s]\n",
            "Epoch 49/100 [Valid]: 100% 2/2 [00:00<00:00, 76.10it/s]\n",
            "Epoch [49/100] | Train Loss: 0.212930 | Validation Loss: 0.229430\n",
            "Epoch 50/100 [Train]: 100% 8/8 [00:00<00:00, 45.03it/s]\n",
            "Epoch 50/100 [Valid]: 100% 2/2 [00:00<00:00, 76.01it/s]\n",
            "Epoch [50/100] | Train Loss: 0.212552 | Validation Loss: 0.229565\n",
            "Epoch 51/100 [Train]: 100% 8/8 [00:00<00:00, 44.87it/s]\n",
            "Epoch 51/100 [Valid]: 100% 2/2 [00:00<00:00, 75.23it/s]\n",
            "Epoch [51/100] | Train Loss: 0.212083 | Validation Loss: 0.231578\n",
            "Epoch 52/100 [Train]: 100% 8/8 [00:00<00:00, 44.63it/s]\n",
            "Epoch 52/100 [Valid]: 100% 2/2 [00:00<00:00, 75.64it/s]\n",
            "Epoch [52/100] | Train Loss: 0.211049 | Validation Loss: 0.233878\n",
            "Epoch 53/100 [Train]: 100% 8/8 [00:00<00:00, 44.76it/s]\n",
            "Epoch 53/100 [Valid]: 100% 2/2 [00:00<00:00, 74.99it/s]\n",
            "Epoch [53/100] | Train Loss: 0.211853 | Validation Loss: 0.239273\n",
            "Epoch 54/100 [Train]: 100% 8/8 [00:00<00:00, 44.62it/s]\n",
            "Epoch 54/100 [Valid]: 100% 2/2 [00:00<00:00, 77.86it/s]\n",
            "Epoch [54/100] | Train Loss: 0.213455 | Validation Loss: 0.225270\n",
            "Epoch 55/100 [Train]: 100% 8/8 [00:00<00:00, 44.76it/s]\n",
            "Epoch 55/100 [Valid]: 100% 2/2 [00:00<00:00, 76.87it/s]\n",
            "Epoch [55/100] | Train Loss: 0.213294 | Validation Loss: 0.234343\n",
            "Epoch 56/100 [Train]: 100% 8/8 [00:00<00:00, 45.37it/s]\n",
            "Epoch 56/100 [Valid]: 100% 2/2 [00:00<00:00, 74.11it/s]\n",
            "Epoch [56/100] | Train Loss: 0.211814 | Validation Loss: 0.263045\n",
            "Epoch 57/100 [Train]: 100% 8/8 [00:00<00:00, 44.98it/s]\n",
            "Epoch 57/100 [Valid]: 100% 2/2 [00:00<00:00, 75.31it/s]\n",
            "Epoch [57/100] | Train Loss: 0.213176 | Validation Loss: 0.230628\n",
            "Epoch 58/100 [Train]: 100% 8/8 [00:00<00:00, 44.37it/s]\n",
            "Epoch 58/100 [Valid]: 100% 2/2 [00:00<00:00, 75.14it/s]\n",
            "Epoch [58/100] | Train Loss: 0.214945 | Validation Loss: 0.233658\n",
            "Epoch 59/100 [Train]: 100% 8/8 [00:00<00:00, 44.66it/s]\n",
            "Epoch 59/100 [Valid]: 100% 2/2 [00:00<00:00, 77.05it/s]\n",
            "Epoch [59/100] | Train Loss: 0.213610 | Validation Loss: 0.236761\n",
            "Epoch 60/100 [Train]: 100% 8/8 [00:00<00:00, 44.61it/s]\n",
            "Epoch 60/100 [Valid]: 100% 2/2 [00:00<00:00, 77.69it/s]\n",
            "Epoch [60/100] | Train Loss: 0.211888 | Validation Loss: 0.230726\n",
            "Epoch 61/100 [Train]: 100% 8/8 [00:00<00:00, 45.05it/s]\n",
            "Epoch 61/100 [Valid]: 100% 2/2 [00:00<00:00, 76.82it/s]\n",
            "Epoch [61/100] | Train Loss: 0.212329 | Validation Loss: 0.241836\n",
            "Epoch 62/100 [Train]: 100% 8/8 [00:00<00:00, 45.00it/s]\n",
            "Epoch 62/100 [Valid]: 100% 2/2 [00:00<00:00, 75.97it/s]\n",
            "Epoch [62/100] | Train Loss: 0.211271 | Validation Loss: 0.234122\n",
            "Epoch 63/100 [Train]: 100% 8/8 [00:00<00:00, 44.80it/s]\n",
            "Epoch 63/100 [Valid]: 100% 2/2 [00:00<00:00, 73.91it/s]\n",
            "Epoch [63/100] | Train Loss: 0.212609 | Validation Loss: 0.227365\n",
            "Epoch 64/100 [Train]: 100% 8/8 [00:00<00:00, 44.69it/s]\n",
            "Epoch 64/100 [Valid]: 100% 2/2 [00:00<00:00, 77.05it/s]\n",
            "Epoch [64/100] | Train Loss: 0.213271 | Validation Loss: 0.213365\n",
            "Epoch 65/100 [Train]: 100% 8/8 [00:00<00:00, 44.84it/s]\n",
            "Epoch 65/100 [Valid]: 100% 2/2 [00:00<00:00, 77.42it/s]\n",
            "Epoch [65/100] | Train Loss: 0.213487 | Validation Loss: 0.241679\n",
            "Epoch 66/100 [Train]: 100% 8/8 [00:00<00:00, 44.78it/s]\n",
            "Epoch 66/100 [Valid]: 100% 2/2 [00:00<00:00, 77.24it/s]\n",
            "Epoch [66/100] | Train Loss: 0.216119 | Validation Loss: 0.243933\n",
            "Epoch 67/100 [Train]: 100% 8/8 [00:00<00:00, 44.71it/s]\n",
            "Epoch 67/100 [Valid]: 100% 2/2 [00:00<00:00, 77.33it/s]\n",
            "Epoch [67/100] | Train Loss: 0.210824 | Validation Loss: 0.240512\n",
            "Epoch 68/100 [Train]: 100% 8/8 [00:00<00:00, 44.42it/s]\n",
            "Epoch 68/100 [Valid]: 100% 2/2 [00:00<00:00, 73.56it/s]\n",
            "Epoch [68/100] | Train Loss: 0.210022 | Validation Loss: 0.226622\n",
            "Epoch 69/100 [Train]: 100% 8/8 [00:00<00:00, 42.65it/s]\n",
            "Epoch 69/100 [Valid]: 100% 2/2 [00:00<00:00, 75.20it/s]\n",
            "Epoch [69/100] | Train Loss: 0.209315 | Validation Loss: 0.236859\n",
            "Epoch 70/100 [Train]: 100% 8/8 [00:00<00:00, 44.39it/s]\n",
            "Epoch 70/100 [Valid]: 100% 2/2 [00:00<00:00, 75.17it/s]\n",
            "Epoch [70/100] | Train Loss: 0.206869 | Validation Loss: 0.236258\n",
            "Epoch 71/100 [Train]: 100% 8/8 [00:00<00:00, 44.45it/s]\n",
            "Epoch 71/100 [Valid]: 100% 2/2 [00:00<00:00, 74.17it/s]\n",
            "Epoch [71/100] | Train Loss: 0.207477 | Validation Loss: 0.251184\n",
            "Epoch 72/100 [Train]: 100% 8/8 [00:00<00:00, 44.22it/s]\n",
            "Epoch 72/100 [Valid]: 100% 2/2 [00:00<00:00, 75.67it/s]\n",
            "Epoch [72/100] | Train Loss: 0.207166 | Validation Loss: 0.239930\n",
            "Epoch 73/100 [Train]: 100% 8/8 [00:00<00:00, 44.26it/s]\n",
            "Epoch 73/100 [Valid]: 100% 2/2 [00:00<00:00, 75.77it/s]\n",
            "Epoch [73/100] | Train Loss: 0.205926 | Validation Loss: 0.217623\n",
            "Epoch 74/100 [Train]: 100% 8/8 [00:00<00:00, 43.03it/s]\n",
            "Epoch 74/100 [Valid]: 100% 2/2 [00:00<00:00, 69.47it/s]\n",
            "Epoch [74/100] | Train Loss: 0.228609 | Validation Loss: 0.253269\n",
            "Epoch 75/100 [Train]: 100% 8/8 [00:00<00:00, 41.39it/s]\n",
            "Epoch 75/100 [Valid]: 100% 2/2 [00:00<00:00, 74.94it/s]\n",
            "Epoch [75/100] | Train Loss: 0.219607 | Validation Loss: 0.225985\n",
            "Epoch 76/100 [Train]: 100% 8/8 [00:00<00:00, 44.06it/s]\n",
            "Epoch 76/100 [Valid]: 100% 2/2 [00:00<00:00, 75.18it/s]\n",
            "Epoch [76/100] | Train Loss: 0.218178 | Validation Loss: 0.226900\n",
            "Epoch 77/100 [Train]: 100% 8/8 [00:00<00:00, 44.58it/s]\n",
            "Epoch 77/100 [Valid]: 100% 2/2 [00:00<00:00, 76.87it/s]\n",
            "Epoch [77/100] | Train Loss: 0.233181 | Validation Loss: 0.230113\n",
            "Epoch 78/100 [Train]: 100% 8/8 [00:00<00:00, 45.14it/s]\n",
            "Epoch 78/100 [Valid]: 100% 2/2 [00:00<00:00, 76.83it/s]\n",
            "Epoch [78/100] | Train Loss: 0.216604 | Validation Loss: 0.323127\n",
            "Epoch 79/100 [Train]: 100% 8/8 [00:00<00:00, 44.28it/s]\n",
            "Epoch 79/100 [Valid]: 100% 2/2 [00:00<00:00, 74.97it/s]\n",
            "Epoch [79/100] | Train Loss: 0.228528 | Validation Loss: 0.217988\n",
            "Epoch 80/100 [Train]: 100% 8/8 [00:00<00:00, 44.30it/s]\n",
            "Epoch 80/100 [Valid]: 100% 2/2 [00:00<00:00, 77.00it/s]\n",
            "Epoch [80/100] | Train Loss: 0.214913 | Validation Loss: 0.262651\n",
            "Epoch 81/100 [Train]: 100% 8/8 [00:00<00:00, 44.74it/s]\n",
            "Epoch 81/100 [Valid]: 100% 2/2 [00:00<00:00, 74.70it/s]\n",
            "Epoch [81/100] | Train Loss: 0.213414 | Validation Loss: 0.224678\n",
            "Epoch 82/100 [Train]: 100% 8/8 [00:00<00:00, 44.71it/s]\n",
            "Epoch 82/100 [Valid]: 100% 2/2 [00:00<00:00, 76.32it/s]\n",
            "Epoch [82/100] | Train Loss: 0.212202 | Validation Loss: 0.232969\n",
            "Epoch 83/100 [Train]: 100% 8/8 [00:00<00:00, 44.77it/s]\n",
            "Epoch 83/100 [Valid]: 100% 2/2 [00:00<00:00, 74.18it/s]\n",
            "Epoch [83/100] | Train Loss: 0.210628 | Validation Loss: 0.220114\n",
            "Epoch 84/100 [Train]: 100% 8/8 [00:00<00:00, 44.26it/s]\n",
            "Epoch 84/100 [Valid]: 100% 2/2 [00:00<00:00, 75.02it/s]\n",
            "Epoch [84/100] | Train Loss: 0.210443 | Validation Loss: 0.233909\n",
            "Epoch 85/100 [Train]: 100% 8/8 [00:00<00:00, 44.55it/s]\n",
            "Epoch 85/100 [Valid]: 100% 2/2 [00:00<00:00, 77.19it/s]\n",
            "Epoch [85/100] | Train Loss: 0.211819 | Validation Loss: 0.243264\n",
            "Epoch 86/100 [Train]: 100% 8/8 [00:00<00:00, 44.43it/s]\n",
            "Epoch 86/100 [Valid]: 100% 2/2 [00:00<00:00, 77.52it/s]\n",
            "Epoch [86/100] | Train Loss: 0.211215 | Validation Loss: 0.234750\n",
            "Epoch 87/100 [Train]: 100% 8/8 [00:00<00:00, 45.11it/s]\n",
            "Epoch 87/100 [Valid]: 100% 2/2 [00:00<00:00, 76.08it/s]\n",
            "Epoch [87/100] | Train Loss: 0.208740 | Validation Loss: 0.247374\n",
            "Epoch 88/100 [Train]: 100% 8/8 [00:00<00:00, 44.63it/s]\n",
            "Epoch 88/100 [Valid]: 100% 2/2 [00:00<00:00, 74.99it/s]\n",
            "Epoch [88/100] | Train Loss: 0.211167 | Validation Loss: 0.221960\n",
            "Epoch 89/100 [Train]: 100% 8/8 [00:00<00:00, 44.58it/s]\n",
            "Epoch 89/100 [Valid]: 100% 2/2 [00:00<00:00, 74.27it/s]\n",
            "Epoch [89/100] | Train Loss: 0.207327 | Validation Loss: 0.231190\n",
            "Epoch 90/100 [Train]: 100% 8/8 [00:00<00:00, 44.48it/s]\n",
            "Epoch 90/100 [Valid]: 100% 2/2 [00:00<00:00, 75.58it/s]\n",
            "Epoch [90/100] | Train Loss: 0.205376 | Validation Loss: 0.217691\n",
            "Epoch 91/100 [Train]: 100% 8/8 [00:00<00:00, 43.89it/s]\n",
            "Epoch 91/100 [Valid]: 100% 2/2 [00:00<00:00, 77.22it/s]\n",
            "Epoch [91/100] | Train Loss: 0.201279 | Validation Loss: 0.230039\n",
            "Epoch 92/100 [Train]: 100% 8/8 [00:00<00:00, 44.62it/s]\n",
            "Epoch 92/100 [Valid]: 100% 2/2 [00:00<00:00, 76.69it/s]\n",
            "Epoch [92/100] | Train Loss: 0.204121 | Validation Loss: 0.268127\n",
            "Epoch 93/100 [Train]: 100% 8/8 [00:00<00:00, 44.95it/s]\n",
            "Epoch 93/100 [Valid]: 100% 2/2 [00:00<00:00, 75.61it/s]\n",
            "Epoch [93/100] | Train Loss: 0.205370 | Validation Loss: 0.254358\n",
            "Epoch 94/100 [Train]: 100% 8/8 [00:00<00:00, 44.30it/s]\n",
            "Epoch 94/100 [Valid]: 100% 2/2 [00:00<00:00, 75.49it/s]\n",
            "Epoch [94/100] | Train Loss: 0.194043 | Validation Loss: 0.242224\n",
            "Epoch 95/100 [Train]: 100% 8/8 [00:00<00:00, 44.32it/s]\n",
            "Epoch 95/100 [Valid]: 100% 2/2 [00:00<00:00, 76.32it/s]\n",
            "Epoch [95/100] | Train Loss: 0.203013 | Validation Loss: 0.227434\n",
            "Epoch 96/100 [Train]: 100% 8/8 [00:00<00:00, 44.47it/s]\n",
            "Epoch 96/100 [Valid]: 100% 2/2 [00:00<00:00, 77.46it/s]\n",
            "Epoch [96/100] | Train Loss: 0.206366 | Validation Loss: 0.256224\n",
            "Epoch 97/100 [Train]: 100% 8/8 [00:00<00:00, 44.67it/s]\n",
            "Epoch 97/100 [Valid]: 100% 2/2 [00:00<00:00, 76.27it/s]\n",
            "Epoch [97/100] | Train Loss: 0.217222 | Validation Loss: 0.207599\n",
            "Epoch 98/100 [Train]: 100% 8/8 [00:00<00:00, 44.42it/s]\n",
            "Epoch 98/100 [Valid]: 100% 2/2 [00:00<00:00, 75.56it/s]\n",
            "Epoch [98/100] | Train Loss: 0.211411 | Validation Loss: 0.213800\n",
            "Epoch 99/100 [Train]: 100% 8/8 [00:00<00:00, 44.15it/s]\n",
            "Epoch 99/100 [Valid]: 100% 2/2 [00:00<00:00, 76.64it/s]\n",
            "Epoch [99/100] | Train Loss: 0.202513 | Validation Loss: 0.239283\n",
            "Epoch 100/100 [Train]: 100% 8/8 [00:00<00:00, 44.51it/s]\n",
            "Epoch 100/100 [Valid]: 100% 2/2 [00:00<00:00, 77.01it/s]\n",
            "Epoch [100/100] | Train Loss: 0.192473 | Validation Loss: 0.244370\n",
            "\n",
            "--- Huấn luyện Hoàn tất ---\n",
            "✅ Model cuối cùng đã được lưu tại epoch có Validation Loss = 0.205983\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile evaluate.py\n",
        "# evaluate.py\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "from config import (\n",
        "    NUM_BASE_FEATURES, NUM_SCALES, LSTM_HIDDEN_UNITS, LSTM_NUM_LAYERS,\n",
        "    ATTENTION_NUM_HEADS, TRAINED_MODEL_PATH\n",
        ")\n",
        "from model import FinalModel\n",
        "from dataset import get_data_loaders\n",
        "\n",
        "def run_evaluation():\n",
        "    \"\"\"Hàm chính để đánh giá mô hình đa nhiệm trên tập test.\"\"\"\n",
        "\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    print(f\"Sử dụng thiết bị: {device.upper()}\")\n",
        "\n",
        "    # 1. Tải dữ liệu\n",
        "    _, test_loader, target_scaler, volatility_scaler = get_data_loaders()\n",
        "    if not test_loader:\n",
        "        print(\"Dừng chương trình vì không tải được dữ liệu.\")\n",
        "        return\n",
        "\n",
        "    # 2. Tải lại mô hình đã huấn luyện\n",
        "    print(f\"Đang tải mô hình từ: {TRAINED_MODEL_PATH}\")\n",
        "    model = FinalModel(\n",
        "        input_feature_size=NUM_BASE_FEATURES, num_scales=NUM_SCALES,\n",
        "        lstm_hidden_units=LSTM_HIDDEN_UNITS, lstm_num_layers=LSTM_NUM_LAYERS,\n",
        "        num_heads=ATTENTION_NUM_HEADS\n",
        "    )\n",
        "    try:\n",
        "        model.load_state_dict(torch.load(TRAINED_MODEL_PATH, map_location=device))\n",
        "        model.to(device)\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Lỗi: Không tìm thấy file model tại '{TRAINED_MODEL_PATH}'. Vui lòng chạy train.py trước.\")\n",
        "        return\n",
        "\n",
        "    # 3. Đánh giá trên tập Test\n",
        "    model.eval()\n",
        "    all_price_preds, all_trend_preds, all_vol_preds = [], [], []\n",
        "    all_price_lbls, all_trend_lbls, all_vol_lbls = [], [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for features, (price_lbl, trend_lbl, vol_lbl) in test_loader:\n",
        "            features = features.to(device)\n",
        "\n",
        "            price_pred, trend_pred, vol_pred = model(features)\n",
        "\n",
        "            # Lưu lại kết quả dự đoán và nhãn thực tế\n",
        "            all_price_preds.extend(price_pred.cpu().numpy())\n",
        "            all_trend_preds.extend(trend_pred.cpu().numpy())\n",
        "\n",
        "            all_price_lbls.extend(price_lbl.numpy())\n",
        "            all_trend_lbls.extend(trend_lbl.numpy())\n",
        "\n",
        "    # 4. Xử lý và Giải chuẩn hóa\n",
        "    # --- Xử lý cho Dự đoán Giá ---\n",
        "    price_preds = np.array(all_price_preds).reshape(-1, 1)\n",
        "    price_actuals = np.array(all_price_lbls).reshape(-1, 1)\n",
        "    original_price_preds = target_scaler.inverse_transform(price_preds)\n",
        "    original_price_actuals = target_scaler.inverse_transform(price_actuals)\n",
        "\n",
        "    # --- Xử lý cho Dự đoán Xu hướng ---\n",
        "    # Chuyển đổi output của model (logits) thành xác suất rồi thành nhãn (0 hoặc 1)\n",
        "    trend_probs = torch.sigmoid(torch.tensor(all_trend_preds)).numpy()\n",
        "    trend_preds_labels = (trend_probs > 0.5).astype(int)\n",
        "    trend_actuals = np.array(all_trend_lbls)\n",
        "\n",
        "    # 5. Tính toán các chỉ số và in kết quả\n",
        "    print(\"\\n--- Kết quả Đánh giá trên Tập Test (Model Cuối cùng) ---\")\n",
        "\n",
        "    # --- Nhiệm vụ 1: Dự đoán Giá ---\n",
        "    mae = np.mean(np.abs(original_price_preds - original_price_actuals))\n",
        "    print(f\"🎯 [Giá] Sai số Trung bình Tuyệt đối (MAE): {mae:.4f} (điểm VN-Index)\")\n",
        "\n",
        "    # --- Nhiệm vụ 2: Dự đoán Xu hướng ---\n",
        "    accuracy = accuracy_score(trend_actuals, trend_preds_labels)\n",
        "    print(f\"🎯 [Xu hướng] Độ chính xác (Accuracy): {accuracy * 100:.2f}%\")\n",
        "\n",
        "    # 6. Vẽ biểu đồ\n",
        "    # --- Biểu đồ 1: So sánh Giá ---\n",
        "    plt.figure(figsize=(15, 6))\n",
        "    plt.plot(original_price_actuals, label='Giá trị Thực tế', color='blue', marker='.', linestyle='-')\n",
        "    plt.plot(original_price_preds, label='Giá trị Dự đoán', color='red', linestyle='--')\n",
        "    plt.title('So sánh Giá trị Thực tế và Dự đoán (Model Cuối cùng)')\n",
        "    plt.xlabel('Ngày (trong tập Test)')\n",
        "    plt.ylabel('Giá đóng cửa VN-Index')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig('final_prediction_vs_actual.png')\n",
        "    print(\"\\n✅ Đã lưu biểu đồ so sánh giá vào file 'final_prediction_vs_actual.png'\")\n",
        "\n",
        "    # --- Biểu đồ 2: Ma trận nhầm lẫn cho Xu hướng ---\n",
        "    cm = confusion_matrix(trend_actuals, trend_preds_labels)\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Giảm', 'Tăng'])\n",
        "    fig, ax = plt.subplots(figsize=(6, 6))\n",
        "    disp.plot(ax=ax, cmap=plt.cm.Blues)\n",
        "    ax.set_title('Ma trận Nhầm lẫn - Dự đoán Xu hướng')\n",
        "    plt.savefig('final_confusion_matrix.png')\n",
        "    print(\"✅ Đã lưu ma trận nhầm lẫn vào file 'final_confusion_matrix.png'\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    run_evaluation()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OfytOWoegJj0",
        "outputId": "ee085cc7-4c22-4f4a-f95d-8300c2a1f05b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting evaluate.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python evaluate.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7eL6y7NUgK6x",
        "outputId": "452fddc9-34e6-4383-9f37-eed38b13dbdf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sử dụng thiết bị: CUDA\n",
            "✅ DataLoader đa nhiệm đã sẵn sàng.\n",
            "Đang tải mô hình từ: final_optimized_model.pth\n",
            "\n",
            "--- Kết quả Đánh giá trên Tập Test (Model Cuối cùng) ---\n",
            "🎯 [Giá] Sai số Trung bình Tuyệt đối (MAE): 20.7005 (điểm VN-Index)\n",
            "🎯 [Xu hướng] Độ chính xác (Accuracy): 61.29%\n",
            "\n",
            "✅ Đã lưu biểu đồ so sánh giá vào file 'final_prediction_vs_actual.png'\n",
            "✅ Đã lưu ma trận nhầm lẫn vào file 'final_confusion_matrix.png'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***ESEMBLE***"
      ],
      "metadata": {
        "id": "ODeSuOt3hM0E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile model.py\n",
        "# model.py\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from config import BATCH_SIZE, LOOKBACK_WINDOW, NUM_BASE_FEATURES, NUM_SCALES\n",
        "\n",
        "# --- KIẾN TRÚC 1: MS-LSTM + ATTENTION ---\n",
        "class MSLSTMAttention(nn.Module):\n",
        "    def __init__(self, input_feature_size, num_scales, lstm_hidden_units, lstm_num_layers, num_heads):\n",
        "        super(MSLSTMAttention, self).__init__()\n",
        "        self.num_scales = num_scales\n",
        "        self.input_feature_size = input_feature_size\n",
        "        self.lstm_branches = nn.ModuleList([\n",
        "            nn.LSTM(input_size=input_feature_size, hidden_size=lstm_hidden_units,\n",
        "                    num_layers=lstm_num_layers, batch_first=True, dropout=0.2 if lstm_num_layers > 1 else 0)\n",
        "            for _ in range(num_scales)\n",
        "        ])\n",
        "        self.attention = nn.MultiheadAttention(\n",
        "            embed_dim=lstm_hidden_units * num_scales,\n",
        "            num_heads=num_heads,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.fc = nn.Linear(in_features=lstm_hidden_units * num_scales, out_features=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        branch_outputs = []\n",
        "        for i in range(self.num_scales):\n",
        "            branch_input = x[:, :, i*self.input_feature_size : (i+1)*self.input_feature_size]\n",
        "            output, _ = self.lstm_branches[i](branch_input)\n",
        "            branch_outputs.append(output)\n",
        "\n",
        "        concatenated_output = torch.cat(branch_outputs, dim=2)\n",
        "        attention_output, _ = self.attention(concatenated_output, concatenated_output, concatenated_output)\n",
        "        last_time_step_output = attention_output[:, -1, :]\n",
        "        final_prediction = self.fc(last_time_step_output)\n",
        "        return final_prediction.squeeze()\n",
        "\n",
        "# --- KIẾN TRÚC 2: FINAL MODEL (HIERARCHICAL + MULTI-TASK) ---\n",
        "class FinalModel(nn.Module):\n",
        "    def __init__(self, input_feature_size, num_scales, lstm_hidden_units, lstm_num_layers, num_heads):\n",
        "        super(FinalModel, self).__init__()\n",
        "        self.input_feature_size = input_feature_size\n",
        "        self.num_scales = num_scales\n",
        "\n",
        "        self.lstm_branches = nn.ModuleList([\n",
        "            nn.LSTM(input_size=self.input_feature_size, hidden_size=lstm_hidden_units,\n",
        "                    num_layers=lstm_num_layers, batch_first=True, dropout=0.2 if lstm_num_layers > 1 else 0)\n",
        "            for _ in range(self.num_scales)\n",
        "        ])\n",
        "        self.attention = nn.MultiheadAttention(embed_dim=lstm_hidden_units * self.num_scales,\n",
        "                                             num_heads=num_heads, batch_first=True)\n",
        "\n",
        "        shared_feature_dim = lstm_hidden_units * self.num_scales\n",
        "        self.intermediate_layer = nn.Sequential(\n",
        "            nn.Linear(shared_feature_dim, shared_feature_dim // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3)\n",
        "        )\n",
        "\n",
        "        self.price_head = nn.Linear(shared_feature_dim // 2, 1)\n",
        "        self.trend_head = nn.Sequential(\n",
        "            nn.Linear(shared_feature_dim // 2, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 1)\n",
        "        )\n",
        "        self.volatility_head = nn.Linear(shared_feature_dim // 2, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        branch_outputs = []\n",
        "        for i in range(self.num_scales):\n",
        "            branch_input = x[:, :, i*self.input_feature_size : (i+1)*self.input_feature_size]\n",
        "            output, _ = self.lstm_branches[i](branch_input)\n",
        "            branch_outputs.append(output)\n",
        "\n",
        "        concatenated_output = torch.cat(branch_outputs, dim=2)\n",
        "        attention_output, _ = self.attention(concatenated_output, concatenated_output, concatenated_output)\n",
        "        shared_features = self.intermediate_layer(attention_output[:, -1, :])\n",
        "\n",
        "        price_prediction = self.price_head(shared_features)\n",
        "        trend_prediction = self.trend_head(shared_features)\n",
        "        volatility_prediction = self.volatility_head(shared_features)\n",
        "\n",
        "        return price_prediction.squeeze(), trend_prediction.squeeze(), volatility_prediction.squeeze()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pf5BZL1chQAx",
        "outputId": "cbca5ac3-f36e-4d24-b419-b4a8c71bcc70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing model.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python model.py"
      ],
      "metadata": {
        "id": "LF6HS4kbhSFN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile ensemble_evaluate.py\n",
        "# ensemble_evaluate.py\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Import cả hai lớp kiến trúc\n",
        "from model import MSLSTMAttention, FinalModel\n",
        "from dataset import get_data_loaders\n",
        "from config import NUM_BASE_FEATURES, NUM_SCALES\n",
        "\n",
        "def run_ensemble_evaluation():\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    print(f\"Sử dụng thiết bị: {device.upper()}\")\n",
        "\n",
        "    # 1. Tải dữ liệu\n",
        "    # Chúng ta cần target_scaler để giải chuẩn hóa\n",
        "    _, test_loader, target_scaler, _ = get_data_loaders()\n",
        "    if not test_loader: return\n",
        "\n",
        "    # 2. Định nghĩa và tải các model\n",
        "    # (Giữ nguyên phần tải model)\n",
        "    model_A_params = {'lstm_hidden_units': 128, 'lstm_num_layers': 2, 'attention_num_heads': 4}\n",
        "    model_A_path = 'mslstm_attention_tuned.pth'\n",
        "    model_A = MSLSTMAttention(\n",
        "        input_feature_size=NUM_BASE_FEATURES, num_scales=NUM_SCALES,\n",
        "        lstm_hidden_units=model_A_params['lstm_hidden_units'],\n",
        "        lstm_num_layers=model_A_params['lstm_num_layers'],\n",
        "        num_heads=model_A_params['attention_num_heads']\n",
        "    )\n",
        "\n",
        "    model_B_params = {'lstm_hidden_units': 192, 'lstm_num_layers': 1, 'attention_num_heads': 8}\n",
        "    model_B_path = 'final_optimized_model.pth'\n",
        "    model_B = FinalModel(\n",
        "        input_feature_size=NUM_BASE_FEATURES, num_scales=NUM_SCALES,\n",
        "        lstm_hidden_units=model_B_params['lstm_hidden_units'],\n",
        "        lstm_num_layers=model_B_params['lstm_num_layers'],\n",
        "        num_heads=model_B_params['attention_num_heads']\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        print(f\"Đang tải Model A từ: {model_A_path}\")\n",
        "        model_A.load_state_dict(torch.load(model_A_path, map_location=device))\n",
        "        model_A.to(device)\n",
        "        model_A.eval()\n",
        "\n",
        "        print(f\"Đang tải Model B từ: {model_B_path}\")\n",
        "        model_B.load_state_dict(torch.load(model_B_path, map_location=device))\n",
        "        model_B.to(device)\n",
        "        model_B.eval()\n",
        "    except FileNotFoundError as e:\n",
        "        print(f\"Lỗi: Không tìm thấy file model. Hãy đảm bảo các file sau tồn tại: {e.filename}\")\n",
        "        return\n",
        "\n",
        "    # 3. Lấy dự đoán và thực hiện ensemble\n",
        "    original_preds_ensemble = []\n",
        "    original_actuals_list = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for features, (price_lbl, _, _) in test_loader:\n",
        "            features = features.to(device)\n",
        "\n",
        "            # --- LOGIC SỬA LỖI ---\n",
        "            # a. Lấy dự đoán đã chuẩn hóa từ mỗi model\n",
        "            scaled_pred_A = model_A(features)\n",
        "            scaled_pred_B_price, _, _ = model_B(features)\n",
        "\n",
        "            # b. Giải chuẩn hóa từng dự đoán một\n",
        "            original_pred_A = target_scaler.inverse_transform(scaled_pred_A.cpu().numpy().reshape(-1, 1))\n",
        "            original_pred_B = target_scaler.inverse_transform(scaled_pred_B_price.cpu().numpy().reshape(-1, 1))\n",
        "\n",
        "            # c. Lấy trung bình các dự đoán đã được giải chuẩn hóa\n",
        "            avg_pred_original = (original_pred_A + original_pred_B) / 2.0\n",
        "\n",
        "            # d. Giải chuẩn hóa giá trị thực để so sánh\n",
        "            original_actuals = target_scaler.inverse_transform(price_lbl.numpy().reshape(-1, 1))\n",
        "\n",
        "            original_preds_ensemble.extend(avg_pred_original.flatten())\n",
        "            original_actuals_list.extend(original_actuals.flatten())\n",
        "\n",
        "    # 4. Tính toán sai số\n",
        "    mae = np.mean(np.abs(np.array(original_preds_ensemble) - np.array(original_actuals_list)))\n",
        "    print(\"\\n--- Kết quả Đánh giá của 'Hội đồng Chuyên gia' (Ensemble) - ĐÃ SỬA LỖI ---\")\n",
        "    print(f\"🏆 [Giá] Sai số Trung bình Tuyệt đối (MAE): {mae:.4f} (điểm VN-Index)\")\n",
        "\n",
        "    # 5. Vẽ biểu đồ\n",
        "    plt.figure(figsize=(15, 6))\n",
        "    plt.plot(original_actuals_list, label='Giá trị Thực tế', color='blue', marker='.', linestyle='-')\n",
        "    plt.plot(original_preds_ensemble, label='Dự đoán Ensemble', color='green', linestyle='--')\n",
        "    plt.title(\"So sánh Giá trị Thực tế và Dự đoán Ensemble (Đã sửa lỗi)\")\n",
        "    plt.xlabel('Ngày (trong tập Test)')\n",
        "    plt.ylabel('Giá đóng cửa VN-Index')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig('final_ensemble_prediction_corrected.png')\n",
        "    print(\"✅ Đã lưu biểu đồ so sánh của Ensemble vào file 'final_ensemble_prediction_corrected.png'\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    run_ensemble_evaluation()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AE0wuKB3hXsa",
        "outputId": "bfb13b3d-bf97-465e-c669-52825da6cf1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting ensemble_evaluate.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python ensemble_evaluate.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WirRtaehZd0",
        "outputId": "26d3b513-8f84-483f-a73e-fefdfcf3505d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sử dụng thiết bị: CUDA\n",
            "✅ DataLoader đa nhiệm đã sẵn sàng.\n",
            "Đang tải Model A từ: mslstm_attention_tuned.pth\n",
            "Đang tải Model B từ: final_optimized_model.pth\n",
            "\n",
            "--- Kết quả Đánh giá của 'Hội đồng Chuyên gia' (Ensemble) - ĐÃ SỬA LỖI ---\n",
            "🏆 [Giá] Sai số Trung bình Tuyệt đối (MAE): 33.4388 (điểm VN-Index)\n",
            "✅ Đã lưu biểu đồ so sánh của Ensemble vào file 'final_ensemble_prediction_corrected.png'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile train_simple_model.py\n",
        "# train_simple_model.py\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "# Import các config đã được tối ưu từ bước trước\n",
        "from config import (\n",
        "    NUM_BASE_FEATURES, NUM_SCALES,\n",
        "    # Dùng các tham số mặc định nhưng hiệu quả cho model đơn giản hơn\n",
        "    LSTM_HIDDEN_UNITS, LSTM_NUM_LAYERS, ATTENTION_NUM_HEADS,\n",
        "    LEARNING_RATE, NUM_EPOCHS\n",
        ")\n",
        "# Import kiến trúc model đơn giản\n",
        "from model import MSLSTMAttention\n",
        "# QUAN TRỌNG: Import hàm get_data_loaders mới nhất để đảm bảo đồng bộ\n",
        "from dataset import get_data_loaders\n",
        "\n",
        "# Đặt tên file riêng cho model này để tránh ghi đè\n",
        "SIMPLE_MODEL_PATH = 'mslstm_attention_synced.pth'\n",
        "\n",
        "def run_simple_training():\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    print(f\"Sử dụng thiết bị: {device.upper()}\")\n",
        "\n",
        "    # 1. Tải dữ liệu bằng data loader mới nhất\n",
        "    # Nó sẽ trả về 3 loại label, nhưng chúng ta chỉ dùng price_label\n",
        "    train_loader, test_loader, _, _ = get_data_loaders()\n",
        "    if not train_loader: return\n",
        "\n",
        "    # 2. Khởi tạo Model A\n",
        "    model = MSLSTMAttention(\n",
        "        input_feature_size=NUM_BASE_FEATURES,\n",
        "        num_scales=NUM_SCALES,\n",
        "        lstm_hidden_units=128, # Dùng một giá trị hợp lý\n",
        "        lstm_num_layers=2,\n",
        "        num_heads=4\n",
        "    ).to(device)\n",
        "\n",
        "    # Model này chỉ có 1 nhiệm vụ nên chỉ cần 1 hàm loss\n",
        "    loss_function = nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    print(\"\\n--- Bắt đầu Huấn luyện lại Model A (Đồng bộ) ---\")\n",
        "    best_val_loss = float('inf')\n",
        "\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        # Chỉ lấy price_lbl từ bộ dữ liệu\n",
        "        for features, (price_lbl, _, _) in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS} [Train]\"):\n",
        "            features, price_lbl = features.to(device), price_lbl.to(device)\n",
        "\n",
        "            outputs = model(features)\n",
        "            loss = loss_function(outputs, price_lbl)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for features, (price_lbl, _, _) in test_loader:\n",
        "                features, price_lbl = features.to(device), price_lbl.to(device)\n",
        "                outputs = model(features)\n",
        "                loss = loss_function(outputs, price_lbl)\n",
        "                val_loss += loss.item()\n",
        "\n",
        "        avg_train_loss = train_loss / len(train_loader)\n",
        "        avg_val_loss = val_loss / len(test_loader)\n",
        "\n",
        "        print(f\"Epoch [{epoch+1:02d}/{NUM_EPOCHS}] | Train Loss: {avg_train_loss:.6f} | Val Loss: {avg_val_loss:.6f}\")\n",
        "\n",
        "        if avg_val_loss < best_val_loss:\n",
        "            best_val_loss = avg_val_loss\n",
        "            torch.save(model.state_dict(), SIMPLE_MODEL_PATH)\n",
        "            print(f\"   -> Val loss cải thiện. Đã lưu model vào '{SIMPLE_MODEL_PATH}'\")\n",
        "\n",
        "    print(f\"\\n--- Huấn luyện Hoàn tất ---\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    run_simple_training()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IyWV3P3Ui61s",
        "outputId": "140d4825-e4ff-4c8c-c09f-85f8b5ec4f5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing train_simple_model.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train_simple_model.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hAgJKrbYi_LE",
        "outputId": "57e410a9-ada4-4aa5-d4c6-089cc73eb4bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sử dụng thiết bị: CUDA\n",
            "✅ DataLoader đa nhiệm đã sẵn sàng.\n",
            "\n",
            "--- Bắt đầu Huấn luyện lại Model A (Đồng bộ) ---\n",
            "Epoch 1/100 [Train]: 100% 8/8 [00:00<00:00, 22.98it/s]\n",
            "Epoch [01/100] | Train Loss: 0.129956 | Val Loss: 0.006859\n",
            "   -> Val loss cải thiện. Đã lưu model vào 'mslstm_attention_synced.pth'\n",
            "Epoch 2/100 [Train]: 100% 8/8 [00:00<00:00, 74.54it/s]\n",
            "Epoch [02/100] | Train Loss: 0.052934 | Val Loss: 0.036107\n",
            "Epoch 3/100 [Train]: 100% 8/8 [00:00<00:00, 90.49it/s]\n",
            "Epoch [03/100] | Train Loss: 0.048240 | Val Loss: 0.004623\n",
            "   -> Val loss cải thiện. Đã lưu model vào 'mslstm_attention_synced.pth'\n",
            "Epoch 4/100 [Train]: 100% 8/8 [00:00<00:00, 97.95it/s]\n",
            "Epoch [04/100] | Train Loss: 0.042537 | Val Loss: 0.009207\n",
            "Epoch 5/100 [Train]: 100% 8/8 [00:00<00:00, 105.60it/s]\n",
            "Epoch [05/100] | Train Loss: 0.042286 | Val Loss: 0.008672\n",
            "Epoch 6/100 [Train]: 100% 8/8 [00:00<00:00, 106.50it/s]\n",
            "Epoch [06/100] | Train Loss: 0.044165 | Val Loss: 0.006925\n",
            "Epoch 7/100 [Train]: 100% 8/8 [00:00<00:00, 105.92it/s]\n",
            "Epoch [07/100] | Train Loss: 0.040683 | Val Loss: 0.006056\n",
            "Epoch 8/100 [Train]: 100% 8/8 [00:00<00:00, 100.66it/s]\n",
            "Epoch [08/100] | Train Loss: 0.041816 | Val Loss: 0.009013\n",
            "Epoch 9/100 [Train]: 100% 8/8 [00:00<00:00, 104.45it/s]\n",
            "Epoch [09/100] | Train Loss: 0.041760 | Val Loss: 0.005343\n",
            "Epoch 10/100 [Train]: 100% 8/8 [00:00<00:00, 104.93it/s]\n",
            "Epoch [10/100] | Train Loss: 0.040896 | Val Loss: 0.008591\n",
            "Epoch 11/100 [Train]: 100% 8/8 [00:00<00:00, 102.09it/s]\n",
            "Epoch [11/100] | Train Loss: 0.041962 | Val Loss: 0.004617\n",
            "   -> Val loss cải thiện. Đã lưu model vào 'mslstm_attention_synced.pth'\n",
            "Epoch 12/100 [Train]: 100% 8/8 [00:00<00:00, 101.44it/s]\n",
            "Epoch [12/100] | Train Loss: 0.044101 | Val Loss: 0.004553\n",
            "   -> Val loss cải thiện. Đã lưu model vào 'mslstm_attention_synced.pth'\n",
            "Epoch 13/100 [Train]: 100% 8/8 [00:00<00:00, 101.78it/s]\n",
            "Epoch [13/100] | Train Loss: 0.041556 | Val Loss: 0.011471\n",
            "Epoch 14/100 [Train]: 100% 8/8 [00:00<00:00, 100.46it/s]\n",
            "Epoch [14/100] | Train Loss: 0.041239 | Val Loss: 0.004853\n",
            "Epoch 15/100 [Train]: 100% 8/8 [00:00<00:00, 88.26it/s]\n",
            "Epoch [15/100] | Train Loss: 0.042577 | Val Loss: 0.006235\n",
            "Epoch 16/100 [Train]: 100% 8/8 [00:00<00:00, 99.78it/s]\n",
            "Epoch [16/100] | Train Loss: 0.041460 | Val Loss: 0.008877\n",
            "Epoch 17/100 [Train]: 100% 8/8 [00:00<00:00, 90.57it/s]\n",
            "Epoch [17/100] | Train Loss: 0.043362 | Val Loss: 0.010623\n",
            "Epoch 18/100 [Train]: 100% 8/8 [00:00<00:00, 86.46it/s]\n",
            "Epoch [18/100] | Train Loss: 0.045490 | Val Loss: 0.005402\n",
            "Epoch 19/100 [Train]: 100% 8/8 [00:00<00:00, 104.56it/s]\n",
            "Epoch [19/100] | Train Loss: 0.044429 | Val Loss: 0.009395\n",
            "Epoch 20/100 [Train]: 100% 8/8 [00:00<00:00, 102.48it/s]\n",
            "Epoch [20/100] | Train Loss: 0.042276 | Val Loss: 0.014765\n",
            "Epoch 21/100 [Train]: 100% 8/8 [00:00<00:00, 101.98it/s]\n",
            "Epoch [21/100] | Train Loss: 0.044779 | Val Loss: 0.005580\n",
            "Epoch 22/100 [Train]: 100% 8/8 [00:00<00:00, 88.67it/s]\n",
            "Epoch [22/100] | Train Loss: 0.043342 | Val Loss: 0.014929\n",
            "Epoch 23/100 [Train]: 100% 8/8 [00:00<00:00, 103.55it/s]\n",
            "Epoch [23/100] | Train Loss: 0.044079 | Val Loss: 0.009179\n",
            "Epoch 24/100 [Train]: 100% 8/8 [00:00<00:00, 105.34it/s]\n",
            "Epoch [24/100] | Train Loss: 0.042888 | Val Loss: 0.005198\n",
            "Epoch 25/100 [Train]: 100% 8/8 [00:00<00:00, 101.65it/s]\n",
            "Epoch [25/100] | Train Loss: 0.041613 | Val Loss: 0.011649\n",
            "Epoch 26/100 [Train]: 100% 8/8 [00:00<00:00, 86.77it/s]\n",
            "Epoch [26/100] | Train Loss: 0.042241 | Val Loss: 0.004830\n",
            "Epoch 27/100 [Train]: 100% 8/8 [00:00<00:00, 105.68it/s]\n",
            "Epoch [27/100] | Train Loss: 0.041283 | Val Loss: 0.013817\n",
            "Epoch 28/100 [Train]: 100% 8/8 [00:00<00:00, 104.47it/s]\n",
            "Epoch [28/100] | Train Loss: 0.041811 | Val Loss: 0.004576\n",
            "Epoch 29/100 [Train]: 100% 8/8 [00:00<00:00, 100.89it/s]\n",
            "Epoch [29/100] | Train Loss: 0.041891 | Val Loss: 0.006784\n",
            "Epoch 30/100 [Train]: 100% 8/8 [00:00<00:00, 105.28it/s]\n",
            "Epoch [30/100] | Train Loss: 0.041714 | Val Loss: 0.004666\n",
            "Epoch 31/100 [Train]: 100% 8/8 [00:00<00:00, 100.67it/s]\n",
            "Epoch [31/100] | Train Loss: 0.043268 | Val Loss: 0.009304\n",
            "Epoch 32/100 [Train]: 100% 8/8 [00:00<00:00, 84.39it/s]\n",
            "Epoch [32/100] | Train Loss: 0.041067 | Val Loss: 0.008683\n",
            "Epoch 33/100 [Train]: 100% 8/8 [00:00<00:00, 102.62it/s]\n",
            "Epoch [33/100] | Train Loss: 0.040816 | Val Loss: 0.005276\n",
            "Epoch 34/100 [Train]: 100% 8/8 [00:00<00:00, 101.30it/s]\n",
            "Epoch [34/100] | Train Loss: 0.041232 | Val Loss: 0.006540\n",
            "Epoch 35/100 [Train]: 100% 8/8 [00:00<00:00, 103.41it/s]\n",
            "Epoch [35/100] | Train Loss: 0.041454 | Val Loss: 0.004705\n",
            "Epoch 36/100 [Train]: 100% 8/8 [00:00<00:00, 104.55it/s]\n",
            "Epoch [36/100] | Train Loss: 0.041899 | Val Loss: 0.006537\n",
            "Epoch 37/100 [Train]: 100% 8/8 [00:00<00:00, 103.83it/s]\n",
            "Epoch [37/100] | Train Loss: 0.040943 | Val Loss: 0.004597\n",
            "Epoch 38/100 [Train]: 100% 8/8 [00:00<00:00, 91.27it/s]\n",
            "Epoch [38/100] | Train Loss: 0.042518 | Val Loss: 0.007330\n",
            "Epoch 39/100 [Train]: 100% 8/8 [00:00<00:00, 106.17it/s]\n",
            "Epoch [39/100] | Train Loss: 0.041009 | Val Loss: 0.014150\n",
            "Epoch 40/100 [Train]: 100% 8/8 [00:00<00:00, 99.57it/s]\n",
            "Epoch [40/100] | Train Loss: 0.042783 | Val Loss: 0.005225\n",
            "Epoch 41/100 [Train]: 100% 8/8 [00:00<00:00, 105.49it/s]\n",
            "Epoch [41/100] | Train Loss: 0.041531 | Val Loss: 0.004675\n",
            "Epoch 42/100 [Train]: 100% 8/8 [00:00<00:00, 100.70it/s]\n",
            "Epoch [42/100] | Train Loss: 0.044651 | Val Loss: 0.018330\n",
            "Epoch 43/100 [Train]: 100% 8/8 [00:00<00:00, 103.64it/s]\n",
            "Epoch [43/100] | Train Loss: 0.042186 | Val Loss: 0.005729\n",
            "Epoch 44/100 [Train]: 100% 8/8 [00:00<00:00, 102.05it/s]\n",
            "Epoch [44/100] | Train Loss: 0.042678 | Val Loss: 0.004545\n",
            "   -> Val loss cải thiện. Đã lưu model vào 'mslstm_attention_synced.pth'\n",
            "Epoch 45/100 [Train]: 100% 8/8 [00:00<00:00, 99.53it/s]\n",
            "Epoch [45/100] | Train Loss: 0.042538 | Val Loss: 0.008141\n",
            "Epoch 46/100 [Train]: 100% 8/8 [00:00<00:00, 105.53it/s]\n",
            "Epoch [46/100] | Train Loss: 0.041472 | Val Loss: 0.006746\n",
            "Epoch 47/100 [Train]: 100% 8/8 [00:00<00:00, 104.50it/s]\n",
            "Epoch [47/100] | Train Loss: 0.040572 | Val Loss: 0.007370\n",
            "Epoch 48/100 [Train]: 100% 8/8 [00:00<00:00, 100.46it/s]\n",
            "Epoch [48/100] | Train Loss: 0.044384 | Val Loss: 0.012712\n",
            "Epoch 49/100 [Train]: 100% 8/8 [00:00<00:00, 95.66it/s]\n",
            "Epoch [49/100] | Train Loss: 0.052182 | Val Loss: 0.004856\n",
            "Epoch 50/100 [Train]: 100% 8/8 [00:00<00:00, 99.52it/s]\n",
            "Epoch [50/100] | Train Loss: 0.047933 | Val Loss: 0.029635\n",
            "Epoch 51/100 [Train]: 100% 8/8 [00:00<00:00, 84.88it/s]\n",
            "Epoch [51/100] | Train Loss: 0.047439 | Val Loss: 0.008233\n",
            "Epoch 52/100 [Train]: 100% 8/8 [00:00<00:00, 101.42it/s]\n",
            "Epoch [52/100] | Train Loss: 0.044690 | Val Loss: 0.004896\n",
            "Epoch 53/100 [Train]: 100% 8/8 [00:00<00:00, 102.85it/s]\n",
            "Epoch [53/100] | Train Loss: 0.044930 | Val Loss: 0.007932\n",
            "Epoch 54/100 [Train]: 100% 8/8 [00:00<00:00, 86.43it/s]\n",
            "Epoch [54/100] | Train Loss: 0.042678 | Val Loss: 0.010740\n",
            "Epoch 55/100 [Train]: 100% 8/8 [00:00<00:00, 103.36it/s]\n",
            "Epoch [55/100] | Train Loss: 0.043151 | Val Loss: 0.005221\n",
            "Epoch 56/100 [Train]: 100% 8/8 [00:00<00:00, 105.13it/s]\n",
            "Epoch [56/100] | Train Loss: 0.041478 | Val Loss: 0.006942\n",
            "Epoch 57/100 [Train]: 100% 8/8 [00:00<00:00, 103.42it/s]\n",
            "Epoch [57/100] | Train Loss: 0.041232 | Val Loss: 0.011280\n",
            "Epoch 58/100 [Train]: 100% 8/8 [00:00<00:00, 104.63it/s]\n",
            "Epoch [58/100] | Train Loss: 0.042401 | Val Loss: 0.004545\n",
            "Epoch 59/100 [Train]: 100% 8/8 [00:00<00:00, 100.70it/s]\n",
            "Epoch [59/100] | Train Loss: 0.044133 | Val Loss: 0.004817\n",
            "Epoch 60/100 [Train]: 100% 8/8 [00:00<00:00, 100.97it/s]\n",
            "Epoch [60/100] | Train Loss: 0.043976 | Val Loss: 0.025427\n",
            "Epoch 61/100 [Train]: 100% 8/8 [00:00<00:00, 91.87it/s]\n",
            "Epoch [61/100] | Train Loss: 0.047862 | Val Loss: 0.004698\n",
            "Epoch 62/100 [Train]: 100% 8/8 [00:00<00:00, 107.65it/s]\n",
            "Epoch [62/100] | Train Loss: 0.045207 | Val Loss: 0.008652\n",
            "Epoch 63/100 [Train]: 100% 8/8 [00:00<00:00, 106.55it/s]\n",
            "Epoch [63/100] | Train Loss: 0.043332 | Val Loss: 0.008487\n",
            "Epoch 64/100 [Train]: 100% 8/8 [00:00<00:00, 101.70it/s]\n",
            "Epoch [64/100] | Train Loss: 0.041215 | Val Loss: 0.006567\n",
            "Epoch 65/100 [Train]: 100% 8/8 [00:00<00:00, 100.79it/s]\n",
            "Epoch [65/100] | Train Loss: 0.041097 | Val Loss: 0.004871\n",
            "Epoch 66/100 [Train]: 100% 8/8 [00:00<00:00, 100.85it/s]\n",
            "Epoch [66/100] | Train Loss: 0.041034 | Val Loss: 0.027935\n",
            "Epoch 67/100 [Train]: 100% 8/8 [00:00<00:00, 103.03it/s]\n",
            "Epoch [67/100] | Train Loss: 0.041965 | Val Loss: 0.008085\n",
            "Epoch 68/100 [Train]: 100% 8/8 [00:00<00:00, 101.18it/s]\n",
            "Epoch [68/100] | Train Loss: 0.040808 | Val Loss: 0.005103\n",
            "Epoch 69/100 [Train]: 100% 8/8 [00:00<00:00, 105.08it/s]\n",
            "Epoch [69/100] | Train Loss: 0.044529 | Val Loss: 0.005194\n",
            "Epoch 70/100 [Train]: 100% 8/8 [00:00<00:00, 102.78it/s]\n",
            "Epoch [70/100] | Train Loss: 0.040643 | Val Loss: 0.007237\n",
            "Epoch 71/100 [Train]: 100% 8/8 [00:00<00:00, 103.20it/s]\n",
            "Epoch [71/100] | Train Loss: 0.042133 | Val Loss: 0.004964\n",
            "Epoch 72/100 [Train]: 100% 8/8 [00:00<00:00, 94.30it/s]\n",
            "Epoch [72/100] | Train Loss: 0.041856 | Val Loss: 0.016589\n",
            "Epoch 73/100 [Train]: 100% 8/8 [00:00<00:00, 92.24it/s]\n",
            "Epoch [73/100] | Train Loss: 0.043958 | Val Loss: 0.005469\n",
            "Epoch 74/100 [Train]: 100% 8/8 [00:00<00:00, 83.67it/s]\n",
            "Epoch [74/100] | Train Loss: 0.040163 | Val Loss: 0.009204\n",
            "Epoch 75/100 [Train]: 100% 8/8 [00:00<00:00, 104.52it/s]\n",
            "Epoch [75/100] | Train Loss: 0.041735 | Val Loss: 0.007463\n",
            "Epoch 76/100 [Train]: 100% 8/8 [00:00<00:00, 101.99it/s]\n",
            "Epoch [76/100] | Train Loss: 0.044018 | Val Loss: 0.008478\n",
            "Epoch 77/100 [Train]: 100% 8/8 [00:00<00:00, 100.21it/s]\n",
            "Epoch [77/100] | Train Loss: 0.043827 | Val Loss: 0.004660\n",
            "Epoch 78/100 [Train]: 100% 8/8 [00:00<00:00, 90.34it/s]\n",
            "Epoch [78/100] | Train Loss: 0.042808 | Val Loss: 0.014313\n",
            "Epoch 79/100 [Train]: 100% 8/8 [00:00<00:00, 100.73it/s]\n",
            "Epoch [79/100] | Train Loss: 0.041628 | Val Loss: 0.004548\n",
            "Epoch 80/100 [Train]: 100% 8/8 [00:00<00:00, 102.49it/s]\n",
            "Epoch [80/100] | Train Loss: 0.043119 | Val Loss: 0.016646\n",
            "Epoch 81/100 [Train]: 100% 8/8 [00:00<00:00, 94.21it/s]\n",
            "Epoch [81/100] | Train Loss: 0.042224 | Val Loss: 0.004645\n",
            "Epoch 82/100 [Train]: 100% 8/8 [00:00<00:00, 103.65it/s]\n",
            "Epoch [82/100] | Train Loss: 0.043446 | Val Loss: 0.014580\n",
            "Epoch 83/100 [Train]: 100% 8/8 [00:00<00:00, 106.05it/s]\n",
            "Epoch [83/100] | Train Loss: 0.041768 | Val Loss: 0.004617\n",
            "Epoch 84/100 [Train]: 100% 8/8 [00:00<00:00, 89.63it/s]\n",
            "Epoch [84/100] | Train Loss: 0.040823 | Val Loss: 0.008835\n",
            "Epoch 85/100 [Train]: 100% 8/8 [00:00<00:00, 98.71it/s]\n",
            "Epoch [85/100] | Train Loss: 0.041773 | Val Loss: 0.004982\n",
            "Epoch 86/100 [Train]: 100% 8/8 [00:00<00:00, 105.74it/s]\n",
            "Epoch [86/100] | Train Loss: 0.039257 | Val Loss: 0.005403\n",
            "Epoch 87/100 [Train]: 100% 8/8 [00:00<00:00, 103.27it/s]\n",
            "Epoch [87/100] | Train Loss: 0.040236 | Val Loss: 0.007075\n",
            "Epoch 88/100 [Train]: 100% 8/8 [00:00<00:00, 84.28it/s]\n",
            "Epoch [88/100] | Train Loss: 0.042086 | Val Loss: 0.012946\n",
            "Epoch 89/100 [Train]: 100% 8/8 [00:00<00:00, 105.54it/s]\n",
            "Epoch [89/100] | Train Loss: 0.042238 | Val Loss: 0.005420\n",
            "Epoch 90/100 [Train]: 100% 8/8 [00:00<00:00, 106.97it/s]\n",
            "Epoch [90/100] | Train Loss: 0.040445 | Val Loss: 0.006858\n",
            "Epoch 91/100 [Train]: 100% 8/8 [00:00<00:00, 105.48it/s]\n",
            "Epoch [91/100] | Train Loss: 0.039477 | Val Loss: 0.006244\n",
            "Epoch 92/100 [Train]: 100% 8/8 [00:00<00:00, 99.11it/s]\n",
            "Epoch [92/100] | Train Loss: 0.038958 | Val Loss: 0.006498\n",
            "Epoch 93/100 [Train]: 100% 8/8 [00:00<00:00, 100.96it/s]\n",
            "Epoch [93/100] | Train Loss: 0.106577 | Val Loss: 0.007222\n",
            "Epoch 94/100 [Train]: 100% 8/8 [00:00<00:00, 103.37it/s]\n",
            "Epoch [94/100] | Train Loss: 0.062247 | Val Loss: 0.026890\n",
            "Epoch 95/100 [Train]: 100% 8/8 [00:00<00:00, 63.41it/s]\n",
            "Epoch [95/100] | Train Loss: 0.047924 | Val Loss: 0.007219\n",
            "Epoch 96/100 [Train]: 100% 8/8 [00:00<00:00, 63.51it/s]\n",
            "Epoch [96/100] | Train Loss: 0.040523 | Val Loss: 0.005784\n",
            "Epoch 97/100 [Train]: 100% 8/8 [00:00<00:00, 67.88it/s]\n",
            "Epoch [97/100] | Train Loss: 0.040992 | Val Loss: 0.004974\n",
            "Epoch 98/100 [Train]: 100% 8/8 [00:00<00:00, 64.22it/s]\n",
            "Epoch [98/100] | Train Loss: 0.042934 | Val Loss: 0.004547\n",
            "Epoch 99/100 [Train]: 100% 8/8 [00:00<00:00, 70.80it/s]\n",
            "Epoch [99/100] | Train Loss: 0.041591 | Val Loss: 0.004582\n",
            "Epoch 100/100 [Train]: 100% 8/8 [00:00<00:00, 72.31it/s]\n",
            "Epoch [100/100] | Train Loss: 0.041268 | Val Loss: 0.004608\n",
            "\n",
            "--- Huấn luyện Hoàn tất ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile ensemble_evaluate.py\n",
        "# ensemble_evaluate.py\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from model import MSLSTMAttention, FinalModel\n",
        "from dataset import get_data_loaders\n",
        "from config import NUM_BASE_FEATURES, NUM_SCALES\n",
        "\n",
        "# Các đường dẫn file model mới\n",
        "SYNCED_MODEL_A_PATH = 'mslstm_attention_synced.pth'\n",
        "OPTIMIZED_MODEL_B_PATH = 'final_optimized_model.pth'\n",
        "\n",
        "def run_ensemble_evaluation():\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    print(f\"Sử dụng thiết bị: {device.upper()}\")\n",
        "\n",
        "    _, test_loader, target_scaler, _ = get_data_loaders()\n",
        "    if not test_loader: return\n",
        "\n",
        "    # Model A (đã được huấn luyện đồng bộ)\n",
        "    model_A = MSLSTMAttention(\n",
        "        input_feature_size=NUM_BASE_FEATURES, num_scales=NUM_SCALES,\n",
        "        lstm_hidden_units=128, lstm_num_layers=2, num_heads=4\n",
        "    )\n",
        "\n",
        "    # Model B (tối ưu)\n",
        "    model_B_params = {'lstm_hidden_units': 192, 'lstm_num_layers': 1, 'attention_num_heads': 8}\n",
        "    model_B = FinalModel(\n",
        "        input_feature_size=NUM_BASE_FEATURES, num_scales=NUM_SCALES,\n",
        "        lstm_hidden_units=model_B_params['lstm_hidden_units'],\n",
        "        lstm_num_layers=model_B_params['lstm_num_layers'],\n",
        "        num_heads=model_B_params['attention_num_heads']\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        print(f\"Đang tải Model A (đồng bộ) từ: {SYNCED_MODEL_A_PATH}\")\n",
        "        model_A.load_state_dict(torch.load(SYNCED_MODEL_A_PATH, map_location=device))\n",
        "        model_A.to(device)\n",
        "        model_A.eval()\n",
        "\n",
        "        print(f\"Đang tải Model B (tối ưu) từ: {OPTIMIZED_MODEL_B_PATH}\")\n",
        "        model_B.load_state_dict(torch.load(OPTIMIZED_MODEL_B_PATH, map_location=device))\n",
        "        model_B.to(device)\n",
        "        model_B.eval()\n",
        "    except FileNotFoundError as e:\n",
        "        print(f\"Lỗi: Không tìm thấy file model. Hãy đảm bảo các file sau tồn tại: {e.filename}\")\n",
        "        return\n",
        "\n",
        "    # Lấy dự đoán và thực hiện ensemble (logic giải chuẩn hóa trước đã đúng)\n",
        "    original_preds_ensemble = []\n",
        "    original_actuals_list = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for features, (price_lbl, _, _) in test_loader:\n",
        "            features = features.to(device)\n",
        "\n",
        "            scaled_pred_A = model_A(features)\n",
        "            scaled_pred_B_price, _, _ = model_B(features)\n",
        "\n",
        "            original_pred_A = target_scaler.inverse_transform(scaled_pred_A.cpu().numpy().reshape(-1, 1))\n",
        "            original_pred_B = target_scaler.inverse_transform(scaled_pred_B_price.cpu().numpy().reshape(-1, 1))\n",
        "\n",
        "            avg_pred_original = (original_pred_A + original_pred_B) / 2.0\n",
        "\n",
        "            original_actuals = target_scaler.inverse_transform(price_lbl.numpy().reshape(-1, 1))\n",
        "\n",
        "            original_preds_ensemble.extend(avg_pred_original.flatten())\n",
        "            original_actuals_list.extend(original_actuals.flatten())\n",
        "\n",
        "    mae = np.mean(np.abs(np.array(original_preds_ensemble) - np.array(original_actuals_list)))\n",
        "    print(\"\\n--- Kết quả Đánh giá của Ensemble (Đã đồng bộ dữ liệu) ---\")\n",
        "    print(f\"🏆 [Giá] Sai số Trung bình Tuyệt đối (MAE): {mae:.4f} (điểm VN-Index)\")\n",
        "\n",
        "    # Vẽ biểu đồ\n",
        "    plt.figure(figsize=(15, 6))\n",
        "    plt.plot(original_actuals_list, label='Giá trị Thực tế', color='blue', marker='.', linestyle='-')\n",
        "    plt.plot(original_preds_ensemble, label='Dự đoán Ensemble', color='green', linestyle='--')\n",
        "    plt.title(\"So sánh Giá trị Thực tế và Dự đoán Ensemble (Đồng bộ)\")\n",
        "    plt.xlabel('Ngày (trong tập Test)')\n",
        "    plt.ylabel('Giá đóng cửa VN-Index')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig('final_ensemble_prediction_synced.png')\n",
        "    print(\"✅ Đã lưu biểu đồ so sánh của Ensemble vào file 'final_ensemble_prediction_synced.png'\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    run_ensemble_evaluation()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tyTZHq4jjGN8",
        "outputId": "151d96d2-7ba3-4ef9-e4d5-b1e91766ede9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting ensemble_evaluate.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python ensemble_evaluate.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0OCGmpqjJ3q",
        "outputId": "5999f17c-2757-4370-b919-f4fb1f5404f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sử dụng thiết bị: CUDA\n",
            "✅ DataLoader đa nhiệm đã sẵn sàng.\n",
            "Đang tải Model A (đồng bộ) từ: mslstm_attention_synced.pth\n",
            "Đang tải Model B (tối ưu) từ: final_optimized_model.pth\n",
            "\n",
            "--- Kết quả Đánh giá của Ensemble (Đã đồng bộ dữ liệu) ---\n",
            "🏆 [Giá] Sai số Trung bình Tuyệt đối (MAE): 19.0011 (điểm VN-Index)\n",
            "✅ Đã lưu biểu đồ so sánh của Ensemble vào file 'final_ensemble_prediction_synced.png'\n"
          ]
        }
      ]
    }
  ]
}